{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "seconds = 12.8\n",
    "seconds_per_pixel = 0.1\n",
    "num_sequence = 10\n",
    "COMPOSERS = [\"Bach\", \"Beethoven\", \"Chopin\", \"Mozart\"]\n",
    "image_dir = \"data/new_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(image, seconds, seconds_per_pixel):\n",
    "    pix_per_slice = int(seconds // seconds_per_pixel)\n",
    "    num_slices = int(image.shape[1] // pix_per_slice)\n",
    "\n",
    "    slices = np.zeros((num_slices, image.shape[0], pix_per_slice))\n",
    "    for slice in range(num_slices):\n",
    "        slices[slice] = image[:, slice * pix_per_slice : (slice + 1) * pix_per_slice]\n",
    "\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_song_to_inputs(song: str, composer:str, seconds:float = 12.8, seconds_per_pixel:float = 0.1, num_sequence:int = 10):\n",
    "    \"\"\"Returns inputs with shape [num_inputs, sequence_length, channels, image_height, image_width]\"\"\"\n",
    "\n",
    "    pixels_per_slice = int(seconds // seconds_per_pixel)\n",
    "    sequence_length = pixels_per_slice * num_sequence\n",
    "\n",
    "    # Load image\n",
    "    im = iio.imread(song, mode=\"L\")\n",
    "    image = (im > 0).astype(int)\n",
    "\n",
    "    # Pad image\n",
    "    pad_width = int(np.ceil(image.shape[1] / sequence_length) * sequence_length) - image.shape[1]\n",
    "    padded_image = np.pad(image, ((0, 0), (0, pad_width)), mode='constant', constant_values=0)\n",
    "\n",
    "    # Convert to input and output for network\n",
    "    images = []\n",
    "    outputs = []\n",
    "    for pad_image in padded_image.T.reshape(-1, sequence_length, image.shape[0]):\n",
    "        images.append(slice_image(pad_image.T, seconds, seconds_per_pixel))\n",
    "        outputs.append(composer)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    inputs = np.expand_dims(np.array(images), axis=2)\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6173, 10, 1, 128, 128)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for composer in COMPOSERS:\n",
    "    for im_path in glob.glob(image_dir + \"/\" + composer + \"/*.png\"):\n",
    "        input, output = convert_song_to_inputs(im_path, composer)\n",
    "        inputs.append(input)\n",
    "        outputs += output\n",
    "\n",
    "inputs = np.vstack(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \n",
       "Bach         2208\n",
       "Beethoven    1838\n",
       "Mozart       1623\n",
       "Chopin        504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(outputs)\n",
    "output_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_Bach</th>\n",
       "      <th>0_Beethoven</th>\n",
       "      <th>0_Chopin</th>\n",
       "      <th>0_Mozart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_Bach  0_Beethoven  0_Chopin  0_Mozart\n",
       "0    True        False     False     False\n",
       "1    True        False     False     False\n",
       "2    True        False     False     False\n",
       "3    True        False     False     False\n",
       "4    True        False     False     False"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies\n",
    "output_df = pd.get_dummies(output_df)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, test, and validation\n",
    "train_X, test_X, train_y, test_y = train_test_split(inputs, output_df, test_size=0.2)\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X, test_y, test_size=0.5)\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_X = torch.Tensor(train_X).to(device)\n",
    "test_X = torch.Tensor(test_X).to(device)\n",
    "val_X = torch.Tensor(val_X).to(device)\n",
    "\n",
    "train_y = torch.Tensor(train_y.to_numpy().astype(int)).to(device)\n",
    "test_y = torch.Tensor(test_y.to_numpy().astype(int)).to(device)\n",
    "val_y = torch.Tensor(val_y.to_numpy().astype(int)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ComposerClassifier(nn.Module):\n",
    "    def __init__(self, hidden_nodes, seconds = 12.8, seconds_per_pixel = 0.1):\n",
    "        super(ComposerClassifier, self).__init__()\n",
    "\n",
    "        # Define network parameters\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "\n",
    "        # Define image slicing parameters\n",
    "        self.seconds = seconds\n",
    "        self.seconds_per_pixel = seconds_per_pixel\n",
    "\n",
    "        # Define CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=(3,3))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3,3), stride=3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=(5,5))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(5,5), stride=5)\n",
    "\n",
    "        # Define LSTM layers\n",
    "        self.lstm = nn.LSTM(392, self.hidden_nodes, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_nodes, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Create sequence tensor from slices processed through CNN layers\n",
    "        num_inputs = x.shape[0]\n",
    "        x = torch.vstack(torch.unbind(x, dim=0)).to(x.device)\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        sequence = x.reshape(num_inputs, -1, 392).to(x.device)\n",
    "\n",
    "        # Process sequence tensor through LSTM layers\n",
    "        h0 = torch.zeros(1, sequence.size(0), self.hidden_nodes).to(x.device)\n",
    "        c0 = torch.zeros(1, sequence.size(0), self.hidden_nodes).to(x.device)\n",
    "        out, _ = self.lstm(sequence, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        # Return softmax probabilities\n",
    "        return nn.functional.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComposerClassifier(100, seconds=seconds, seconds_per_pixel=seconds_per_pixel)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        # Number of epochs to wait if no improvement is seen\n",
    "        self.patience = patience\n",
    "\n",
    "        # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        # Internal trackers\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        # If the validation loss has improved\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            # Save the best validation loss and reset the counter\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "\n",
    "        # If the validation loss has not improved\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            # Increment the counter and if the counter is greater than the patience, stop training\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, optimizer, criterion, scheduler, train_X, train_y, val_X, val_y, num_epochs=300, batch_size=32, lr=0.001, early_stopper=None) -> tuple[list, list, list]:\n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    micro_precisions = []\n",
    "    micro_recalls = []\n",
    "    micro_f1s = []\n",
    "\n",
    "    macro_precisions = []\n",
    "    macro_recalls = []\n",
    "    macro_f1s = []\n",
    "\n",
    "    weighted_precisions = []\n",
    "    weighted_recalls = []\n",
    "    weighted_f1s = []\n",
    "\n",
    "    # Train the model\n",
    "    num_batches = int(np.ceil(len(train_X) / batch_size))\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in range(num_batches):\n",
    "            # Get the batch data\n",
    "            batch_X = train_X[batch_size * batch:min(batch_size * (batch + 1), train_X.shape[0])]\n",
    "            batch_y = train_y[batch_size * batch:min(batch_size * (batch + 1), train_X.shape[0])]\n",
    "\n",
    "            # Forward Pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "\n",
    "            # Backward Pass\n",
    "            train_loss = criterion(output, batch_y)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():\n",
    "            # Forward Pass\n",
    "            output = model(val_X)\n",
    "\n",
    "            # Compute Metrics\n",
    "            val_loss = criterion(output, val_y)\n",
    "            correct = correct = val_y.cpu().argmax(dim=1)\n",
    "            answer = output.argmax(dim=1).cpu()\n",
    "\n",
    "            accuracy = accuracy_score(correct, answer)\n",
    "\n",
    "            micro_precision = precision_score(correct, answer, average='micro', zero_division=0)\n",
    "            micro_recall = recall_score(correct, answer, average='micro', zero_division=0)\n",
    "            micro_f1 = f1_score(correct, answer, average='micro', zero_division=0)\n",
    "\n",
    "            macro_precision = precision_score(correct, answer, average='macro', zero_division=0)\n",
    "            macro_recall = recall_score(correct, answer, average='macro', zero_division=0)\n",
    "            macro_f1 = f1_score(correct, answer, average='macro', zero_division=0)\n",
    "\n",
    "            weighted_precision = precision_score(correct, answer, average='weighted', zero_division=0)\n",
    "            weighted_recall = recall_score(correct, answer, average='weighted', zero_division=0)\n",
    "            weighted_f1 = f1_score(correct, answer, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "            # Record Metrics\n",
    "            train_losses += [train_loss.item()]\n",
    "            val_losses += [val_loss.item()]\n",
    "\n",
    "            accuracies += [accuracy]\n",
    "\n",
    "            micro_precisions += [micro_precision]\n",
    "            micro_recalls += [micro_recall]\n",
    "            micro_f1s += [micro_f1]\n",
    "\n",
    "            macro_precisions += [macro_precision]\n",
    "            macro_recalls += [macro_recall]\n",
    "            macro_f1s += [macro_f1]\n",
    "\n",
    "            weighted_precisions += [weighted_precision]\n",
    "            weighted_recalls += [weighted_recall]\n",
    "            weighted_f1s += [weighted_f1]\n",
    "\n",
    "            # Print Metrics\n",
    "            print(f\"Epoch: {epoch}, Train Loss: {train_loss.item():.3f}, Validation Loss: {val_loss.item():.3f}, LR: {scheduler.get_last_lr()[0]:.6f} Accuracy: {accuracy:.3f}\",\n",
    "                  f\"\\n\\tPrecision | Micro | {micro_precision:.3f} | Macro | {macro_precision:.3f} | Weighted | {weighted_f1:.3f}\",\n",
    "                  f\"\\n\\tRecall    | Micro | {micro_recall:.3f} | Macro | {macro_recall:.3f} | Weighted | {weighted_precision:.3f}\",\n",
    "                  f\"\\n\\tF1        | Micro | {micro_f1:.3f} | Macro | {macro_f1:.3f} | Weighted | {weighted_recall:.3f}\")\n",
    "\n",
    "        if early_stopper is not None and early_stopper.early_stop(val_loss):\n",
    "            print(f\"Early stopped triggered at epoch: {epoch}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "    precisions = (micro_precisions, macro_precisions, weighted_precisions)\n",
    "    recalls = (micro_recalls, macro_recalls, weighted_recalls)\n",
    "    f1s = (micro_f1s, macro_f1s, weighted_f1s)\n",
    "    return train_losses, val_losses, accuracies, precisions, recalls, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.266, Validation Loss: 1.295, LR: 0.000500 Accuracy: 0.442 \n",
      "\tPrecision | Micro | 0.442 | Macro | 0.216 | Weighted | 0.351 \n",
      "\tRecall    | Micro | 0.442 | Macro | 0.325 | Weighted | 0.292 \n",
      "\tF1        | Micro | 0.442 | Macro | 0.259 | Weighted | 0.442\n",
      "Epoch: 1, Train Loss: 1.199, Validation Loss: 1.212, LR: 0.000500 Accuracy: 0.506 \n",
      "\tPrecision | Micro | 0.506 | Macro | 0.388 | Weighted | 0.413 \n",
      "\tRecall    | Micro | 0.506 | Macro | 0.374 | Weighted | 0.471 \n",
      "\tF1        | Micro | 0.506 | Macro | 0.310 | Weighted | 0.506\n",
      "Epoch: 2, Train Loss: 1.157, Validation Loss: 1.167, LR: 0.000499 Accuracy: 0.598 \n",
      "\tPrecision | Micro | 0.598 | Macro | 0.448 | Weighted | 0.553 \n",
      "\tRecall    | Micro | 0.598 | Macro | 0.468 | Weighted | 0.550 \n",
      "\tF1        | Micro | 0.598 | Macro | 0.438 | Weighted | 0.598\n",
      "Epoch: 3, Train Loss: 1.149, Validation Loss: 1.132, LR: 0.000499 Accuracy: 0.634 \n",
      "\tPrecision | Micro | 0.634 | Macro | 0.472 | Weighted | 0.604 \n",
      "\tRecall    | Micro | 0.634 | Macro | 0.509 | Weighted | 0.585 \n",
      "\tF1        | Micro | 0.634 | Macro | 0.485 | Weighted | 0.634\n",
      "Epoch: 4, Train Loss: 1.084, Validation Loss: 1.098, LR: 0.000498 Accuracy: 0.663 \n",
      "\tPrecision | Micro | 0.663 | Macro | 0.494 | Weighted | 0.625 \n",
      "\tRecall    | Micro | 0.663 | Macro | 0.525 | Weighted | 0.604 \n",
      "\tF1        | Micro | 0.663 | Macro | 0.504 | Weighted | 0.663\n",
      "Epoch: 5, Train Loss: 1.056, Validation Loss: 1.094, LR: 0.000498 Accuracy: 0.655 \n",
      "\tPrecision | Micro | 0.655 | Macro | 0.482 | Weighted | 0.625 \n",
      "\tRecall    | Micro | 0.655 | Macro | 0.528 | Weighted | 0.599 \n",
      "\tF1        | Micro | 0.655 | Macro | 0.504 | Weighted | 0.655\n",
      "Epoch: 6, Train Loss: 1.028, Validation Loss: 1.074, LR: 0.000497 Accuracy: 0.673 \n",
      "\tPrecision | Micro | 0.673 | Macro | 0.498 | Weighted | 0.640 \n",
      "\tRecall    | Micro | 0.673 | Macro | 0.540 | Weighted | 0.614 \n",
      "\tF1        | Micro | 0.673 | Macro | 0.516 | Weighted | 0.673\n",
      "Epoch: 7, Train Loss: 1.033, Validation Loss: 1.086, LR: 0.000497 Accuracy: 0.653 \n",
      "\tPrecision | Micro | 0.653 | Macro | 0.483 | Weighted | 0.622 \n",
      "\tRecall    | Micro | 0.653 | Macro | 0.523 | Weighted | 0.602 \n",
      "\tF1        | Micro | 0.653 | Macro | 0.498 | Weighted | 0.653\n",
      "Epoch: 8, Train Loss: 1.028, Validation Loss: 1.092, LR: 0.000496 Accuracy: 0.648 \n",
      "\tPrecision | Micro | 0.648 | Macro | 0.490 | Weighted | 0.608 \n",
      "\tRecall    | Micro | 0.648 | Macro | 0.511 | Weighted | 0.598 \n",
      "\tF1        | Micro | 0.648 | Macro | 0.489 | Weighted | 0.648\n",
      "Epoch: 9, Train Loss: 1.013, Validation Loss: 1.077, LR: 0.000496 Accuracy: 0.663 \n",
      "\tPrecision | Micro | 0.663 | Macro | 0.499 | Weighted | 0.624 \n",
      "\tRecall    | Micro | 0.663 | Macro | 0.525 | Weighted | 0.610 \n",
      "\tF1        | Micro | 0.663 | Macro | 0.502 | Weighted | 0.663\n",
      "Epoch: 10, Train Loss: 1.009, Validation Loss: 1.057, LR: 0.000495 Accuracy: 0.687 \n",
      "\tPrecision | Micro | 0.687 | Macro | 0.511 | Weighted | 0.651 \n",
      "\tRecall    | Micro | 0.687 | Macro | 0.549 | Weighted | 0.627 \n",
      "\tF1        | Micro | 0.687 | Macro | 0.526 | Weighted | 0.687\n",
      "Epoch: 11, Train Loss: 0.993, Validation Loss: 1.083, LR: 0.000495 Accuracy: 0.647 \n",
      "\tPrecision | Micro | 0.647 | Macro | 0.487 | Weighted | 0.606 \n",
      "\tRecall    | Micro | 0.647 | Macro | 0.510 | Weighted | 0.597 \n",
      "\tF1        | Micro | 0.647 | Macro | 0.486 | Weighted | 0.647\n",
      "Epoch: 12, Train Loss: 0.993, Validation Loss: 1.056, LR: 0.000494 Accuracy: 0.692 \n",
      "\tPrecision | Micro | 0.692 | Macro | 0.522 | Weighted | 0.653 \n",
      "\tRecall    | Micro | 0.692 | Macro | 0.549 | Weighted | 0.634 \n",
      "\tF1        | Micro | 0.692 | Macro | 0.528 | Weighted | 0.692\n",
      "Epoch: 13, Train Loss: 0.966, Validation Loss: 1.052, LR: 0.000494 Accuracy: 0.694 \n",
      "\tPrecision | Micro | 0.694 | Macro | 0.517 | Weighted | 0.656 \n",
      "\tRecall    | Micro | 0.694 | Macro | 0.556 | Weighted | 0.634 \n",
      "\tF1        | Micro | 0.694 | Macro | 0.531 | Weighted | 0.694\n",
      "Epoch: 14, Train Loss: 0.965, Validation Loss: 1.033, LR: 0.000493 Accuracy: 0.702 \n",
      "\tPrecision | Micro | 0.702 | Macro | 0.520 | Weighted | 0.668 \n",
      "\tRecall    | Micro | 0.702 | Macro | 0.562 | Weighted | 0.643 \n",
      "\tF1        | Micro | 0.702 | Macro | 0.538 | Weighted | 0.702\n",
      "Epoch: 15, Train Loss: 0.961, Validation Loss: 1.046, LR: 0.000493 Accuracy: 0.689 \n",
      "\tPrecision | Micro | 0.689 | Macro | 0.515 | Weighted | 0.650 \n",
      "\tRecall    | Micro | 0.689 | Macro | 0.546 | Weighted | 0.628 \n",
      "\tF1        | Micro | 0.689 | Macro | 0.524 | Weighted | 0.689\n",
      "Epoch: 16, Train Loss: 0.951, Validation Loss: 1.025, LR: 0.000492 Accuracy: 0.716 \n",
      "\tPrecision | Micro | 0.716 | Macro | 0.527 | Weighted | 0.683 \n",
      "\tRecall    | Micro | 0.716 | Macro | 0.576 | Weighted | 0.653 \n",
      "\tF1        | Micro | 0.716 | Macro | 0.551 | Weighted | 0.716\n",
      "Epoch: 17, Train Loss: 0.966, Validation Loss: 1.038, LR: 0.000492 Accuracy: 0.708 \n",
      "\tPrecision | Micro | 0.708 | Macro | 0.535 | Weighted | 0.669 \n",
      "\tRecall    | Micro | 0.708 | Macro | 0.562 | Weighted | 0.650 \n",
      "\tF1        | Micro | 0.708 | Macro | 0.540 | Weighted | 0.708\n",
      "Epoch: 18, Train Loss: 0.942, Validation Loss: 1.020, LR: 0.000491 Accuracy: 0.723 \n",
      "\tPrecision | Micro | 0.723 | Macro | 0.533 | Weighted | 0.686 \n",
      "\tRecall    | Micro | 0.723 | Macro | 0.578 | Weighted | 0.656 \n",
      "\tF1        | Micro | 0.723 | Macro | 0.553 | Weighted | 0.723\n",
      "Epoch: 19, Train Loss: 0.954, Validation Loss: 1.028, LR: 0.000491 Accuracy: 0.716 \n",
      "\tPrecision | Micro | 0.716 | Macro | 0.539 | Weighted | 0.677 \n",
      "\tRecall    | Micro | 0.716 | Macro | 0.569 | Weighted | 0.656 \n",
      "\tF1        | Micro | 0.716 | Macro | 0.546 | Weighted | 0.716\n",
      "Epoch: 20, Train Loss: 0.942, Validation Loss: 1.024, LR: 0.000490 Accuracy: 0.720 \n",
      "\tPrecision | Micro | 0.720 | Macro | 0.540 | Weighted | 0.680 \n",
      "\tRecall    | Micro | 0.720 | Macro | 0.572 | Weighted | 0.658 \n",
      "\tF1        | Micro | 0.720 | Macro | 0.549 | Weighted | 0.720\n",
      "Epoch: 21, Train Loss: 0.958, Validation Loss: 1.033, LR: 0.000490 Accuracy: 0.705 \n",
      "\tPrecision | Micro | 0.705 | Macro | 0.530 | Weighted | 0.665 \n",
      "\tRecall    | Micro | 0.705 | Macro | 0.558 | Weighted | 0.644 \n",
      "\tF1        | Micro | 0.705 | Macro | 0.537 | Weighted | 0.705\n",
      "Epoch: 22, Train Loss: 0.942, Validation Loss: 1.026, LR: 0.000489 Accuracy: 0.710 \n",
      "\tPrecision | Micro | 0.710 | Macro | 0.528 | Weighted | 0.670 \n",
      "\tRecall    | Micro | 0.710 | Macro | 0.563 | Weighted | 0.645 \n",
      "\tF1        | Micro | 0.710 | Macro | 0.540 | Weighted | 0.710\n",
      "Epoch: 23, Train Loss: 0.934, Validation Loss: 1.032, LR: 0.000489 Accuracy: 0.707 \n",
      "\tPrecision | Micro | 0.707 | Macro | 0.527 | Weighted | 0.668 \n",
      "\tRecall    | Micro | 0.707 | Macro | 0.562 | Weighted | 0.644 \n",
      "\tF1        | Micro | 0.707 | Macro | 0.539 | Weighted | 0.707\n",
      "Epoch: 24, Train Loss: 0.939, Validation Loss: 1.012, LR: 0.000488 Accuracy: 0.728 \n",
      "\tPrecision | Micro | 0.728 | Macro | 0.539 | Weighted | 0.696 \n",
      "\tRecall    | Micro | 0.728 | Macro | 0.588 | Weighted | 0.669 \n",
      "\tF1        | Micro | 0.728 | Macro | 0.561 | Weighted | 0.728\n",
      "Epoch: 25, Train Loss: 0.927, Validation Loss: 1.008, LR: 0.000488 Accuracy: 0.733 \n",
      "\tPrecision | Micro | 0.733 | Macro | 0.543 | Weighted | 0.695 \n",
      "\tRecall    | Micro | 0.733 | Macro | 0.586 | Weighted | 0.665 \n",
      "\tF1        | Micro | 0.733 | Macro | 0.562 | Weighted | 0.733\n",
      "Epoch: 26, Train Loss: 0.933, Validation Loss: 1.018, LR: 0.000487 Accuracy: 0.720 \n",
      "\tPrecision | Micro | 0.720 | Macro | 0.539 | Weighted | 0.680 \n",
      "\tRecall    | Micro | 0.720 | Macro | 0.572 | Weighted | 0.657 \n",
      "\tF1        | Micro | 0.720 | Macro | 0.549 | Weighted | 0.720\n",
      "Epoch: 27, Train Loss: 0.922, Validation Loss: 1.000, LR: 0.000487 Accuracy: 0.739 \n",
      "\tPrecision | Micro | 0.739 | Macro | 0.550 | Weighted | 0.701 \n",
      "\tRecall    | Micro | 0.739 | Macro | 0.591 | Weighted | 0.673 \n",
      "\tF1        | Micro | 0.739 | Macro | 0.566 | Weighted | 0.739\n",
      "Epoch: 28, Train Loss: 0.919, Validation Loss: 0.995, LR: 0.000486 Accuracy: 0.746 \n",
      "\tPrecision | Micro | 0.746 | Macro | 0.552 | Weighted | 0.709 \n",
      "\tRecall    | Micro | 0.746 | Macro | 0.598 | Weighted | 0.680 \n",
      "\tF1        | Micro | 0.746 | Macro | 0.572 | Weighted | 0.746\n",
      "Epoch: 29, Train Loss: 0.926, Validation Loss: 1.008, LR: 0.000486 Accuracy: 0.731 \n",
      "\tPrecision | Micro | 0.731 | Macro | 0.546 | Weighted | 0.691 \n",
      "\tRecall    | Micro | 0.731 | Macro | 0.581 | Weighted | 0.667 \n",
      "\tF1        | Micro | 0.731 | Macro | 0.557 | Weighted | 0.731\n",
      "Epoch: 30, Train Loss: 0.917, Validation Loss: 0.999, LR: 0.000485 Accuracy: 0.739 \n",
      "\tPrecision | Micro | 0.739 | Macro | 0.551 | Weighted | 0.700 \n",
      "\tRecall    | Micro | 0.739 | Macro | 0.590 | Weighted | 0.674 \n",
      "\tF1        | Micro | 0.739 | Macro | 0.566 | Weighted | 0.739\n",
      "Epoch: 31, Train Loss: 0.934, Validation Loss: 0.993, LR: 0.000485 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.563 | Weighted | 0.711 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.599 | Weighted | 0.688 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.575 | Weighted | 0.749\n",
      "Epoch: 32, Train Loss: 0.923, Validation Loss: 0.994, LR: 0.000484 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.555 | Weighted | 0.705 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.594 | Weighted | 0.679 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.570 | Weighted | 0.742\n",
      "Epoch: 33, Train Loss: 0.917, Validation Loss: 1.002, LR: 0.000484 Accuracy: 0.741 \n",
      "\tPrecision | Micro | 0.741 | Macro | 0.554 | Weighted | 0.708 \n",
      "\tRecall    | Micro | 0.741 | Macro | 0.597 | Weighted | 0.684 \n",
      "\tF1        | Micro | 0.741 | Macro | 0.571 | Weighted | 0.741\n",
      "Epoch: 34, Train Loss: 0.912, Validation Loss: 0.994, LR: 0.000483 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.553 | Weighted | 0.708 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.597 | Weighted | 0.682 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.572 | Weighted | 0.742\n",
      "Epoch: 35, Train Loss: 0.923, Validation Loss: 0.995, LR: 0.000483 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.552 | Weighted | 0.707 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.596 | Weighted | 0.679 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.571 | Weighted | 0.742\n",
      "Epoch: 36, Train Loss: 0.930, Validation Loss: 0.992, LR: 0.000482 Accuracy: 0.754 \n",
      "\tPrecision | Micro | 0.754 | Macro | 0.559 | Weighted | 0.718 \n",
      "\tRecall    | Micro | 0.754 | Macro | 0.606 | Weighted | 0.688 \n",
      "\tF1        | Micro | 0.754 | Macro | 0.581 | Weighted | 0.754\n",
      "Epoch: 37, Train Loss: 0.907, Validation Loss: 1.002, LR: 0.000482 Accuracy: 0.736 \n",
      "\tPrecision | Micro | 0.736 | Macro | 0.553 | Weighted | 0.701 \n",
      "\tRecall    | Micro | 0.736 | Macro | 0.589 | Weighted | 0.680 \n",
      "\tF1        | Micro | 0.736 | Macro | 0.565 | Weighted | 0.736\n",
      "Epoch: 38, Train Loss: 0.906, Validation Loss: 1.009, LR: 0.000481 Accuracy: 0.728 \n",
      "\tPrecision | Micro | 0.728 | Macro | 0.541 | Weighted | 0.697 \n",
      "\tRecall    | Micro | 0.728 | Macro | 0.589 | Weighted | 0.675 \n",
      "\tF1        | Micro | 0.728 | Macro | 0.562 | Weighted | 0.728\n",
      "Epoch: 39, Train Loss: 0.915, Validation Loss: 0.995, LR: 0.000481 Accuracy: 0.746 \n",
      "\tPrecision | Micro | 0.746 | Macro | 0.551 | Weighted | 0.712 \n",
      "\tRecall    | Micro | 0.746 | Macro | 0.602 | Weighted | 0.683 \n",
      "\tF1        | Micro | 0.746 | Macro | 0.575 | Weighted | 0.746\n",
      "Epoch: 40, Train Loss: 0.923, Validation Loss: 0.990, LR: 0.000480 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.558 | Weighted | 0.714 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.603 | Weighted | 0.685 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.577 | Weighted | 0.749\n",
      "Epoch: 41, Train Loss: 0.949, Validation Loss: 1.010, LR: 0.000480 Accuracy: 0.724 \n",
      "\tPrecision | Micro | 0.724 | Macro | 0.536 | Weighted | 0.686 \n",
      "\tRecall    | Micro | 0.724 | Macro | 0.581 | Weighted | 0.660 \n",
      "\tF1        | Micro | 0.724 | Macro | 0.554 | Weighted | 0.724\n",
      "Epoch: 42, Train Loss: 0.935, Validation Loss: 0.988, LR: 0.000479 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.564 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.615 | Weighted | 0.692 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.588 | Weighted | 0.762\n",
      "Epoch: 43, Train Loss: 0.969, Validation Loss: 1.010, LR: 0.000479 Accuracy: 0.728 \n",
      "\tPrecision | Micro | 0.728 | Macro | 0.541 | Weighted | 0.689 \n",
      "\tRecall    | Micro | 0.728 | Macro | 0.584 | Weighted | 0.663 \n",
      "\tF1        | Micro | 0.728 | Macro | 0.558 | Weighted | 0.728\n",
      "Epoch: 44, Train Loss: 0.908, Validation Loss: 0.995, LR: 0.000478 Accuracy: 0.741 \n",
      "\tPrecision | Micro | 0.741 | Macro | 0.557 | Weighted | 0.705 \n",
      "\tRecall    | Micro | 0.741 | Macro | 0.593 | Weighted | 0.683 \n",
      "\tF1        | Micro | 0.741 | Macro | 0.570 | Weighted | 0.741\n",
      "Epoch: 45, Train Loss: 0.910, Validation Loss: 1.015, LR: 0.000478 Accuracy: 0.721 \n",
      "\tPrecision | Micro | 0.721 | Macro | 0.554 | Weighted | 0.689 \n",
      "\tRecall    | Micro | 0.721 | Macro | 0.577 | Weighted | 0.684 \n",
      "\tF1        | Micro | 0.721 | Macro | 0.553 | Weighted | 0.721\n",
      "Epoch: 46, Train Loss: 0.892, Validation Loss: 1.007, LR: 0.000478 Accuracy: 0.734 \n",
      "\tPrecision | Micro | 0.734 | Macro | 0.563 | Weighted | 0.698 \n",
      "\tRecall    | Micro | 0.734 | Macro | 0.585 | Weighted | 0.690 \n",
      "\tF1        | Micro | 0.734 | Macro | 0.562 | Weighted | 0.734\n",
      "Epoch: 47, Train Loss: 0.914, Validation Loss: 1.004, LR: 0.000477 Accuracy: 0.734 \n",
      "\tPrecision | Micro | 0.734 | Macro | 0.559 | Weighted | 0.696 \n",
      "\tRecall    | Micro | 0.734 | Macro | 0.584 | Weighted | 0.682 \n",
      "\tF1        | Micro | 0.734 | Macro | 0.561 | Weighted | 0.734\n",
      "Epoch: 48, Train Loss: 0.928, Validation Loss: 1.003, LR: 0.000477 Accuracy: 0.734 \n",
      "\tPrecision | Micro | 0.734 | Macro | 0.552 | Weighted | 0.695 \n",
      "\tRecall    | Micro | 0.734 | Macro | 0.584 | Weighted | 0.673 \n",
      "\tF1        | Micro | 0.734 | Macro | 0.561 | Weighted | 0.734\n",
      "Epoch: 49, Train Loss: 0.923, Validation Loss: 1.013, LR: 0.000476 Accuracy: 0.729 \n",
      "\tPrecision | Micro | 0.729 | Macro | 0.555 | Weighted | 0.689 \n",
      "\tRecall    | Micro | 0.729 | Macro | 0.579 | Weighted | 0.672 \n",
      "\tF1        | Micro | 0.729 | Macro | 0.557 | Weighted | 0.729\n",
      "Epoch: 50, Train Loss: 0.898, Validation Loss: 0.998, LR: 0.000476 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.564 | Weighted | 0.706 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.594 | Weighted | 0.686 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.571 | Weighted | 0.744\n",
      "Epoch: 51, Train Loss: 0.885, Validation Loss: 0.993, LR: 0.000475 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.554 | Weighted | 0.709 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.598 | Weighted | 0.683 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.573 | Weighted | 0.744\n",
      "Epoch: 52, Train Loss: 0.893, Validation Loss: 0.998, LR: 0.000475 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.558 | Weighted | 0.714 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.603 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.577 | Weighted | 0.747\n",
      "Epoch: 53, Train Loss: 0.889, Validation Loss: 0.988, LR: 0.000474 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.562 | Weighted | 0.713 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.602 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.578 | Weighted | 0.749\n",
      "Epoch: 54, Train Loss: 0.915, Validation Loss: 1.001, LR: 0.000474 Accuracy: 0.734 \n",
      "\tPrecision | Micro | 0.734 | Macro | 0.552 | Weighted | 0.696 \n",
      "\tRecall    | Micro | 0.734 | Macro | 0.586 | Weighted | 0.671 \n",
      "\tF1        | Micro | 0.734 | Macro | 0.564 | Weighted | 0.734\n",
      "Epoch: 55, Train Loss: 0.921, Validation Loss: 0.988, LR: 0.000473 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.565 | Weighted | 0.719 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.609 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.584 | Weighted | 0.757\n",
      "Epoch: 56, Train Loss: 0.888, Validation Loss: 0.989, LR: 0.000473 Accuracy: 0.750 \n",
      "\tPrecision | Micro | 0.750 | Macro | 0.556 | Weighted | 0.716 \n",
      "\tRecall    | Micro | 0.750 | Macro | 0.605 | Weighted | 0.686 \n",
      "\tF1        | Micro | 0.750 | Macro | 0.579 | Weighted | 0.750\n",
      "Epoch: 57, Train Loss: 0.907, Validation Loss: 0.993, LR: 0.000472 Accuracy: 0.754 \n",
      "\tPrecision | Micro | 0.754 | Macro | 0.564 | Weighted | 0.716 \n",
      "\tRecall    | Micro | 0.754 | Macro | 0.606 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.754 | Macro | 0.582 | Weighted | 0.754\n",
      "Epoch: 58, Train Loss: 0.899, Validation Loss: 0.990, LR: 0.000472 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.552 | Weighted | 0.715 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.606 | Weighted | 0.685 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.578 | Weighted | 0.749\n",
      "Epoch: 59, Train Loss: 0.913, Validation Loss: 1.022, LR: 0.000471 Accuracy: 0.723 \n",
      "\tPrecision | Micro | 0.723 | Macro | 0.542 | Weighted | 0.696 \n",
      "\tRecall    | Micro | 0.723 | Macro | 0.592 | Weighted | 0.680 \n",
      "\tF1        | Micro | 0.723 | Macro | 0.562 | Weighted | 0.723\n",
      "Epoch: 60, Train Loss: 0.893, Validation Loss: 0.988, LR: 0.000471 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.553 | Weighted | 0.716 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.606 | Weighted | 0.686 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.578 | Weighted | 0.749\n",
      "Epoch: 61, Train Loss: 0.891, Validation Loss: 0.983, LR: 0.000470 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.560 | Weighted | 0.722 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.611 | Weighted | 0.691 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.584 | Weighted | 0.757\n",
      "Epoch: 62, Train Loss: 0.886, Validation Loss: 0.983, LR: 0.000470 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.567 | Weighted | 0.726 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.614 | Weighted | 0.697 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.588 | Weighted | 0.762\n",
      "Epoch: 63, Train Loss: 0.885, Validation Loss: 0.983, LR: 0.000469 Accuracy: 0.765 \n",
      "\tPrecision | Micro | 0.765 | Macro | 0.575 | Weighted | 0.730 \n",
      "\tRecall    | Micro | 0.765 | Macro | 0.616 | Weighted | 0.704 \n",
      "\tF1        | Micro | 0.765 | Macro | 0.591 | Weighted | 0.765\n",
      "Epoch: 64, Train Loss: 0.893, Validation Loss: 0.988, LR: 0.000469 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.567 | Weighted | 0.720 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.608 | Weighted | 0.693 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.584 | Weighted | 0.757\n",
      "Epoch: 65, Train Loss: 0.881, Validation Loss: 0.985, LR: 0.000469 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.567 | Weighted | 0.720 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.607 | Weighted | 0.693 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.583 | Weighted | 0.755\n",
      "Epoch: 66, Train Loss: 0.883, Validation Loss: 1.012, LR: 0.000468 Accuracy: 0.728 \n",
      "\tPrecision | Micro | 0.728 | Macro | 0.559 | Weighted | 0.690 \n",
      "\tRecall    | Micro | 0.728 | Macro | 0.578 | Weighted | 0.684 \n",
      "\tF1        | Micro | 0.728 | Macro | 0.554 | Weighted | 0.728\n",
      "Epoch: 67, Train Loss: 0.896, Validation Loss: 0.996, LR: 0.000468 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.554 | Weighted | 0.710 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.598 | Weighted | 0.685 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.573 | Weighted | 0.742\n",
      "Epoch: 68, Train Loss: 0.881, Validation Loss: 0.986, LR: 0.000467 Accuracy: 0.754 \n",
      "\tPrecision | Micro | 0.754 | Macro | 0.560 | Weighted | 0.717 \n",
      "\tRecall    | Micro | 0.754 | Macro | 0.606 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.754 | Macro | 0.581 | Weighted | 0.754\n",
      "Epoch: 69, Train Loss: 0.914, Validation Loss: 0.981, LR: 0.000467 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.564 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.692 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.587 | Weighted | 0.760\n",
      "Epoch: 70, Train Loss: 0.935, Validation Loss: 0.993, LR: 0.000466 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.552 | Weighted | 0.711 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.604 | Weighted | 0.680 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.576 | Weighted | 0.747\n",
      "Epoch: 71, Train Loss: 0.896, Validation Loss: 0.995, LR: 0.000466 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.563 | Weighted | 0.710 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.599 | Weighted | 0.685 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.576 | Weighted | 0.747\n",
      "Epoch: 72, Train Loss: 0.915, Validation Loss: 1.000, LR: 0.000465 Accuracy: 0.741 \n",
      "\tPrecision | Micro | 0.741 | Macro | 0.555 | Weighted | 0.702 \n",
      "\tRecall    | Micro | 0.741 | Macro | 0.594 | Weighted | 0.675 \n",
      "\tF1        | Micro | 0.741 | Macro | 0.570 | Weighted | 0.741\n",
      "Epoch: 73, Train Loss: 0.891, Validation Loss: 0.995, LR: 0.000465 Accuracy: 0.749 \n",
      "\tPrecision | Micro | 0.749 | Macro | 0.567 | Weighted | 0.711 \n",
      "\tRecall    | Micro | 0.749 | Macro | 0.599 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.749 | Macro | 0.578 | Weighted | 0.749\n",
      "Epoch: 74, Train Loss: 0.887, Validation Loss: 0.993, LR: 0.000464 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.561 | Weighted | 0.710 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.599 | Weighted | 0.683 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.576 | Weighted | 0.747\n",
      "Epoch: 75, Train Loss: 0.886, Validation Loss: 0.993, LR: 0.000464 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.557 | Weighted | 0.706 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.596 | Weighted | 0.678 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.573 | Weighted | 0.744\n",
      "Epoch: 76, Train Loss: 0.887, Validation Loss: 0.991, LR: 0.000463 Accuracy: 0.750 \n",
      "\tPrecision | Micro | 0.750 | Macro | 0.559 | Weighted | 0.716 \n",
      "\tRecall    | Micro | 0.750 | Macro | 0.604 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.750 | Macro | 0.579 | Weighted | 0.750\n",
      "Epoch: 77, Train Loss: 0.882, Validation Loss: 0.992, LR: 0.000463 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.551 | Weighted | 0.715 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.605 | Weighted | 0.686 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.576 | Weighted | 0.747\n",
      "Epoch: 78, Train Loss: 0.890, Validation Loss: 0.988, LR: 0.000462 Accuracy: 0.750 \n",
      "\tPrecision | Micro | 0.750 | Macro | 0.554 | Weighted | 0.715 \n",
      "\tRecall    | Micro | 0.750 | Macro | 0.606 | Weighted | 0.684 \n",
      "\tF1        | Micro | 0.750 | Macro | 0.579 | Weighted | 0.750\n",
      "Epoch: 79, Train Loss: 0.904, Validation Loss: 0.987, LR: 0.000462 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.563 | Weighted | 0.718 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.607 | Weighted | 0.687 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.583 | Weighted | 0.755\n",
      "Epoch: 80, Train Loss: 0.885, Validation Loss: 0.998, LR: 0.000462 Accuracy: 0.741 \n",
      "\tPrecision | Micro | 0.741 | Macro | 0.557 | Weighted | 0.703 \n",
      "\tRecall    | Micro | 0.741 | Macro | 0.591 | Weighted | 0.679 \n",
      "\tF1        | Micro | 0.741 | Macro | 0.569 | Weighted | 0.741\n",
      "Epoch: 81, Train Loss: 0.881, Validation Loss: 0.996, LR: 0.000461 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.555 | Weighted | 0.706 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.595 | Weighted | 0.678 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.572 | Weighted | 0.742\n",
      "Epoch: 82, Train Loss: 0.883, Validation Loss: 0.999, LR: 0.000461 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.556 | Weighted | 0.704 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.594 | Weighted | 0.677 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.571 | Weighted | 0.742\n",
      "Epoch: 83, Train Loss: 0.883, Validation Loss: 0.997, LR: 0.000460 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.559 | Weighted | 0.710 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.600 | Weighted | 0.681 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.576 | Weighted | 0.747\n",
      "Epoch: 84, Train Loss: 0.881, Validation Loss: 0.994, LR: 0.000460 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.556 | Weighted | 0.707 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.596 | Weighted | 0.678 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.573 | Weighted | 0.744\n",
      "Epoch: 85, Train Loss: 0.887, Validation Loss: 0.991, LR: 0.000459 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.549 | Weighted | 0.707 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.598 | Weighted | 0.676 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.572 | Weighted | 0.742\n",
      "Epoch: 86, Train Loss: 0.894, Validation Loss: 0.992, LR: 0.000459 Accuracy: 0.752 \n",
      "\tPrecision | Micro | 0.752 | Macro | 0.559 | Weighted | 0.718 \n",
      "\tRecall    | Micro | 0.752 | Macro | 0.607 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.752 | Macro | 0.581 | Weighted | 0.752\n",
      "Epoch: 87, Train Loss: 0.882, Validation Loss: 0.994, LR: 0.000458 Accuracy: 0.750 \n",
      "\tPrecision | Micro | 0.750 | Macro | 0.557 | Weighted | 0.719 \n",
      "\tRecall    | Micro | 0.750 | Macro | 0.608 | Weighted | 0.692 \n",
      "\tF1        | Micro | 0.750 | Macro | 0.580 | Weighted | 0.750\n",
      "Epoch: 88, Train Loss: 0.882, Validation Loss: 0.990, LR: 0.000458 Accuracy: 0.752 \n",
      "\tPrecision | Micro | 0.752 | Macro | 0.556 | Weighted | 0.719 \n",
      "\tRecall    | Micro | 0.752 | Macro | 0.609 | Weighted | 0.690 \n",
      "\tF1        | Micro | 0.752 | Macro | 0.581 | Weighted | 0.752\n",
      "Epoch: 89, Train Loss: 0.892, Validation Loss: 1.002, LR: 0.000457 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.550 | Weighted | 0.713 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.603 | Weighted | 0.685 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.574 | Weighted | 0.744\n",
      "Epoch: 90, Train Loss: 0.907, Validation Loss: 0.999, LR: 0.000457 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.552 | Weighted | 0.714 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.605 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.576 | Weighted | 0.744\n",
      "Epoch: 91, Train Loss: 0.887, Validation Loss: 1.014, LR: 0.000456 Accuracy: 0.726 \n",
      "\tPrecision | Micro | 0.726 | Macro | 0.543 | Weighted | 0.699 \n",
      "\tRecall    | Micro | 0.726 | Macro | 0.593 | Weighted | 0.680 \n",
      "\tF1        | Micro | 0.726 | Macro | 0.564 | Weighted | 0.726\n",
      "Epoch: 92, Train Loss: 0.902, Validation Loss: 0.999, LR: 0.000456 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.552 | Weighted | 0.715 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.605 | Weighted | 0.691 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.576 | Weighted | 0.744\n",
      "Epoch: 93, Train Loss: 0.895, Validation Loss: 1.019, LR: 0.000456 Accuracy: 0.724 \n",
      "\tPrecision | Micro | 0.724 | Macro | 0.543 | Weighted | 0.698 \n",
      "\tRecall    | Micro | 0.724 | Macro | 0.594 | Weighted | 0.683 \n",
      "\tF1        | Micro | 0.724 | Macro | 0.563 | Weighted | 0.724\n",
      "Epoch: 94, Train Loss: 0.901, Validation Loss: 1.001, LR: 0.000455 Accuracy: 0.744 \n",
      "\tPrecision | Micro | 0.744 | Macro | 0.553 | Weighted | 0.714 \n",
      "\tRecall    | Micro | 0.744 | Macro | 0.607 | Weighted | 0.693 \n",
      "\tF1        | Micro | 0.744 | Macro | 0.576 | Weighted | 0.744\n",
      "Epoch: 95, Train Loss: 0.879, Validation Loss: 1.000, LR: 0.000455 Accuracy: 0.736 \n",
      "\tPrecision | Micro | 0.736 | Macro | 0.547 | Weighted | 0.705 \n",
      "\tRecall    | Micro | 0.736 | Macro | 0.599 | Weighted | 0.684 \n",
      "\tF1        | Micro | 0.736 | Macro | 0.567 | Weighted | 0.736\n",
      "Epoch: 96, Train Loss: 0.879, Validation Loss: 1.003, LR: 0.000454 Accuracy: 0.739 \n",
      "\tPrecision | Micro | 0.739 | Macro | 0.548 | Weighted | 0.709 \n",
      "\tRecall    | Micro | 0.739 | Macro | 0.602 | Weighted | 0.686 \n",
      "\tF1        | Micro | 0.739 | Macro | 0.572 | Weighted | 0.739\n",
      "Epoch: 97, Train Loss: 0.888, Validation Loss: 0.985, LR: 0.000454 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.560 | Weighted | 0.726 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.694 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 98, Train Loss: 0.879, Validation Loss: 0.980, LR: 0.000453 Accuracy: 0.759 \n",
      "\tPrecision | Micro | 0.759 | Macro | 0.561 | Weighted | 0.722 \n",
      "\tRecall    | Micro | 0.759 | Macro | 0.610 | Weighted | 0.691 \n",
      "\tF1        | Micro | 0.759 | Macro | 0.584 | Weighted | 0.759\n",
      "Epoch: 99, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000453 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.560 | Weighted | 0.721 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.610 | Weighted | 0.690 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.583 | Weighted | 0.757\n",
      "Epoch: 100, Train Loss: 0.879, Validation Loss: 0.982, LR: 0.000452 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.561 | Weighted | 0.719 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.607 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.581 | Weighted | 0.755\n",
      "Epoch: 101, Train Loss: 0.879, Validation Loss: 0.983, LR: 0.000452 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.563 | Weighted | 0.723 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.611 | Weighted | 0.692 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.585 | Weighted | 0.760\n",
      "Epoch: 102, Train Loss: 0.911, Validation Loss: 0.986, LR: 0.000451 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.556 | Weighted | 0.721 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.611 | Weighted | 0.690 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.582 | Weighted | 0.755\n",
      "Epoch: 103, Train Loss: 0.878, Validation Loss: 0.980, LR: 0.000451 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.560 | Weighted | 0.725 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.693 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 104, Train Loss: 0.879, Validation Loss: 0.985, LR: 0.000451 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.559 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.613 | Weighted | 0.695 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.585 | Weighted | 0.757\n",
      "Epoch: 105, Train Loss: 0.879, Validation Loss: 0.993, LR: 0.000450 Accuracy: 0.746 \n",
      "\tPrecision | Micro | 0.746 | Macro | 0.553 | Weighted | 0.714 \n",
      "\tRecall    | Micro | 0.746 | Macro | 0.604 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.746 | Macro | 0.576 | Weighted | 0.746\n",
      "Epoch: 106, Train Loss: 0.891, Validation Loss: 0.983, LR: 0.000450 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.565 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.612 | Weighted | 0.695 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 107, Train Loss: 0.879, Validation Loss: 0.977, LR: 0.000449 Accuracy: 0.767 \n",
      "\tPrecision | Micro | 0.767 | Macro | 0.566 | Weighted | 0.731 \n",
      "\tRecall    | Micro | 0.767 | Macro | 0.618 | Weighted | 0.699 \n",
      "\tF1        | Micro | 0.767 | Macro | 0.591 | Weighted | 0.767\n",
      "Epoch: 108, Train Loss: 0.879, Validation Loss: 0.981, LR: 0.000449 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.558 | Weighted | 0.721 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.609 | Weighted | 0.689 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.582 | Weighted | 0.757\n",
      "Epoch: 109, Train Loss: 0.879, Validation Loss: 0.979, LR: 0.000448 Accuracy: 0.765 \n",
      "\tPrecision | Micro | 0.765 | Macro | 0.564 | Weighted | 0.731 \n",
      "\tRecall    | Micro | 0.765 | Macro | 0.618 | Weighted | 0.700 \n",
      "\tF1        | Micro | 0.765 | Macro | 0.590 | Weighted | 0.765\n",
      "Epoch: 110, Train Loss: 0.892, Validation Loss: 0.982, LR: 0.000448 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.567 | Weighted | 0.728 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.614 | Weighted | 0.699 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.588 | Weighted | 0.763\n",
      "Epoch: 111, Train Loss: 0.881, Validation Loss: 0.984, LR: 0.000447 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.559 | Weighted | 0.722 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.609 | Weighted | 0.691 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.582 | Weighted | 0.757\n",
      "Epoch: 112, Train Loss: 0.878, Validation Loss: 0.980, LR: 0.000447 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.561 | Weighted | 0.726 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.696 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 113, Train Loss: 0.879, Validation Loss: 0.980, LR: 0.000447 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.560 | Weighted | 0.727 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.697 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 114, Train Loss: 0.878, Validation Loss: 0.979, LR: 0.000446 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.563 | Weighted | 0.730 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.618 | Weighted | 0.700 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.589 | Weighted | 0.763\n",
      "Epoch: 115, Train Loss: 0.878, Validation Loss: 0.981, LR: 0.000446 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.562 | Weighted | 0.728 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.616 | Weighted | 0.699 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.587 | Weighted | 0.762\n",
      "Epoch: 116, Train Loss: 0.878, Validation Loss: 0.979, LR: 0.000445 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.561 | Weighted | 0.728 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.616 | Weighted | 0.698 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.587 | Weighted | 0.762\n",
      "Epoch: 117, Train Loss: 0.879, Validation Loss: 0.982, LR: 0.000445 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.561 | Weighted | 0.728 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.616 | Weighted | 0.699 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.587 | Weighted | 0.760\n",
      "Epoch: 118, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000444 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.558 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.613 | Weighted | 0.694 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.584 | Weighted | 0.757\n",
      "Epoch: 119, Train Loss: 0.878, Validation Loss: 0.989, LR: 0.000444 Accuracy: 0.750 \n",
      "\tPrecision | Micro | 0.750 | Macro | 0.554 | Weighted | 0.718 \n",
      "\tRecall    | Micro | 0.750 | Macro | 0.607 | Weighted | 0.690 \n",
      "\tF1        | Micro | 0.750 | Macro | 0.579 | Weighted | 0.750\n",
      "Epoch: 120, Train Loss: 0.878, Validation Loss: 0.985, LR: 0.000443 Accuracy: 0.752 \n",
      "\tPrecision | Micro | 0.752 | Macro | 0.555 | Weighted | 0.720 \n",
      "\tRecall    | Micro | 0.752 | Macro | 0.610 | Weighted | 0.693 \n",
      "\tF1        | Micro | 0.752 | Macro | 0.581 | Weighted | 0.752\n",
      "Epoch: 121, Train Loss: 0.880, Validation Loss: 0.989, LR: 0.000443 Accuracy: 0.757 \n",
      "\tPrecision | Micro | 0.757 | Macro | 0.561 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.757 | Macro | 0.611 | Weighted | 0.697 \n",
      "\tF1        | Micro | 0.757 | Macro | 0.584 | Weighted | 0.757\n",
      "Epoch: 122, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000443 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.563 | Weighted | 0.730 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.618 | Weighted | 0.699 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.589 | Weighted | 0.763\n",
      "Epoch: 123, Train Loss: 0.878, Validation Loss: 0.981, LR: 0.000442 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.559 | Weighted | 0.726 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.613 | Weighted | 0.695 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.585 | Weighted | 0.760\n",
      "Epoch: 124, Train Loss: 0.878, Validation Loss: 0.978, LR: 0.000442 Accuracy: 0.767 \n",
      "\tPrecision | Micro | 0.767 | Macro | 0.566 | Weighted | 0.733 \n",
      "\tRecall    | Micro | 0.767 | Macro | 0.621 | Weighted | 0.703 \n",
      "\tF1        | Micro | 0.767 | Macro | 0.592 | Weighted | 0.767\n",
      "Epoch: 125, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000441 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.562 | Weighted | 0.729 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.617 | Weighted | 0.698 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.588 | Weighted | 0.763\n",
      "Epoch: 126, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000441 Accuracy: 0.759 \n",
      "\tPrecision | Micro | 0.759 | Macro | 0.559 | Weighted | 0.725 \n",
      "\tRecall    | Micro | 0.759 | Macro | 0.614 | Weighted | 0.695 \n",
      "\tF1        | Micro | 0.759 | Macro | 0.585 | Weighted | 0.759\n",
      "Epoch: 127, Train Loss: 0.878, Validation Loss: 0.982, LR: 0.000440 Accuracy: 0.759 \n",
      "\tPrecision | Micro | 0.759 | Macro | 0.559 | Weighted | 0.724 \n",
      "\tRecall    | Micro | 0.759 | Macro | 0.612 | Weighted | 0.692 \n",
      "\tF1        | Micro | 0.759 | Macro | 0.584 | Weighted | 0.759\n",
      "Epoch: 128, Train Loss: 0.877, Validation Loss: 0.984, LR: 0.000440 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.557 | Weighted | 0.723 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.611 | Weighted | 0.694 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.582 | Weighted | 0.755\n",
      "Epoch: 129, Train Loss: 0.877, Validation Loss: 0.981, LR: 0.000439 Accuracy: 0.755 \n",
      "\tPrecision | Micro | 0.755 | Macro | 0.557 | Weighted | 0.723 \n",
      "\tRecall    | Micro | 0.755 | Macro | 0.611 | Weighted | 0.694 \n",
      "\tF1        | Micro | 0.755 | Macro | 0.582 | Weighted | 0.755\n",
      "Epoch: 130, Train Loss: 0.879, Validation Loss: 0.980, LR: 0.000439 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.561 | Weighted | 0.727 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.614 | Weighted | 0.697 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.586 | Weighted | 0.760\n",
      "Epoch: 131, Train Loss: 0.879, Validation Loss: 0.976, LR: 0.000439 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.689 | Weighted | 0.737 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.629 | Weighted | 0.742 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.618 | Weighted | 0.762\n",
      "Epoch: 132, Train Loss: 0.879, Validation Loss: 0.982, LR: 0.000438 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.731 | Weighted | 0.740 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.631 | Weighted | 0.760 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.620 | Weighted | 0.763\n",
      "Epoch: 133, Train Loss: 0.876, Validation Loss: 0.978, LR: 0.000438 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.729 | Weighted | 0.737 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.629 | Weighted | 0.757 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.618 | Weighted | 0.762\n",
      "Epoch: 134, Train Loss: 0.886, Validation Loss: 0.976, LR: 0.000437 Accuracy: 0.763 \n",
      "\tPrecision | Micro | 0.763 | Macro | 0.692 | Weighted | 0.739 \n",
      "\tRecall    | Micro | 0.763 | Macro | 0.631 | Weighted | 0.742 \n",
      "\tF1        | Micro | 0.763 | Macro | 0.625 | Weighted | 0.763\n",
      "Epoch: 135, Train Loss: 0.881, Validation Loss: 0.976, LR: 0.000437 Accuracy: 0.768 \n",
      "\tPrecision | Micro | 0.768 | Macro | 0.712 | Weighted | 0.752 \n",
      "\tRecall    | Micro | 0.768 | Macro | 0.649 | Weighted | 0.756 \n",
      "\tF1        | Micro | 0.768 | Macro | 0.653 | Weighted | 0.768\n",
      "Epoch: 136, Train Loss: 0.879, Validation Loss: 0.975, LR: 0.000436 Accuracy: 0.771 \n",
      "\tPrecision | Micro | 0.771 | Macro | 0.704 | Weighted | 0.754 \n",
      "\tRecall    | Micro | 0.771 | Macro | 0.651 | Weighted | 0.756 \n",
      "\tF1        | Micro | 0.771 | Macro | 0.655 | Weighted | 0.771\n",
      "Epoch: 137, Train Loss: 0.875, Validation Loss: 0.997, LR: 0.000436 Accuracy: 0.747 \n",
      "\tPrecision | Micro | 0.747 | Macro | 0.683 | Weighted | 0.734 \n",
      "\tRecall    | Micro | 0.747 | Macro | 0.632 | Weighted | 0.740 \n",
      "\tF1        | Micro | 0.747 | Macro | 0.632 | Weighted | 0.747\n",
      "Epoch: 138, Train Loss: 0.885, Validation Loss: 0.974, LR: 0.000436 Accuracy: 0.773 \n",
      "\tPrecision | Micro | 0.773 | Macro | 0.695 | Weighted | 0.760 \n",
      "\tRecall    | Micro | 0.773 | Macro | 0.660 | Weighted | 0.759 \n",
      "\tF1        | Micro | 0.773 | Macro | 0.663 | Weighted | 0.773\n",
      "Epoch: 139, Train Loss: 0.898, Validation Loss: 0.983, LR: 0.000435 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.711 | Weighted | 0.738 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.636 | Weighted | 0.745 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.636 | Weighted | 0.760\n",
      "Epoch: 140, Train Loss: 0.872, Validation Loss: 0.969, LR: 0.000435 Accuracy: 0.773 \n",
      "\tPrecision | Micro | 0.773 | Macro | 0.709 | Weighted | 0.759 \n",
      "\tRecall    | Micro | 0.773 | Macro | 0.661 | Weighted | 0.762 \n",
      "\tF1        | Micro | 0.773 | Macro | 0.662 | Weighted | 0.773\n",
      "Epoch: 141, Train Loss: 0.873, Validation Loss: 0.972, LR: 0.000434 Accuracy: 0.771 \n",
      "\tPrecision | Micro | 0.771 | Macro | 0.705 | Weighted | 0.762 \n",
      "\tRecall    | Micro | 0.771 | Macro | 0.670 | Weighted | 0.763 \n",
      "\tF1        | Micro | 0.771 | Macro | 0.675 | Weighted | 0.771\n",
      "Epoch: 142, Train Loss: 0.873, Validation Loss: 0.982, LR: 0.000434 Accuracy: 0.759 \n",
      "\tPrecision | Micro | 0.759 | Macro | 0.704 | Weighted | 0.745 \n",
      "\tRecall    | Micro | 0.759 | Macro | 0.642 | Weighted | 0.756 \n",
      "\tF1        | Micro | 0.759 | Macro | 0.646 | Weighted | 0.759\n",
      "Epoch: 143, Train Loss: 0.865, Validation Loss: 0.967, LR: 0.000433 Accuracy: 0.775 \n",
      "\tPrecision | Micro | 0.775 | Macro | 0.708 | Weighted | 0.766 \n",
      "\tRecall    | Micro | 0.775 | Macro | 0.674 | Weighted | 0.764 \n",
      "\tF1        | Micro | 0.775 | Macro | 0.683 | Weighted | 0.775\n",
      "Epoch: 144, Train Loss: 0.866, Validation Loss: 0.984, LR: 0.000433 Accuracy: 0.752 \n",
      "\tPrecision | Micro | 0.752 | Macro | 0.674 | Weighted | 0.745 \n",
      "\tRecall    | Micro | 0.752 | Macro | 0.651 | Weighted | 0.746 \n",
      "\tF1        | Micro | 0.752 | Macro | 0.656 | Weighted | 0.752\n",
      "Epoch: 145, Train Loss: 0.861, Validation Loss: 0.994, LR: 0.000432 Accuracy: 0.742 \n",
      "\tPrecision | Micro | 0.742 | Macro | 0.668 | Weighted | 0.736 \n",
      "\tRecall    | Micro | 0.742 | Macro | 0.643 | Weighted | 0.740 \n",
      "\tF1        | Micro | 0.742 | Macro | 0.646 | Weighted | 0.742\n",
      "Epoch: 146, Train Loss: 0.870, Validation Loss: 0.968, LR: 0.000432 Accuracy: 0.771 \n",
      "\tPrecision | Micro | 0.771 | Macro | 0.703 | Weighted | 0.756 \n",
      "\tRecall    | Micro | 0.771 | Macro | 0.657 | Weighted | 0.754 \n",
      "\tF1        | Micro | 0.771 | Macro | 0.663 | Weighted | 0.771\n",
      "Epoch: 147, Train Loss: 0.859, Validation Loss: 0.967, LR: 0.000432 Accuracy: 0.781 \n",
      "\tPrecision | Micro | 0.781 | Macro | 0.721 | Weighted | 0.774 \n",
      "\tRecall    | Micro | 0.781 | Macro | 0.685 | Weighted | 0.775 \n",
      "\tF1        | Micro | 0.781 | Macro | 0.692 | Weighted | 0.781\n",
      "Epoch: 148, Train Loss: 0.856, Validation Loss: 0.976, LR: 0.000431 Accuracy: 0.770 \n",
      "\tPrecision | Micro | 0.770 | Macro | 0.721 | Weighted | 0.761 \n",
      "\tRecall    | Micro | 0.770 | Macro | 0.671 | Weighted | 0.765 \n",
      "\tF1        | Micro | 0.770 | Macro | 0.679 | Weighted | 0.770\n",
      "Epoch: 149, Train Loss: 0.857, Validation Loss: 0.985, LR: 0.000431 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.698 | Weighted | 0.751 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.655 | Weighted | 0.756 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.661 | Weighted | 0.760\n",
      "Epoch: 150, Train Loss: 0.862, Validation Loss: 0.980, LR: 0.000430 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.721 | Weighted | 0.742 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.645 | Weighted | 0.748 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.655 | Weighted | 0.760\n",
      "Epoch: 151, Train Loss: 0.870, Validation Loss: 0.966, LR: 0.000430 Accuracy: 0.773 \n",
      "\tPrecision | Micro | 0.773 | Macro | 0.733 | Weighted | 0.760 \n",
      "\tRecall    | Micro | 0.773 | Macro | 0.669 | Weighted | 0.763 \n",
      "\tF1        | Micro | 0.773 | Macro | 0.681 | Weighted | 0.773\n",
      "Epoch: 152, Train Loss: 0.864, Validation Loss: 0.968, LR: 0.000429 Accuracy: 0.771 \n",
      "\tPrecision | Micro | 0.771 | Macro | 0.725 | Weighted | 0.762 \n",
      "\tRecall    | Micro | 0.771 | Macro | 0.678 | Weighted | 0.763 \n",
      "\tF1        | Micro | 0.771 | Macro | 0.689 | Weighted | 0.771\n",
      "Epoch: 153, Train Loss: 0.851, Validation Loss: 0.976, LR: 0.000429 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.683 | Weighted | 0.748 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.656 | Weighted | 0.744 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.663 | Weighted | 0.760\n",
      "Epoch: 154, Train Loss: 0.846, Validation Loss: 0.974, LR: 0.000429 Accuracy: 0.765 \n",
      "\tPrecision | Micro | 0.765 | Macro | 0.698 | Weighted | 0.755 \n",
      "\tRecall    | Micro | 0.765 | Macro | 0.666 | Weighted | 0.752 \n",
      "\tF1        | Micro | 0.765 | Macro | 0.675 | Weighted | 0.765\n",
      "Epoch: 155, Train Loss: 0.835, Validation Loss: 0.965, LR: 0.000428 Accuracy: 0.776 \n",
      "\tPrecision | Micro | 0.776 | Macro | 0.713 | Weighted | 0.770 \n",
      "\tRecall    | Micro | 0.776 | Macro | 0.690 | Weighted | 0.768 \n",
      "\tF1        | Micro | 0.776 | Macro | 0.697 | Weighted | 0.776\n",
      "Epoch: 156, Train Loss: 0.848, Validation Loss: 0.976, LR: 0.000428 Accuracy: 0.762 \n",
      "\tPrecision | Micro | 0.762 | Macro | 0.696 | Weighted | 0.752 \n",
      "\tRecall    | Micro | 0.762 | Macro | 0.665 | Weighted | 0.750 \n",
      "\tF1        | Micro | 0.762 | Macro | 0.671 | Weighted | 0.762\n",
      "Epoch: 157, Train Loss: 0.855, Validation Loss: 0.969, LR: 0.000427 Accuracy: 0.770 \n",
      "\tPrecision | Micro | 0.770 | Macro | 0.715 | Weighted | 0.763 \n",
      "\tRecall    | Micro | 0.770 | Macro | 0.678 | Weighted | 0.763 \n",
      "\tF1        | Micro | 0.770 | Macro | 0.689 | Weighted | 0.770\n",
      "Epoch: 158, Train Loss: 0.830, Validation Loss: 0.977, LR: 0.000427 Accuracy: 0.760 \n",
      "\tPrecision | Micro | 0.760 | Macro | 0.693 | Weighted | 0.760 \n",
      "\tRecall    | Micro | 0.760 | Macro | 0.686 | Weighted | 0.761 \n",
      "\tF1        | Micro | 0.760 | Macro | 0.689 | Weighted | 0.760\n",
      "Epoch: 159, Train Loss: 0.829, Validation Loss: 0.964, LR: 0.000426 Accuracy: 0.773 \n",
      "\tPrecision | Micro | 0.773 | Macro | 0.735 | Weighted | 0.763 \n",
      "\tRecall    | Micro | 0.773 | Macro | 0.677 | Weighted | 0.765 \n",
      "\tF1        | Micro | 0.773 | Macro | 0.691 | Weighted | 0.773\n",
      "Epoch: 160, Train Loss: 0.827, Validation Loss: 0.971, LR: 0.000426 Accuracy: 0.770 \n",
      "\tPrecision | Micro | 0.770 | Macro | 0.721 | Weighted | 0.767 \n",
      "\tRecall    | Micro | 0.770 | Macro | 0.690 | Weighted | 0.768 \n",
      "\tF1        | Micro | 0.770 | Macro | 0.699 | Weighted | 0.770\n",
      "Epoch: 161, Train Loss: 0.824, Validation Loss: 0.958, LR: 0.000426 Accuracy: 0.784 \n",
      "\tPrecision | Micro | 0.784 | Macro | 0.760 | Weighted | 0.780 \n",
      "\tRecall    | Micro | 0.784 | Macro | 0.708 | Weighted | 0.784 \n",
      "\tF1        | Micro | 0.784 | Macro | 0.724 | Weighted | 0.784\n",
      "Epoch: 162, Train Loss: 0.829, Validation Loss: 0.962, LR: 0.000425 Accuracy: 0.778 \n",
      "\tPrecision | Micro | 0.778 | Macro | 0.723 | Weighted | 0.777 \n",
      "\tRecall    | Micro | 0.778 | Macro | 0.716 | Weighted | 0.778 \n",
      "\tF1        | Micro | 0.778 | Macro | 0.719 | Weighted | 0.778\n",
      "Epoch: 163, Train Loss: 0.827, Validation Loss: 0.956, LR: 0.000425 Accuracy: 0.776 \n",
      "\tPrecision | Micro | 0.776 | Macro | 0.729 | Weighted | 0.769 \n",
      "\tRecall    | Micro | 0.776 | Macro | 0.693 | Weighted | 0.768 \n",
      "\tF1        | Micro | 0.776 | Macro | 0.705 | Weighted | 0.776\n",
      "Epoch: 164, Train Loss: 0.825, Validation Loss: 0.960, LR: 0.000424 Accuracy: 0.781 \n",
      "\tPrecision | Micro | 0.781 | Macro | 0.740 | Weighted | 0.771 \n",
      "\tRecall    | Micro | 0.781 | Macro | 0.685 | Weighted | 0.774 \n",
      "\tF1        | Micro | 0.781 | Macro | 0.698 | Weighted | 0.781\n",
      "Epoch: 165, Train Loss: 0.826, Validation Loss: 0.946, LR: 0.000424 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.755 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.730 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.740 | Weighted | 0.797\n",
      "Epoch: 166, Train Loss: 0.814, Validation Loss: 0.953, LR: 0.000423 Accuracy: 0.786 \n",
      "\tPrecision | Micro | 0.786 | Macro | 0.733 | Weighted | 0.785 \n",
      "\tRecall    | Micro | 0.786 | Macro | 0.735 | Weighted | 0.785 \n",
      "\tF1        | Micro | 0.786 | Macro | 0.734 | Weighted | 0.786\n",
      "Epoch: 167, Train Loss: 0.811, Validation Loss: 0.950, LR: 0.000423 Accuracy: 0.793 \n",
      "\tPrecision | Micro | 0.793 | Macro | 0.758 | Weighted | 0.786 \n",
      "\tRecall    | Micro | 0.793 | Macro | 0.717 | Weighted | 0.786 \n",
      "\tF1        | Micro | 0.793 | Macro | 0.732 | Weighted | 0.793\n",
      "Epoch: 168, Train Loss: 0.811, Validation Loss: 0.947, LR: 0.000423 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.774 | Weighted | 0.791 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.722 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.739 | Weighted | 0.797\n",
      "Epoch: 169, Train Loss: 0.811, Validation Loss: 0.945, LR: 0.000422 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.763 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.731 | Weighted | 0.791 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.743 | Weighted | 0.796\n",
      "Epoch: 170, Train Loss: 0.810, Validation Loss: 0.946, LR: 0.000422 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.758 | Weighted | 0.790 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.721 | Weighted | 0.789 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.734 | Weighted | 0.796\n",
      "Epoch: 171, Train Loss: 0.810, Validation Loss: 0.942, LR: 0.000421 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.765 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.732 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.745 | Weighted | 0.802\n",
      "Epoch: 172, Train Loss: 0.809, Validation Loss: 0.949, LR: 0.000421 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.750 | Weighted | 0.783 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.731 | Weighted | 0.783 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.738 | Weighted | 0.788\n",
      "Epoch: 173, Train Loss: 0.806, Validation Loss: 0.932, LR: 0.000421 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 174, Train Loss: 0.807, Validation Loss: 0.940, LR: 0.000420 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.762 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.730 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.742 | Weighted | 0.797\n",
      "Epoch: 175, Train Loss: 0.808, Validation Loss: 0.945, LR: 0.000420 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.764 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.723 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.737 | Weighted | 0.799\n",
      "Epoch: 176, Train Loss: 0.820, Validation Loss: 0.952, LR: 0.000419 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.772 | Weighted | 0.787 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.713 | Weighted | 0.791 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.731 | Weighted | 0.794\n",
      "Epoch: 177, Train Loss: 0.802, Validation Loss: 0.943, LR: 0.000419 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.762 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.765 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.760 | Weighted | 0.797\n",
      "Epoch: 178, Train Loss: 0.797, Validation Loss: 0.944, LR: 0.000418 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.767 | Weighted | 0.790 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.734 | Weighted | 0.791 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.746 | Weighted | 0.796\n",
      "Epoch: 179, Train Loss: 0.791, Validation Loss: 0.942, LR: 0.000418 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.757 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.756 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.756 | Weighted | 0.794\n",
      "Epoch: 180, Train Loss: 0.786, Validation Loss: 0.936, LR: 0.000418 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.808 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.753 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 181, Train Loss: 0.785, Validation Loss: 0.939, LR: 0.000417 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 182, Train Loss: 0.786, Validation Loss: 0.935, LR: 0.000417 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.798 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 183, Train Loss: 0.785, Validation Loss: 0.941, LR: 0.000416 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.779 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.762 | Weighted | 0.799\n",
      "Epoch: 184, Train Loss: 0.786, Validation Loss: 0.931, LR: 0.000416 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 185, Train Loss: 0.785, Validation Loss: 0.937, LR: 0.000416 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.771 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 186, Train Loss: 0.785, Validation Loss: 0.935, LR: 0.000415 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.767 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 187, Train Loss: 0.785, Validation Loss: 0.934, LR: 0.000415 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.770 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.761 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.765 | Weighted | 0.804\n",
      "Epoch: 188, Train Loss: 0.785, Validation Loss: 0.937, LR: 0.000414 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.773 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 189, Train Loss: 0.785, Validation Loss: 0.943, LR: 0.000414 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.771 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.760 | Weighted | 0.796\n",
      "Epoch: 190, Train Loss: 0.785, Validation Loss: 0.938, LR: 0.000413 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.768 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.757 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.762 | Weighted | 0.797\n",
      "Epoch: 191, Train Loss: 0.785, Validation Loss: 0.934, LR: 0.000413 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.744 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.755 | Weighted | 0.801\n",
      "Epoch: 192, Train Loss: 0.785, Validation Loss: 0.937, LR: 0.000413 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 193, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000412 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.761 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.748 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.754 | Weighted | 0.799\n",
      "Epoch: 194, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000412 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.765 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.759 | Weighted | 0.806\n",
      "Epoch: 195, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000411 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.770 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 196, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000411 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.760 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.765 | Weighted | 0.804\n",
      "Epoch: 197, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000411 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 198, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000410 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.778 | Weighted | 0.809\n",
      "Epoch: 199, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000410 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 200, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000409 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 201, Train Loss: 0.785, Validation Loss: 0.936, LR: 0.000409 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.775 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 202, Train Loss: 0.785, Validation Loss: 0.931, LR: 0.000409 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 203, Train Loss: 0.785, Validation Loss: 0.930, LR: 0.000408 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 204, Train Loss: 0.784, Validation Loss: 0.928, LR: 0.000408 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 205, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000407 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.770 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 206, Train Loss: 0.784, Validation Loss: 0.965, LR: 0.000407 Accuracy: 0.780 \n",
      "\tPrecision | Micro | 0.780 | Macro | 0.741 | Weighted | 0.782 \n",
      "\tRecall    | Micro | 0.780 | Macro | 0.744 | Weighted | 0.787 \n",
      "\tF1        | Micro | 0.780 | Macro | 0.741 | Weighted | 0.780\n",
      "Epoch: 207, Train Loss: 0.787, Validation Loss: 0.957, LR: 0.000406 Accuracy: 0.780 \n",
      "\tPrecision | Micro | 0.780 | Macro | 0.767 | Weighted | 0.775 \n",
      "\tRecall    | Micro | 0.780 | Macro | 0.706 | Weighted | 0.779 \n",
      "\tF1        | Micro | 0.780 | Macro | 0.724 | Weighted | 0.780\n",
      "Epoch: 208, Train Loss: 0.786, Validation Loss: 0.949, LR: 0.000406 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.778 | Weighted | 0.790 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.738 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.752 | Weighted | 0.794\n",
      "Epoch: 209, Train Loss: 0.785, Validation Loss: 0.944, LR: 0.000406 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.777 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.746 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.758 | Weighted | 0.799\n",
      "Epoch: 210, Train Loss: 0.793, Validation Loss: 0.944, LR: 0.000405 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.774 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.761 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.766 | Weighted | 0.799\n",
      "Epoch: 211, Train Loss: 0.784, Validation Loss: 0.938, LR: 0.000405 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.749 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.759 | Weighted | 0.809\n",
      "Epoch: 212, Train Loss: 0.788, Validation Loss: 0.935, LR: 0.000404 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.793 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.746 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.763 | Weighted | 0.809\n",
      "Epoch: 213, Train Loss: 0.785, Validation Loss: 0.935, LR: 0.000404 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 214, Train Loss: 0.785, Validation Loss: 0.936, LR: 0.000404 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.776 | Weighted | 0.795 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.738 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.752 | Weighted | 0.799\n",
      "Epoch: 215, Train Loss: 0.785, Validation Loss: 0.924, LR: 0.000403 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 216, Train Loss: 0.797, Validation Loss: 0.929, LR: 0.000403 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 217, Train Loss: 0.785, Validation Loss: 0.926, LR: 0.000402 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 218, Train Loss: 0.784, Validation Loss: 0.926, LR: 0.000402 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 219, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000402 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.777 | Weighted | 0.809\n",
      "Epoch: 220, Train Loss: 0.784, Validation Loss: 0.928, LR: 0.000401 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 221, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000401 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.771 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.762 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.765 | Weighted | 0.804\n",
      "Epoch: 222, Train Loss: 0.785, Validation Loss: 0.929, LR: 0.000400 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.773 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 223, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000400 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.778 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 224, Train Loss: 0.785, Validation Loss: 0.928, LR: 0.000400 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 225, Train Loss: 0.784, Validation Loss: 0.924, LR: 0.000399 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.791 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822\n",
      "Epoch: 226, Train Loss: 0.784, Validation Loss: 0.926, LR: 0.000399 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.786 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 227, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000398 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.783 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 228, Train Loss: 0.784, Validation Loss: 0.926, LR: 0.000398 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 229, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000398 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.790 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 230, Train Loss: 0.785, Validation Loss: 0.943, LR: 0.000397 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.768 | Weighted | 0.791 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.734 | Weighted | 0.791 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.746 | Weighted | 0.796\n",
      "Epoch: 231, Train Loss: 0.785, Validation Loss: 0.923, LR: 0.000397 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.780 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 232, Train Loss: 0.836, Validation Loss: 0.952, LR: 0.000396 Accuracy: 0.789 \n",
      "\tPrecision | Micro | 0.789 | Macro | 0.785 | Weighted | 0.784 \n",
      "\tRecall    | Micro | 0.789 | Macro | 0.731 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.789 | Macro | 0.747 | Weighted | 0.789\n",
      "Epoch: 233, Train Loss: 0.804, Validation Loss: 0.951, LR: 0.000396 Accuracy: 0.793 \n",
      "\tPrecision | Micro | 0.793 | Macro | 0.774 | Weighted | 0.784 \n",
      "\tRecall    | Micro | 0.793 | Macro | 0.713 | Weighted | 0.787 \n",
      "\tF1        | Micro | 0.793 | Macro | 0.732 | Weighted | 0.793\n",
      "Epoch: 234, Train Loss: 0.794, Validation Loss: 0.939, LR: 0.000396 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.765 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.758 | Weighted | 0.804\n",
      "Epoch: 235, Train Loss: 0.800, Validation Loss: 0.956, LR: 0.000395 Accuracy: 0.778 \n",
      "\tPrecision | Micro | 0.778 | Macro | 0.759 | Weighted | 0.773 \n",
      "\tRecall    | Micro | 0.778 | Macro | 0.718 | Weighted | 0.777 \n",
      "\tF1        | Micro | 0.778 | Macro | 0.731 | Weighted | 0.778\n",
      "Epoch: 236, Train Loss: 0.784, Validation Loss: 0.946, LR: 0.000395 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.770 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.760 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.764 | Weighted | 0.797\n",
      "Epoch: 237, Train Loss: 0.785, Validation Loss: 0.928, LR: 0.000394 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 238, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000394 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.777 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 239, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000394 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.746 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.758 | Weighted | 0.804\n",
      "Epoch: 240, Train Loss: 0.786, Validation Loss: 0.934, LR: 0.000393 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 241, Train Loss: 0.792, Validation Loss: 0.931, LR: 0.000393 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 242, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000392 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 243, Train Loss: 0.785, Validation Loss: 0.937, LR: 0.000392 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.758 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.770 | Weighted | 0.804\n",
      "Epoch: 244, Train Loss: 0.786, Validation Loss: 0.942, LR: 0.000392 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.766 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.748 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.755 | Weighted | 0.799\n",
      "Epoch: 245, Train Loss: 0.785, Validation Loss: 0.939, LR: 0.000391 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.764 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 246, Train Loss: 0.794, Validation Loss: 0.944, LR: 0.000391 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.785 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.759 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.769 | Weighted | 0.802\n",
      "Epoch: 247, Train Loss: 0.785, Validation Loss: 0.942, LR: 0.000391 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.792 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.771 | Weighted | 0.804\n",
      "Epoch: 248, Train Loss: 0.790, Validation Loss: 0.954, LR: 0.000390 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.790 | Weighted | 0.780 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.707 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.726 | Weighted | 0.788\n",
      "Epoch: 249, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000390 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.786 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.749 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 250, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000389 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.778 | Weighted | 0.795 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.739 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.754 | Weighted | 0.801\n",
      "Epoch: 251, Train Loss: 0.784, Validation Loss: 0.942, LR: 0.000389 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.786 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.750 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 252, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000389 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.764 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 253, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000388 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.774 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 254, Train Loss: 0.785, Validation Loss: 0.928, LR: 0.000388 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 255, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000387 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.786 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.777 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 256, Train Loss: 0.784, Validation Loss: 0.925, LR: 0.000387 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.804 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 257, Train Loss: 0.785, Validation Loss: 0.931, LR: 0.000387 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.776 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.767 | Weighted | 0.804\n",
      "Epoch: 258, Train Loss: 0.784, Validation Loss: 0.938, LR: 0.000386 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.758 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 259, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000386 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.753 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 260, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000385 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.781 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.756 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 261, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000385 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.780 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.753 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 262, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000385 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.782 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.750 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.763 | Weighted | 0.804\n",
      "Epoch: 263, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000384 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.774 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 264, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000384 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.775 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 265, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000384 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.781 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.756 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 266, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000383 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 267, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000383 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 268, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000382 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 269, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000382 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 270, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000382 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 271, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000381 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 272, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000381 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 273, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000380 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 274, Train Loss: 0.785, Validation Loss: 0.937, LR: 0.000380 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.767 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.760 | Weighted | 0.806\n",
      "Epoch: 275, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000380 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.771 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 276, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000379 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.767 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.759 | Weighted | 0.806\n",
      "Epoch: 277, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000379 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.780 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.745 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.759 | Weighted | 0.804\n",
      "Epoch: 278, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000379 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 279, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000378 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 280, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000378 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 281, Train Loss: 0.784, Validation Loss: 0.928, LR: 0.000377 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 282, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000377 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 283, Train Loss: 0.784, Validation Loss: 0.939, LR: 0.000377 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.791 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.739 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.757 | Weighted | 0.801\n",
      "Epoch: 284, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000376 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.786 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 285, Train Loss: 0.783, Validation Loss: 0.938, LR: 0.000376 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.748 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 286, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000376 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.786 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.745 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.761 | Weighted | 0.807\n",
      "Epoch: 287, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000375 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 288, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000375 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 289, Train Loss: 0.784, Validation Loss: 0.949, LR: 0.000374 Accuracy: 0.793 \n",
      "\tPrecision | Micro | 0.793 | Macro | 0.782 | Weighted | 0.786 \n",
      "\tRecall    | Micro | 0.793 | Macro | 0.731 | Weighted | 0.789 \n",
      "\tF1        | Micro | 0.793 | Macro | 0.748 | Weighted | 0.793\n",
      "Epoch: 290, Train Loss: 0.794, Validation Loss: 0.935, LR: 0.000374 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.756 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 291, Train Loss: 0.806, Validation Loss: 0.948, LR: 0.000374 Accuracy: 0.793 \n",
      "\tPrecision | Micro | 0.793 | Macro | 0.798 | Weighted | 0.785 \n",
      "\tRecall    | Micro | 0.793 | Macro | 0.723 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.793 | Macro | 0.747 | Weighted | 0.793\n",
      "Epoch: 292, Train Loss: 0.803, Validation Loss: 0.956, LR: 0.000373 Accuracy: 0.783 \n",
      "\tPrecision | Micro | 0.783 | Macro | 0.760 | Weighted | 0.777 \n",
      "\tRecall    | Micro | 0.783 | Macro | 0.752 | Weighted | 0.786 \n",
      "\tF1        | Micro | 0.783 | Macro | 0.750 | Weighted | 0.783\n",
      "Epoch: 293, Train Loss: 0.791, Validation Loss: 0.949, LR: 0.000373 Accuracy: 0.791 \n",
      "\tPrecision | Micro | 0.791 | Macro | 0.787 | Weighted | 0.784 \n",
      "\tRecall    | Micro | 0.791 | Macro | 0.719 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.791 | Macro | 0.739 | Weighted | 0.791\n",
      "Epoch: 294, Train Loss: 0.789, Validation Loss: 0.955, LR: 0.000373 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.764 | Weighted | 0.787 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.736 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.746 | Weighted | 0.788\n",
      "Epoch: 295, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000372 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 296, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000372 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.757 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.765 | Weighted | 0.801\n",
      "Epoch: 297, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000371 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 298, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000371 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.771 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.779 | Weighted | 0.806\n",
      "Epoch: 299, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000371 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 300, Train Loss: 0.784, Validation Loss: 0.924, LR: 0.000370 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 301, Train Loss: 0.784, Validation Loss: 0.924, LR: 0.000370 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 302, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000370 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.779 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.748 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.760 | Weighted | 0.804\n",
      "Epoch: 303, Train Loss: 0.786, Validation Loss: 0.930, LR: 0.000369 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 304, Train Loss: 0.784, Validation Loss: 0.939, LR: 0.000369 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.793 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.774 | Weighted | 0.801\n",
      "Epoch: 305, Train Loss: 0.784, Validation Loss: 0.942, LR: 0.000369 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.758 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.762 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.760 | Weighted | 0.797\n",
      "Epoch: 306, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000368 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 307, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000368 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.780 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.770 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 308, Train Loss: 0.783, Validation Loss: 0.941, LR: 0.000367 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.776 | Weighted | 0.795 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.754 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.763 | Weighted | 0.799\n",
      "Epoch: 309, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000367 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 310, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000367 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.768 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 311, Train Loss: 0.790, Validation Loss: 0.942, LR: 0.000366 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.779 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.748 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.760 | Weighted | 0.797\n",
      "Epoch: 312, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000366 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.779 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.746 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.758 | Weighted | 0.797\n",
      "Epoch: 313, Train Loss: 0.784, Validation Loss: 0.943, LR: 0.000366 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.792 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.742 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.759 | Weighted | 0.794\n",
      "Epoch: 314, Train Loss: 0.784, Validation Loss: 0.923, LR: 0.000365 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 315, Train Loss: 0.784, Validation Loss: 0.925, LR: 0.000365 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 316, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000364 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 317, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000364 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.772 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.759 | Weighted | 0.802\n",
      "Epoch: 318, Train Loss: 0.785, Validation Loss: 0.939, LR: 0.000364 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.803 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.742 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 319, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000363 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.784 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.751 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.764 | Weighted | 0.797\n",
      "Epoch: 320, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000363 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.776 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 321, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000363 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 322, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000362 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 323, Train Loss: 0.784, Validation Loss: 0.926, LR: 0.000362 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 324, Train Loss: 0.784, Validation Loss: 0.928, LR: 0.000362 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 325, Train Loss: 0.784, Validation Loss: 0.926, LR: 0.000361 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 326, Train Loss: 0.784, Validation Loss: 0.925, LR: 0.000361 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 327, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000360 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 328, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000360 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.774 | Weighted | 0.815\n",
      "Epoch: 329, Train Loss: 0.784, Validation Loss: 0.927, LR: 0.000360 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 330, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000359 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.802 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 331, Train Loss: 0.784, Validation Loss: 0.924, LR: 0.000359 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.783 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.787 | Weighted | 0.823\n",
      "Epoch: 332, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000359 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.769 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 333, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000358 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 334, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000358 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 335, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000358 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 336, Train Loss: 0.788, Validation Loss: 0.949, LR: 0.000357 Accuracy: 0.789 \n",
      "\tPrecision | Micro | 0.789 | Macro | 0.758 | Weighted | 0.785 \n",
      "\tRecall    | Micro | 0.789 | Macro | 0.754 | Weighted | 0.788 \n",
      "\tF1        | Micro | 0.789 | Macro | 0.753 | Weighted | 0.789\n",
      "Epoch: 337, Train Loss: 0.784, Validation Loss: 0.955, LR: 0.000357 Accuracy: 0.784 \n",
      "\tPrecision | Micro | 0.784 | Macro | 0.776 | Weighted | 0.777 \n",
      "\tRecall    | Micro | 0.784 | Macro | 0.726 | Weighted | 0.783 \n",
      "\tF1        | Micro | 0.784 | Macro | 0.742 | Weighted | 0.784\n",
      "Epoch: 338, Train Loss: 0.784, Validation Loss: 0.941, LR: 0.000357 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.753 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 339, Train Loss: 0.786, Validation Loss: 0.939, LR: 0.000356 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.764 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.768 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 340, Train Loss: 0.784, Validation Loss: 0.951, LR: 0.000356 Accuracy: 0.786 \n",
      "\tPrecision | Micro | 0.786 | Macro | 0.770 | Weighted | 0.780 \n",
      "\tRecall    | Micro | 0.786 | Macro | 0.708 | Weighted | 0.785 \n",
      "\tF1        | Micro | 0.786 | Macro | 0.725 | Weighted | 0.786\n",
      "Epoch: 341, Train Loss: 0.784, Validation Loss: 0.941, LR: 0.000355 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.770 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.765 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.768 | Weighted | 0.799\n",
      "Epoch: 342, Train Loss: 0.784, Validation Loss: 0.942, LR: 0.000355 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.776 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.750 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 343, Train Loss: 0.784, Validation Loss: 0.938, LR: 0.000355 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.771 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 344, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000354 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.774 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 345, Train Loss: 0.783, Validation Loss: 0.938, LR: 0.000354 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.771 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 346, Train Loss: 0.784, Validation Loss: 0.952, LR: 0.000354 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.747 | Weighted | 0.790 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.762 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.753 | Weighted | 0.788\n",
      "Epoch: 347, Train Loss: 0.783, Validation Loss: 0.943, LR: 0.000353 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.761 | Weighted | 0.791 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.735 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.745 | Weighted | 0.796\n",
      "Epoch: 348, Train Loss: 0.783, Validation Loss: 0.944, LR: 0.000353 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.764 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.738 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.748 | Weighted | 0.797\n",
      "Epoch: 349, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000353 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.767 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.757 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 350, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000352 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.774 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 351, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000352 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.770 | Weighted | 0.795 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.743 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.754 | Weighted | 0.799\n",
      "Epoch: 352, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000352 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.773 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 353, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000351 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.761 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 354, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000351 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.768 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 355, Train Loss: 0.783, Validation Loss: 0.939, LR: 0.000351 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.770 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.754 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.760 | Weighted | 0.802\n",
      "Epoch: 356, Train Loss: 0.784, Validation Loss: 0.944, LR: 0.000350 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.760 | Weighted | 0.790 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.737 | Weighted | 0.789 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.747 | Weighted | 0.794\n",
      "Epoch: 357, Train Loss: 0.783, Validation Loss: 0.938, LR: 0.000350 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.772 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.771 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 358, Train Loss: 0.783, Validation Loss: 0.941, LR: 0.000349 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.751 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 359, Train Loss: 0.783, Validation Loss: 0.939, LR: 0.000349 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.774 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.754 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 360, Train Loss: 0.784, Validation Loss: 0.939, LR: 0.000349 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.764 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.758 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.761 | Weighted | 0.799\n",
      "Epoch: 361, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000348 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.780 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.748 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.761 | Weighted | 0.802\n",
      "Epoch: 362, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000348 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.773 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.757 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 363, Train Loss: 0.784, Validation Loss: 0.941, LR: 0.000348 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.770 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.746 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.756 | Weighted | 0.801\n",
      "Epoch: 364, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000347 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.777 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 365, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000347 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 366, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000347 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.764 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.771 | Weighted | 0.804\n",
      "Epoch: 367, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000346 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 368, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000346 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.768 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.757 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.761 | Weighted | 0.804\n",
      "Epoch: 369, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000346 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 370, Train Loss: 0.783, Validation Loss: 0.940, LR: 0.000345 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.780 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.741 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.756 | Weighted | 0.801\n",
      "Epoch: 371, Train Loss: 0.784, Validation Loss: 0.948, LR: 0.000345 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.756 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.739 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.747 | Weighted | 0.794\n",
      "Epoch: 372, Train Loss: 0.786, Validation Loss: 0.947, LR: 0.000345 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.774 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.764 | Weighted | 0.796\n",
      "Epoch: 373, Train Loss: 0.810, Validation Loss: 0.951, LR: 0.000344 Accuracy: 0.791 \n",
      "\tPrecision | Micro | 0.791 | Macro | 0.786 | Weighted | 0.785 \n",
      "\tRecall    | Micro | 0.791 | Macro | 0.739 | Weighted | 0.789 \n",
      "\tF1        | Micro | 0.791 | Macro | 0.756 | Weighted | 0.791\n",
      "Epoch: 374, Train Loss: 0.813, Validation Loss: 0.938, LR: 0.000344 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.776 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.776 | Weighted | 0.801\n",
      "Epoch: 375, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000344 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 376, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000343 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 377, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000343 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.778 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.787 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.781 | Weighted | 0.818\n",
      "Epoch: 378, Train Loss: 0.785, Validation Loss: 0.930, LR: 0.000343 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 379, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000342 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 380, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000342 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 381, Train Loss: 0.785, Validation Loss: 0.930, LR: 0.000342 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 382, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000341 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.756 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 383, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000341 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.756 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 384, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000341 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.764 | Weighted | 0.809\n",
      "Epoch: 385, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000340 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 386, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000340 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.775 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 387, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000339 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.764 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.760 | Weighted | 0.806\n",
      "Epoch: 388, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000339 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 389, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000339 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 390, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000338 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 391, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000338 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.765 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.763 | Weighted | 0.807\n",
      "Epoch: 392, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000338 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 393, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000337 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 394, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000337 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 395, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000337 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.762 | Weighted | 0.806\n",
      "Epoch: 396, Train Loss: 0.783, Validation Loss: 0.939, LR: 0.000336 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.766 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.744 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.753 | Weighted | 0.797\n",
      "Epoch: 397, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000336 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 398, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000336 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 399, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000335 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 400, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000335 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 401, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000335 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 402, Train Loss: 0.784, Validation Loss: 0.931, LR: 0.000334 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 403, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000334 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.756 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.765 | Weighted | 0.807\n",
      "Epoch: 404, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000334 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 405, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000333 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 406, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000333 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 407, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000333 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.762 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.763 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 408, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000332 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 409, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000332 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 410, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000332 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 411, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000331 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.767 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.751 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.758 | Weighted | 0.802\n",
      "Epoch: 412, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000331 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 413, Train Loss: 0.784, Validation Loss: 0.938, LR: 0.000331 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.769 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.749 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.757 | Weighted | 0.801\n",
      "Epoch: 414, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000330 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.768 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 415, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000330 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 416, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000330 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 417, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000329 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.778 | Weighted | 0.817\n",
      "Epoch: 418, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000329 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 419, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000329 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 420, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000328 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.789 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 421, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000328 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 422, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000328 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 423, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000327 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.769 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.769 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 424, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000327 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.768 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.763 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 425, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000327 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.778 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 426, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000326 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 427, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000326 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 428, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000326 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 429, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000326 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 430, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000325 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 431, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000325 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 432, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000325 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.769 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.761 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 433, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000324 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.787 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.764 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 434, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000324 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 435, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000324 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 436, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000323 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 437, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000323 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 438, Train Loss: 0.783, Validation Loss: 0.938, LR: 0.000323 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.759 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.764 | Weighted | 0.801\n",
      "Epoch: 439, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000322 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 440, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000322 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 441, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000322 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.772 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 442, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000321 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.774 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 443, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000321 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 444, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000321 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.790 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.740 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.757 | Weighted | 0.807\n",
      "Epoch: 445, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000320 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 446, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000320 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.765 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 447, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000320 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.774 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 448, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000319 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.773 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.765 | Weighted | 0.807\n",
      "Epoch: 449, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000319 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.761 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.767 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 450, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000319 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.764 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 451, Train Loss: 0.809, Validation Loss: 0.954, LR: 0.000318 Accuracy: 0.783 \n",
      "\tPrecision | Micro | 0.783 | Macro | 0.741 | Weighted | 0.780 \n",
      "\tRecall    | Micro | 0.783 | Macro | 0.763 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.783 | Macro | 0.744 | Weighted | 0.783\n",
      "Epoch: 452, Train Loss: 0.788, Validation Loss: 0.959, LR: 0.000318 Accuracy: 0.783 \n",
      "\tPrecision | Micro | 0.783 | Macro | 0.771 | Weighted | 0.774 \n",
      "\tRecall    | Micro | 0.783 | Macro | 0.702 | Weighted | 0.781 \n",
      "\tF1        | Micro | 0.783 | Macro | 0.722 | Weighted | 0.783\n",
      "Epoch: 453, Train Loss: 0.789, Validation Loss: 0.948, LR: 0.000318 Accuracy: 0.791 \n",
      "\tPrecision | Micro | 0.791 | Macro | 0.797 | Weighted | 0.787 \n",
      "\tRecall    | Micro | 0.791 | Macro | 0.723 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.791 | Macro | 0.745 | Weighted | 0.791\n",
      "Epoch: 454, Train Loss: 0.784, Validation Loss: 0.950, LR: 0.000317 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.770 | Weighted | 0.789 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.750 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.757 | Weighted | 0.788\n",
      "Epoch: 455, Train Loss: 0.783, Validation Loss: 0.940, LR: 0.000317 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.788 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.752 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.766 | Weighted | 0.802\n",
      "Epoch: 456, Train Loss: 0.784, Validation Loss: 0.939, LR: 0.000317 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.773 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.757 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.764 | Weighted | 0.799\n",
      "Epoch: 457, Train Loss: 0.785, Validation Loss: 0.936, LR: 0.000317 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 458, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000316 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.804 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 459, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000316 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.775 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.764 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 460, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000316 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.775 | Weighted | 0.807\n",
      "Epoch: 461, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000315 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 462, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000315 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.783 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.765 | Weighted | 0.804\n",
      "Epoch: 463, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000315 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 464, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000314 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 465, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000314 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 466, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000314 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 467, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000313 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.771 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 468, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000313 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 469, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000313 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 470, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000312 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 471, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000312 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 472, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000312 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 473, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000311 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 474, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000311 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 475, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000311 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 476, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000311 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.775 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 477, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000310 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 478, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000310 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 479, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000310 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 480, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000309 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 481, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000309 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.753 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 482, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000309 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 483, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000308 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 484, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000308 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 485, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000308 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 486, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000307 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 487, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000307 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 488, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000307 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 489, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000307 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 490, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000306 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 491, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000306 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 492, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000306 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 493, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000305 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.796 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 494, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000305 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 495, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000305 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 496, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000304 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 497, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000304 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 498, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000304 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 499, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000303 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.778 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 500, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000303 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 501, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000303 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 502, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000303 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.793 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 503, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000302 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 504, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000302 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.778 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 505, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000302 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.771 | Weighted | 0.814\n",
      "Epoch: 506, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000301 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.779 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.782 | Weighted | 0.814\n",
      "Epoch: 507, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000301 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 508, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000301 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.797 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 509, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000300 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 510, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000300 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 511, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000300 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.792 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 512, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000300 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 513, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000299 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.778 | Weighted | 0.810\n",
      "Epoch: 514, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000299 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 515, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000299 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 516, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000298 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 517, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000298 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 518, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000298 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.783 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.746 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.760 | Weighted | 0.804\n",
      "Epoch: 519, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000297 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 520, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000297 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.772 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 521, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000297 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 522, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000297 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 523, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000296 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 524, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000296 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.774 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.762 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 525, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000296 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 526, Train Loss: 0.784, Validation Loss: 0.936, LR: 0.000295 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.752 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 527, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000295 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 528, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000295 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 529, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000295 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.774 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.749 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.759 | Weighted | 0.801\n",
      "Epoch: 530, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000294 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 531, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000294 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 532, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000294 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 533, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000293 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.776 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.777 | Weighted | 0.809\n",
      "Epoch: 534, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000293 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.783 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 535, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000293 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 536, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000292 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.764 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 537, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000292 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.801 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 538, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000292 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 539, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000292 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.776 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.748 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.760 | Weighted | 0.799\n",
      "Epoch: 540, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000291 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 541, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000291 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 542, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000291 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.755 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 543, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000290 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.773 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.772 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 544, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000290 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.776 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.763 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 545, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000290 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.755 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 546, Train Loss: 0.783, Validation Loss: 0.941, LR: 0.000290 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.780 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.753 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.764 | Weighted | 0.801\n",
      "Epoch: 547, Train Loss: 0.783, Validation Loss: 0.949, LR: 0.000289 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.777 | Weighted | 0.789 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.748 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.759 | Weighted | 0.794\n",
      "Epoch: 548, Train Loss: 0.798, Validation Loss: 0.937, LR: 0.000289 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.790 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.735 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.753 | Weighted | 0.804\n",
      "Epoch: 549, Train Loss: 0.784, Validation Loss: 0.943, LR: 0.000289 Accuracy: 0.794 \n",
      "\tPrecision | Micro | 0.794 | Macro | 0.790 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.794 | Macro | 0.742 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.794 | Macro | 0.760 | Weighted | 0.794\n",
      "Epoch: 550, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000288 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.771 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 551, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000288 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 552, Train Loss: 0.784, Validation Loss: 0.934, LR: 0.000288 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.811 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.750 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 553, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000288 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.778 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 554, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000287 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 555, Train Loss: 0.784, Validation Loss: 0.947, LR: 0.000287 Accuracy: 0.788 \n",
      "\tPrecision | Micro | 0.788 | Macro | 0.779 | Weighted | 0.787 \n",
      "\tRecall    | Micro | 0.788 | Macro | 0.739 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.788 | Macro | 0.753 | Weighted | 0.788\n",
      "Epoch: 556, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000287 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 557, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000286 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.753 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 558, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000286 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.791 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.743 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 559, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000286 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 560, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000286 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.786 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 561, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000285 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 562, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000285 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 563, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000285 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.772 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 564, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000284 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.792 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 565, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000284 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.784 | Weighted | 0.817\n",
      "Epoch: 566, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000284 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.782 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 567, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000284 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.801 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 568, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000283 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 569, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000283 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.796 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 570, Train Loss: 0.783, Validation Loss: 0.922, LR: 0.000283 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.801 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 571, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000282 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.798 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 572, Train Loss: 0.783, Validation Loss: 0.922, LR: 0.000282 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.786 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.792 | Weighted | 0.823\n",
      "Epoch: 573, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000282 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.790 | Weighted | 0.820\n",
      "Epoch: 574, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000282 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.803 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.775 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.787 | Weighted | 0.822\n",
      "Epoch: 575, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000281 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.790 | Weighted | 0.820\n",
      "Epoch: 576, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000281 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 577, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000281 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.769 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.782 | Weighted | 0.818\n",
      "Epoch: 578, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000280 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.803 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 579, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000280 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.789 | Weighted | 0.820\n",
      "Epoch: 580, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000280 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 581, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000280 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 582, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000279 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 583, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000279 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.800 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.777 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 584, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000279 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.774 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 585, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000278 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 586, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000278 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 587, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000278 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.777 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 588, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000278 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 589, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000277 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.772 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 590, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000277 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 591, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000277 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.774 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.784 | Weighted | 0.820\n",
      "Epoch: 592, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000277 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.782 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 593, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000276 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.798 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 594, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000276 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 595, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000276 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.756 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 596, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000275 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 597, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000275 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 598, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000275 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.805 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.767 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.782 | Weighted | 0.818\n",
      "Epoch: 599, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000275 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.795 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 600, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000274 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.803 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.782 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 601, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000274 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 602, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000274 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.772 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 603, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000274 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.771 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 604, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000273 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.787 | Weighted | 0.818\n",
      "Epoch: 605, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000273 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.807 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.767 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.783 | Weighted | 0.820\n",
      "Epoch: 606, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000273 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 607, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000272 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.787 | Weighted | 0.818\n",
      "Epoch: 608, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000272 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 609, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000272 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 610, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000272 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 611, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000271 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 612, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000271 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 613, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000271 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.778 | Weighted | 0.810\n",
      "Epoch: 614, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000271 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 615, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000270 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 616, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000270 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.796 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 617, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000270 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.765 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 618, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000269 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 619, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000269 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.790 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 620, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000269 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 621, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000269 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.807 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.770 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 622, Train Loss: 0.794, Validation Loss: 0.953, LR: 0.000268 Accuracy: 0.786 \n",
      "\tPrecision | Micro | 0.786 | Macro | 0.794 | Weighted | 0.779 \n",
      "\tRecall    | Micro | 0.786 | Macro | 0.717 | Weighted | 0.790 \n",
      "\tF1        | Micro | 0.786 | Macro | 0.738 | Weighted | 0.786\n",
      "Epoch: 623, Train Loss: 0.806, Validation Loss: 0.942, LR: 0.000268 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.794 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.748 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.765 | Weighted | 0.796\n",
      "Epoch: 624, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000268 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 625, Train Loss: 0.784, Validation Loss: 0.945, LR: 0.000268 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.781 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.743 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.758 | Weighted | 0.796\n",
      "Epoch: 626, Train Loss: 0.783, Validation Loss: 0.944, LR: 0.000267 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.775 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.728 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.744 | Weighted | 0.797\n",
      "Epoch: 627, Train Loss: 0.783, Validation Loss: 0.938, LR: 0.000267 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.751 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 628, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000267 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.770 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.765 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.767 | Weighted | 0.802\n",
      "Epoch: 629, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000266 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 630, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000266 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.775 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.760 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 631, Train Loss: 0.783, Validation Loss: 0.935, LR: 0.000266 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 632, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000266 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.777 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.763 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 633, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000265 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.786 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 634, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000265 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 635, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000265 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.773 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.755 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 636, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000265 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.764 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 637, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000264 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 638, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000264 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.755 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 639, Train Loss: 0.783, Validation Loss: 0.940, LR: 0.000264 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.806 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.735 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.756 | Weighted | 0.804\n",
      "Epoch: 640, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000264 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 641, Train Loss: 0.784, Validation Loss: 0.932, LR: 0.000263 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 642, Train Loss: 0.787, Validation Loss: 0.944, LR: 0.000263 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.765 | Weighted | 0.791 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.759 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.759 | Weighted | 0.796\n",
      "Epoch: 643, Train Loss: 0.799, Validation Loss: 0.951, LR: 0.000263 Accuracy: 0.786 \n",
      "\tPrecision | Micro | 0.786 | Macro | 0.780 | Weighted | 0.786 \n",
      "\tRecall    | Micro | 0.786 | Macro | 0.729 | Weighted | 0.794 \n",
      "\tF1        | Micro | 0.786 | Macro | 0.745 | Weighted | 0.786\n",
      "Epoch: 644, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000263 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.761 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.775 | Weighted | 0.807\n",
      "Epoch: 645, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000262 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 646, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000262 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.813 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.748 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 647, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000262 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.772 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.778 | Weighted | 0.809\n",
      "Epoch: 648, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000261 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 649, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000261 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.801 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 650, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000261 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 651, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000261 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.758 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 652, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000260 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 653, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000260 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 654, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000260 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 655, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000260 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 656, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000259 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 657, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000259 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 658, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000259 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 659, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000259 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 660, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000258 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 661, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000258 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 662, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000258 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 663, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000258 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 664, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000257 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 665, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000257 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 666, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000257 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 667, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000257 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 668, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000256 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 669, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000256 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 670, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000256 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 671, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000256 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 672, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000255 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.798 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 673, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000255 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 674, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000255 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 675, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000254 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 676, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000254 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 677, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000254 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 678, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000254 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 679, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000253 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.797 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 680, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000253 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 681, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000253 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.798 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 682, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000253 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.755 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 683, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000252 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 684, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000252 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 685, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000252 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 686, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000252 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.799 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 687, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000251 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 688, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000251 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.801 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 689, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000251 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 690, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000251 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 691, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000250 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 692, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000250 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 693, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000250 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.764 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.777 | Weighted | 0.817\n",
      "Epoch: 694, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000250 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.755 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 695, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000249 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 696, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000249 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.803 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.771 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 697, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000249 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 698, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000249 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 699, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000248 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.762 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 700, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000248 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.762 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 701, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000248 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 702, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000248 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.804 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.772 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 703, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000247 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 704, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000247 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 705, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000247 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 706, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000247 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 707, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000246 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 708, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000246 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.793 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 709, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000246 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.753 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 710, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000246 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.759 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 711, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000245 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 712, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000245 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 713, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000245 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 714, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000245 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.815 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.761 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 715, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000245 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.764 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 716, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000244 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 717, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000244 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 718, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000244 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 719, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000244 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 720, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000243 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.801 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 721, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000243 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.750 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 722, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000243 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.762 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 723, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000243 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.786 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 724, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000242 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 725, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000242 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.754 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 726, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000242 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 727, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000242 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 728, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000241 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.804 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.770 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.784 | Weighted | 0.820\n",
      "Epoch: 729, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000241 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.755 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 730, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000241 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.745 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.764 | Weighted | 0.812\n",
      "Epoch: 731, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000241 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.751 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.771 | Weighted | 0.814\n",
      "Epoch: 732, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000240 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 733, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000240 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.754 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 734, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000240 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.810 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.757 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 735, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000240 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.795 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 736, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000239 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 737, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000239 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 738, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000239 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.754 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.773 | Weighted | 0.815\n",
      "Epoch: 739, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000239 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 740, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000238 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 741, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000238 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.769 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.761 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.765 | Weighted | 0.807\n",
      "Epoch: 742, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000238 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.772 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.769 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 743, Train Loss: 0.784, Validation Loss: 0.928, LR: 0.000238 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.796 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 744, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000238 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 745, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000237 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.796 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 746, Train Loss: 0.783, Validation Loss: 0.934, LR: 0.000237 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 747, Train Loss: 0.783, Validation Loss: 0.933, LR: 0.000237 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.764 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.753 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.758 | Weighted | 0.801\n",
      "Epoch: 748, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000237 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.799 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 749, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000236 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.817 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.756 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 750, Train Loss: 0.785, Validation Loss: 0.967, LR: 0.000236 Accuracy: 0.773 \n",
      "\tPrecision | Micro | 0.773 | Macro | 0.790 | Weighted | 0.766 \n",
      "\tRecall    | Micro | 0.773 | Macro | 0.701 | Weighted | 0.777 \n",
      "\tF1        | Micro | 0.773 | Macro | 0.725 | Weighted | 0.773\n",
      "Epoch: 751, Train Loss: 0.783, Validation Loss: 0.940, LR: 0.000236 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.793 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.747 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.761 | Weighted | 0.799\n",
      "Epoch: 752, Train Loss: 0.784, Validation Loss: 0.935, LR: 0.000236 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.748 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 753, Train Loss: 0.784, Validation Loss: 0.941, LR: 0.000235 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.809 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.737 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.756 | Weighted | 0.804\n",
      "Epoch: 754, Train Loss: 0.784, Validation Loss: 0.937, LR: 0.000235 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.769 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.774 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.771 | Weighted | 0.801\n",
      "Epoch: 755, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000235 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 756, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000235 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.754 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 757, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000234 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 758, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000234 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 759, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000234 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 760, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000234 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 761, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000234 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 762, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000233 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 763, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000233 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 764, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000233 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 765, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000233 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 766, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000232 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.756 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.770 | Weighted | 0.814\n",
      "Epoch: 767, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000232 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.774 | Weighted | 0.815\n",
      "Epoch: 768, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000232 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 769, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000232 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.756 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 770, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000231 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 771, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000231 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 772, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000231 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 773, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000231 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 774, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000230 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 775, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000230 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 776, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000230 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 777, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000230 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 778, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000230 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 779, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000229 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 780, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000229 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 781, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000229 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 782, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000229 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 783, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000228 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 784, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000228 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.765 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.778 | Weighted | 0.817\n",
      "Epoch: 785, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000228 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.799 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 786, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000228 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 787, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000228 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 788, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000227 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.801 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.783 | Weighted | 0.820\n",
      "Epoch: 789, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000227 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.799 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 790, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000227 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 791, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000227 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 792, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000226 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.774 | Weighted | 0.815\n",
      "Epoch: 793, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000226 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.753 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.765 | Weighted | 0.807\n",
      "Epoch: 794, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000226 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 795, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000226 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 796, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000225 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 797, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000225 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 798, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000225 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 799, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000225 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 800, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000225 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 801, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000224 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 802, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000224 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 803, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000224 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.756 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 804, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000224 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.761 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 805, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000223 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 806, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000223 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 807, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000223 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 808, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000223 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 809, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000223 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 810, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000222 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.762 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.779 | Weighted | 0.818\n",
      "Epoch: 811, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000222 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 812, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000222 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 813, Train Loss: 0.783, Validation Loss: 0.925, LR: 0.000222 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.758 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.776 | Weighted | 0.817\n",
      "Epoch: 814, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000221 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.757 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 815, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000221 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.772 | Weighted | 0.815\n",
      "Epoch: 816, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000221 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.787 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 817, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000221 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.802 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.761 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.777 | Weighted | 0.817\n",
      "Epoch: 818, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000221 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.756 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 819, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000220 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.784 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 820, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000220 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 821, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000220 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 822, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000220 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 823, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000219 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.784 | Weighted | 0.817\n",
      "Epoch: 824, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000219 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 825, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000219 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.757 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.773 | Weighted | 0.815\n",
      "Epoch: 826, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000219 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.803 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.790 | Weighted | 0.820\n",
      "Epoch: 827, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000219 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.793 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 828, Train Loss: 0.783, Validation Loss: 0.936, LR: 0.000218 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 829, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000218 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.758 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 830, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000218 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 831, Train Loss: 0.783, Validation Loss: 0.927, LR: 0.000218 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 832, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000217 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.752 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 833, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000217 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.753 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 834, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000217 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.768 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 835, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000217 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.773 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 836, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000217 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 837, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000216 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 838, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000216 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 839, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000216 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 840, Train Loss: 0.783, Validation Loss: 0.939, LR: 0.000216 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.763 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.748 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.755 | Weighted | 0.801\n",
      "Epoch: 841, Train Loss: 0.784, Validation Loss: 0.944, LR: 0.000216 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.793 | Weighted | 0.793 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.739 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.757 | Weighted | 0.796\n",
      "Epoch: 842, Train Loss: 0.795, Validation Loss: 0.939, LR: 0.000215 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.766 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.763 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 843, Train Loss: 0.784, Validation Loss: 0.930, LR: 0.000215 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 844, Train Loss: 0.785, Validation Loss: 0.938, LR: 0.000215 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.790 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.755 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 845, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000215 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 846, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000214 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.778 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 847, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000214 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.770 | Weighted | 0.802\n",
      "Epoch: 848, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000214 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 849, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000214 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.752 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 850, Train Loss: 0.783, Validation Loss: 0.916, LR: 0.000214 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.801 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.788 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 851, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000213 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.793 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.775 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.783 | Weighted | 0.822\n",
      "Epoch: 852, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000213 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.784 | Weighted | 0.822\n",
      "Epoch: 853, Train Loss: 0.783, Validation Loss: 0.918, LR: 0.000213 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.804 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.786 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.794 | Weighted | 0.827\n",
      "Epoch: 854, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000213 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.784 | Weighted | 0.822\n",
      "Epoch: 855, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000213 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.777 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.785 | Weighted | 0.823\n",
      "Epoch: 856, Train Loss: 0.783, Validation Loss: 0.918, LR: 0.000212 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.780 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.788 | Weighted | 0.823\n",
      "Epoch: 857, Train Loss: 0.783, Validation Loss: 0.918, LR: 0.000212 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.799 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.782 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.789 | Weighted | 0.825\n",
      "Epoch: 858, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000212 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.785 | Weighted | 0.822\n",
      "Epoch: 859, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000212 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.780 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.788 | Weighted | 0.823\n",
      "Epoch: 860, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000211 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.785 | Weighted | 0.822\n",
      "Epoch: 861, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000211 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 862, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000211 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.785 | Weighted | 0.822\n",
      "Epoch: 863, Train Loss: 0.783, Validation Loss: 0.919, LR: 0.000211 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 864, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000211 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 865, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000210 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 866, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000210 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 867, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000210 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 868, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000210 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 869, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000210 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.771 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 870, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000209 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.793 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.770 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.780 | Weighted | 0.818\n",
      "Epoch: 871, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000209 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.793 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.770 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.780 | Weighted | 0.818\n",
      "Epoch: 872, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000209 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.778 | Weighted | 0.817\n",
      "Epoch: 873, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000209 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.778 | Weighted | 0.817\n",
      "Epoch: 874, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000209 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.780 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.787 | Weighted | 0.822\n",
      "Epoch: 875, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000208 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.782 | Weighted | 0.818\n",
      "Epoch: 876, Train Loss: 0.783, Validation Loss: 0.921, LR: 0.000208 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.772 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.781 | Weighted | 0.820\n",
      "Epoch: 877, Train Loss: 0.783, Validation Loss: 0.920, LR: 0.000208 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.777 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.785 | Weighted | 0.822\n",
      "Epoch: 878, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000208 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.802 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.740 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.761 | Weighted | 0.802\n",
      "Epoch: 879, Train Loss: 0.783, Validation Loss: 0.937, LR: 0.000208 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.777 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.746 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.758 | Weighted | 0.801\n",
      "Epoch: 880, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000207 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 881, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000207 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 882, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000207 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 883, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000207 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.753 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 884, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000206 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 885, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000206 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 886, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000206 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 887, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000206 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 888, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000206 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 889, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000205 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 890, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000205 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 891, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000205 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 892, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000205 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 893, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000205 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 894, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000204 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 895, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000204 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 896, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000204 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 897, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000204 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 898, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000204 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 899, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000203 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 900, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000203 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.753 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 901, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000203 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 902, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000203 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 903, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000203 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 904, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000202 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.758 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 905, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000202 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 906, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000202 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 907, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000202 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.753 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.768 | Weighted | 0.812\n",
      "Epoch: 908, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000202 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 909, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000201 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 910, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000201 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.756 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.771 | Weighted | 0.814\n",
      "Epoch: 911, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000201 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.756 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.770 | Weighted | 0.814\n",
      "Epoch: 912, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000201 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 913, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000201 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 914, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000200 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 915, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000200 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 916, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000200 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 917, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000200 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 918, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000200 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 919, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000199 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 920, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000199 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 921, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000199 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 922, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000199 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 923, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000199 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 924, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000198 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 925, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000198 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 926, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000198 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 927, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000198 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 928, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000198 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 929, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000197 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 930, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000197 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 931, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000197 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.799 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.779 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 932, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000197 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 933, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000197 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 934, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000196 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 935, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000196 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.782 | Weighted | 0.818\n",
      "Epoch: 936, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000196 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.753 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 937, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000196 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 938, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000196 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 939, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000195 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 940, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000195 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.756 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 941, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000195 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 942, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000195 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.801 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 943, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000195 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 944, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000194 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 945, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000194 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 946, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000194 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.801 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 947, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000194 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 948, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000194 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.748 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.763 | Weighted | 0.807\n",
      "Epoch: 949, Train Loss: 0.794, Validation Loss: 0.945, LR: 0.000193 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.799 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.738 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.758 | Weighted | 0.797\n",
      "Epoch: 950, Train Loss: 0.794, Validation Loss: 0.945, LR: 0.000193 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.769 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.748 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.757 | Weighted | 0.796\n",
      "Epoch: 951, Train Loss: 0.784, Validation Loss: 0.958, LR: 0.000193 Accuracy: 0.791 \n",
      "\tPrecision | Micro | 0.791 | Macro | 0.767 | Weighted | 0.785 \n",
      "\tRecall    | Micro | 0.791 | Macro | 0.753 | Weighted | 0.793 \n",
      "\tF1        | Micro | 0.791 | Macro | 0.754 | Weighted | 0.791\n",
      "Epoch: 952, Train Loss: 0.793, Validation Loss: 0.941, LR: 0.000193 Accuracy: 0.796 \n",
      "\tPrecision | Micro | 0.796 | Macro | 0.765 | Weighted | 0.791 \n",
      "\tRecall    | Micro | 0.796 | Macro | 0.762 | Weighted | 0.795 \n",
      "\tF1        | Micro | 0.796 | Macro | 0.759 | Weighted | 0.796\n",
      "Epoch: 953, Train Loss: 0.784, Validation Loss: 0.929, LR: 0.000193 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 954, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000193 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.799 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 955, Train Loss: 0.783, Validation Loss: 0.928, LR: 0.000192 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.782 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.802 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 956, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000192 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 957, Train Loss: 0.783, Validation Loss: 0.931, LR: 0.000192 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 958, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000192 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 959, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000192 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 960, Train Loss: 0.783, Validation Loss: 0.930, LR: 0.000191 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.775 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 961, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000191 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 962, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000191 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 963, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000191 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.783 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 964, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000191 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 965, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000190 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 966, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000190 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 967, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000190 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 968, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000190 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 969, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000190 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 970, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 971, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 972, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 973, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 974, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 975, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000189 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 976, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000188 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 977, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000188 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 978, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000188 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 979, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000188 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 980, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000188 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 981, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000187 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 982, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000187 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 983, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000187 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 984, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000187 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 985, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000187 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 986, Train Loss: 0.783, Validation Loss: 0.929, LR: 0.000186 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.785 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 987, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000186 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.783 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 988, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000186 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.785 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 989, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000186 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.783 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 990, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000186 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 991, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000186 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 992, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000185 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 993, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000185 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.777 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.757 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 994, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000185 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 995, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000185 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.777 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.757 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 996, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000185 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 997, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000184 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.777 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.757 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 998, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000184 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 999, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000184 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1000, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000184 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1001, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000184 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1002, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000183 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1003, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000183 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1004, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000183 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1005, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000183 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1006, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000183 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1007, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000183 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1008, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000182 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1009, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000182 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1010, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000182 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1011, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000182 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1012, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000182 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1013, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000181 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1014, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000181 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1015, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000181 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1016, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000181 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1017, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000181 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1018, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000181 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1019, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000180 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1020, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000180 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1021, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000180 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1022, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000180 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1023, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000180 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 1024, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000179 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1025, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000179 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.776 | Weighted | 0.818\n",
      "Epoch: 1026, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000179 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.778 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1027, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000179 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1028, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000179 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.789 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.769 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.778 | Weighted | 0.818\n",
      "Epoch: 1029, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000179 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1030, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000178 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1031, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000178 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1032, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000178 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1033, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000178 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1034, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000178 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1035, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000178 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1036, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000177 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1037, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000177 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 1038, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000177 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1039, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000177 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.784 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1040, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000177 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1041, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000176 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 1042, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000176 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1043, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000176 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 1044, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000176 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 1045, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000176 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 1046, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000176 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.778 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1047, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000175 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.773 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.756 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.763 | Weighted | 0.807\n",
      "Epoch: 1048, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000175 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1049, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000175 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1050, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000175 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.773 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 1051, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000175 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1052, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000175 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.769 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.765 | Weighted | 0.807\n",
      "Epoch: 1053, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000174 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.785 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1054, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000174 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.759 | Weighted | 0.804\n",
      "Epoch: 1055, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000174 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.770 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.767 | Weighted | 0.809\n",
      "Epoch: 1056, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000174 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.774 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1057, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000174 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1058, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000173 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.786 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.753 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 1059, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000173 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.786 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1060, Train Loss: 0.784, Validation Loss: 0.940, LR: 0.000173 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.787 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.746 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.761 | Weighted | 0.802\n",
      "Epoch: 1061, Train Loss: 0.783, Validation Loss: 0.926, LR: 0.000173 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1062, Train Loss: 0.783, Validation Loss: 0.924, LR: 0.000173 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 1063, Train Loss: 0.783, Validation Loss: 0.923, LR: 0.000173 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1064, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000172 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1065, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000172 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1066, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000172 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 1067, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000172 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 1068, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000172 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.795 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1069, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000172 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1070, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000171 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1071, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000171 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1072, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000171 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1073, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000171 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1074, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000171 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1075, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000171 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1076, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000170 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1077, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000170 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1078, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000170 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1079, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000170 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1080, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000170 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1081, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000170 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1082, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000169 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1083, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000169 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1084, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000169 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1085, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000169 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1086, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000169 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 1087, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000169 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1088, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000168 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.790 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1089, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000168 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 1090, Train Loss: 0.784, Validation Loss: 0.933, LR: 0.000168 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.797 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 1091, Train Loss: 0.796, Validation Loss: 0.933, LR: 0.000168 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.773 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.799 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 1092, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000168 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.790 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.777 | Weighted | 0.809\n",
      "Epoch: 1093, Train Loss: 0.783, Validation Loss: 0.941, LR: 0.000168 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.774 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.743 | Weighted | 0.792 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.755 | Weighted | 0.797\n",
      "Epoch: 1094, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000167 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1095, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000167 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.778 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.784 | Weighted | 0.822\n",
      "Epoch: 1096, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000167 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.792 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1097, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000167 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1098, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000167 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.776 | Weighted | 0.817\n",
      "Epoch: 1099, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000167 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1100, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000166 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1101, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000166 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1102, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000166 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1103, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000166 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1104, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000166 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 1105, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000166 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 1106, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000165 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1107, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000165 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.787 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 1108, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000165 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.789 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1109, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000165 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1110, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000165 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1111, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000165 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.784 | Weighted | 0.820\n",
      "Epoch: 1112, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000164 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1113, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000164 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1114, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000164 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1115, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000164 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1116, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000164 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1117, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000164 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1118, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000163 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1119, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000163 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1120, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000163 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1121, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000163 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1122, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000163 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 1123, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000163 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1124, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000162 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1125, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000162 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1126, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000162 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1127, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000162 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1128, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000162 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1129, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000162 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1130, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000161 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1131, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000161 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1132, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000161 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 1133, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000161 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1134, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000161 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.794 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 1135, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000161 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 1136, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000160 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.792 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.789 | Weighted | 0.820\n",
      "Epoch: 1137, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000160 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 1138, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000160 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1139, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000160 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.789 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1140, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000160 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 1141, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000160 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.792 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1142, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000159 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 1143, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000159 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.796 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 1144, Train Loss: 0.782, Validation Loss: 0.919, LR: 0.000159 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.798 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.798 | Weighted | 0.828\n",
      "Epoch: 1145, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000159 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.794 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.786 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.790 | Weighted | 0.822\n",
      "Epoch: 1146, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000159 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.787 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.791 | Weighted | 0.823\n",
      "Epoch: 1147, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000159 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.790 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.791 | Weighted | 0.823\n",
      "Epoch: 1148, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000159 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.790 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.793 | Weighted | 0.823\n",
      "Epoch: 1149, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000158 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.793 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 1150, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000158 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.788 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.791 | Weighted | 0.823\n",
      "Epoch: 1151, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000158 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.790 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.793 | Weighted | 0.823\n",
      "Epoch: 1152, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000158 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.790 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.790 | Weighted | 0.822\n",
      "Epoch: 1153, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000158 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.792 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.794 | Weighted | 0.825\n",
      "Epoch: 1154, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000158 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.778 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 1155, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000157 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.799 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.792 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.795 | Weighted | 0.825\n",
      "Epoch: 1156, Train Loss: 0.782, Validation Loss: 0.919, LR: 0.000157 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.792 | Weighted | 0.823\n",
      "Epoch: 1157, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000157 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.790 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.790 | Weighted | 0.822\n",
      "Epoch: 1158, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000157 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.780 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.786 | Weighted | 0.822\n",
      "Epoch: 1159, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000157 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.792 | Weighted | 0.822\n",
      "Epoch: 1160, Train Loss: 0.782, Validation Loss: 0.918, LR: 0.000157 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.793 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.793 | Weighted | 0.825\n",
      "Epoch: 1161, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000156 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 1162, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000156 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.779 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 1163, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000156 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823\n",
      "Epoch: 1164, Train Loss: 0.782, Validation Loss: 0.917, LR: 0.000156 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.795 | Weighted | 0.825\n",
      "Epoch: 1165, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000156 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 1166, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000156 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.783 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.787 | Weighted | 0.822\n",
      "Epoch: 1167, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000156 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.785 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1168, Train Loss: 0.782, Validation Loss: 0.918, LR: 0.000155 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.792 | Weighted | 0.822\n",
      "Epoch: 1169, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000155 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 1170, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000155 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.793 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.786 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.788 | Weighted | 0.822\n",
      "Epoch: 1171, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000155 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.782 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1172, Train Loss: 0.782, Validation Loss: 0.919, LR: 0.000155 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.789 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.789 | Weighted | 0.820\n",
      "Epoch: 1173, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000155 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.786 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.787 | Weighted | 0.820\n",
      "Epoch: 1174, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000154 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.792 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1175, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000154 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 1176, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000154 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.779 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 1177, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000154 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.787 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.789 | Weighted | 0.823\n",
      "Epoch: 1178, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000154 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.786 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 1179, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000154 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.775 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1180, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000154 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1181, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000153 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1182, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000153 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 1183, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000153 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.770 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1184, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000153 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1185, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000153 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1186, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000153 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 1187, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000152 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1188, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000152 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1189, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000152 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1190, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000152 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.786 | Weighted | 0.818\n",
      "Epoch: 1191, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000152 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1192, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000152 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.772 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1193, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000152 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1194, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000151 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1195, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000151 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1196, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000151 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 1197, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000151 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 1198, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000151 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1199, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000151 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.782 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.781 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 1200, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000151 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1201, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000150 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 1202, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000150 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1203, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000150 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 1204, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000150 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1205, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000150 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1206, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000150 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818\n",
      "Epoch: 1207, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000149 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 1208, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000149 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1209, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000149 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1210, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000149 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1211, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000149 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1212, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000149 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1213, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000149 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.784 | Weighted | 0.820\n",
      "Epoch: 1214, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000148 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1215, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000148 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1216, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000148 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.779 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 1217, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000148 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1218, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000148 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.772 | Weighted | 0.815\n",
      "Epoch: 1219, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000148 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1220, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000148 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1221, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000147 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 1222, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000147 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 1223, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000147 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1224, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000147 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.795 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.763 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.776 | Weighted | 0.817\n",
      "Epoch: 1225, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000147 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1226, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000147 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 1227, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000146 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1228, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000146 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1229, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000146 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.761 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.779 | Weighted | 0.818\n",
      "Epoch: 1230, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000146 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.758 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.775 | Weighted | 0.817\n",
      "Epoch: 1231, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000146 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1232, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000146 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.772 | Weighted | 0.814\n",
      "Epoch: 1233, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000146 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1234, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000145 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1235, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000145 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.767 | Weighted | 0.810\n",
      "Epoch: 1236, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000145 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.750 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.766 | Weighted | 0.812\n",
      "Epoch: 1237, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000145 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.793 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1238, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000145 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 1239, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000145 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1240, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000145 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1241, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000144 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1242, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000144 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1243, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000144 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1244, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000144 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.796 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.768 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1245, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000144 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.755 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.770 | Weighted | 0.814\n",
      "Epoch: 1246, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000144 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1247, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000144 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1248, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000143 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1249, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000143 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1250, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000143 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1251, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000143 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.777 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 1252, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000143 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1253, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000143 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1254, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000143 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1255, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000142 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.771 | Weighted | 0.814\n",
      "Epoch: 1256, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000142 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1257, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000142 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1258, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000142 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 1259, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000142 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1260, Train Loss: 0.789, Validation Loss: 0.924, LR: 0.000142 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1261, Train Loss: 0.783, Validation Loss: 0.939, LR: 0.000142 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.774 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.775 | Weighted | 0.806\n",
      "Epoch: 1262, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000141 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 1263, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000141 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1264, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000141 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.783 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1265, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000141 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 1266, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000141 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 1267, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000141 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 1268, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000141 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 1269, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000140 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1270, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000140 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1271, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000140 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1272, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000140 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1273, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000140 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1274, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000140 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.777 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.757 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1275, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000140 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.771 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 1276, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000139 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.763 | Weighted | 0.804\n",
      "Epoch: 1277, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.772 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 1278, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000139 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.774 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.763 | Weighted | 0.804\n",
      "Epoch: 1279, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.772 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 1280, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 1281, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.773 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.764 | Weighted | 0.806\n",
      "Epoch: 1282, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 1283, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000139 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 1284, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1285, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1286, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1287, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1288, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1289, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1290, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000138 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1291, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000137 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1292, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000137 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1293, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000137 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1294, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000137 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1295, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000137 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1296, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000137 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1297, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000137 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1298, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1299, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1300, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 1301, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1302, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 1303, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1304, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000136 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1305, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1306, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1307, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1308, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1309, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1310, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000135 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1311, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1312, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000135 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1313, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1314, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1315, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1316, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000134 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1317, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1318, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1319, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000134 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1320, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000133 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1321, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000133 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 1322, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000133 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1323, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000133 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 1324, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000133 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1325, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000133 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.785 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1326, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000133 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1327, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000133 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1328, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000132 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1329, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000132 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1330, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000132 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1331, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000132 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1332, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000132 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1333, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000132 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1334, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000132 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1335, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000131 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1336, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000131 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1337, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000131 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1338, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000131 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1339, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000131 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1340, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000131 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1341, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000131 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1342, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000131 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.793 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1343, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000130 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1344, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000130 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1345, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000130 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1346, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000130 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1347, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000130 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1348, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000130 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1349, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000130 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.789 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1350, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000130 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 1351, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000129 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1352, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000129 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.757 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.773 | Weighted | 0.815\n",
      "Epoch: 1353, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000129 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1354, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000129 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1355, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000129 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1356, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000129 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1357, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000129 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1358, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000128 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1359, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000128 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.790 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1360, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000128 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 1361, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000128 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1362, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000128 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1363, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000128 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1364, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000128 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.785 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1365, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000128 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1366, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000127 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1367, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000127 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.765 | Weighted | 0.809\n",
      "Epoch: 1368, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000127 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.799 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.765 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.779 | Weighted | 0.817\n",
      "Epoch: 1369, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000127 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1370, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000127 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 1371, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000127 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1372, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000127 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.756 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1373, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000127 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 1374, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000126 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1375, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000126 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.754 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.769 | Weighted | 0.812\n",
      "Epoch: 1376, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000126 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1377, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000126 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1378, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000126 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1379, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000126 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.766 | Weighted | 0.810\n",
      "Epoch: 1380, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000126 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 1381, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000126 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1382, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000125 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.775 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.765 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1383, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000125 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.748 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.759 | Weighted | 0.806\n",
      "Epoch: 1384, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000125 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1385, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000125 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 1386, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000125 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.776 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.765 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1387, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000125 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.751 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.763 | Weighted | 0.809\n",
      "Epoch: 1388, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000125 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 1389, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000125 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1390, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000124 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.774 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1391, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000124 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.786 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1392, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000124 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.762 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 1393, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000124 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1394, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000124 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.776 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 1395, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000124 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.792 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1396, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000124 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.748 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 1397, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000124 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1398, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000123 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 1399, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000123 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.792 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1400, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000123 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.748 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 1401, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000123 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.775 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.766 | Weighted | 0.807\n",
      "Epoch: 1402, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000123 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1403, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000123 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.795 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1404, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000123 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1405, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000123 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1406, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000122 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1407, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000122 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.793 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.753 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1408, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000122 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.777 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 1409, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000122 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1410, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000122 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1411, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000122 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.793 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.754 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1412, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000122 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1413, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000122 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 1414, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000121 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.773 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 1415, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000121 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.770 | Weighted | 0.810\n",
      "Epoch: 1416, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000121 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1417, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000121 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 1418, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000121 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.770 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.771 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.770 | Weighted | 0.804\n",
      "Epoch: 1419, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000121 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.800 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.747 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.766 | Weighted | 0.807\n",
      "Epoch: 1420, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000121 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 1421, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000121 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.786 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 1422, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000121 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.773 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 1423, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000120 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.798 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.745 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.763 | Weighted | 0.804\n",
      "Epoch: 1424, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000120 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.792 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1425, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000120 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 1426, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000120 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.778 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 1427, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000120 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.795 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.746 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 1428, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000120 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.780 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.750 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.762 | Weighted | 0.804\n",
      "Epoch: 1429, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000120 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.775 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.764 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1430, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000120 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1431, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000119 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.744 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.762 | Weighted | 0.806\n",
      "Epoch: 1432, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000119 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1433, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000119 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1434, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000119 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.778 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 1435, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000119 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.778 | Weighted | 0.817\n",
      "Epoch: 1436, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000119 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.771 | Weighted | 0.810\n",
      "Epoch: 1437, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000119 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1438, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000119 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.759 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1439, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000118 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.767 | Weighted | 0.812\n",
      "Epoch: 1440, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000118 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.795 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.773 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.783 | Weighted | 0.820\n",
      "Epoch: 1441, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000118 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1442, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000118 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1443, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000118 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.788 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.773 | Weighted | 0.815\n",
      "Epoch: 1444, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000118 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.791 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.788 | Weighted | 0.820\n",
      "Epoch: 1445, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000118 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 1446, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000118 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.752 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1447, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000118 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.754 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.766 | Weighted | 0.809\n",
      "Epoch: 1448, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000117 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.788 | Weighted | 0.818\n",
      "Epoch: 1449, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000117 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 1450, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000117 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.751 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1451, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000117 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.749 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.763 | Weighted | 0.807\n",
      "Epoch: 1452, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000117 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.794 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.789 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.791 | Weighted | 0.820\n",
      "Epoch: 1453, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000117 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.798 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 1454, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000117 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.789 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.752 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.766 | Weighted | 0.807\n",
      "Epoch: 1455, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000117 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1456, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000116 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1457, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000116 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 1458, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000116 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 1459, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000116 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1460, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000116 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.752 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1461, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000116 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 1462, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000116 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1463, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000116 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.756 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1464, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000116 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.749 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.764 | Weighted | 0.807\n",
      "Epoch: 1465, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000115 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 1466, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000115 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1467, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000115 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.780 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.747 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1468, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000115 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1469, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000115 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.792 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.758 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1470, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000115 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 1471, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000115 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1472, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000115 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1473, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000115 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1474, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000114 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1475, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000114 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.796 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.772 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.782 | Weighted | 0.820\n",
      "Epoch: 1476, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000114 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1477, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000114 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.788 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.780 | Weighted | 0.817\n",
      "Epoch: 1478, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000114 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.751 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.764 | Weighted | 0.807\n",
      "Epoch: 1479, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000114 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.766 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.777 | Weighted | 0.817\n",
      "Epoch: 1480, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000114 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1481, Train Loss: 0.782, Validation Loss: 0.942, LR: 0.000114 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.790 | Weighted | 0.794 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.744 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.761 | Weighted | 0.797\n",
      "Epoch: 1482, Train Loss: 0.787, Validation Loss: 0.939, LR: 0.000114 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.783 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.745 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.759 | Weighted | 0.802\n",
      "Epoch: 1483, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000113 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 1484, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000113 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.777 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.756 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 1485, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000113 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1486, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000113 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.783 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.767 | Weighted | 0.799\n",
      "Epoch: 1487, Train Loss: 0.782, Validation Loss: 0.940, LR: 0.000113 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.773 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.764 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.768 | Weighted | 0.802\n",
      "Epoch: 1488, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000113 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.770 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.753 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1489, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000113 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.773 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.753 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1490, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000113 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.760 | Weighted | 0.799\n",
      "Epoch: 1491, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000112 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.760 | Weighted | 0.799\n",
      "Epoch: 1492, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000112 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.796 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.760 | Weighted | 0.799\n",
      "Epoch: 1493, Train Loss: 0.782, Validation Loss: 0.938, LR: 0.000112 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.759 | Weighted | 0.799\n",
      "Epoch: 1494, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.771 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.751 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.759 | Weighted | 0.799\n",
      "Epoch: 1495, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1496, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1497, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1498, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1499, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000112 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1500, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1501, Train Loss: 0.782, Validation Loss: 0.937, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1502, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.773 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1503, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.773 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.761 | Weighted | 0.801\n",
      "Epoch: 1504, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.774 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 1505, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1506, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1507, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1508, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000111 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1509, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1510, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1511, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1512, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1513, Train Loss: 0.782, Validation Loss: 0.936, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1514, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1515, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1516, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1517, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000110 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1518, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.772 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.752 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 1519, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 1520, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 1521, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 1522, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 1523, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.763 | Weighted | 0.802\n",
      "Epoch: 1524, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1525, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1526, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1527, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000109 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1528, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1529, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1530, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1531, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1532, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.764 | Weighted | 0.804\n",
      "Epoch: 1533, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1534, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1535, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1536, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000108 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1537, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000107 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1538, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000107 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1539, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000107 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1540, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000107 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 1541, Train Loss: 0.782, Validation Loss: 0.934, LR: 0.000107 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1542, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000107 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1543, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000107 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1544, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000107 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1545, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000107 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1546, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1547, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1548, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.768 | Weighted | 0.807\n",
      "Epoch: 1549, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1550, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1551, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1552, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1553, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1554, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1555, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000106 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.768 | Weighted | 0.809\n",
      "Epoch: 1556, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000105 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 1557, Train Loss: 0.782, Validation Loss: 0.948, LR: 0.000105 Accuracy: 0.793 \n",
      "\tPrecision | Micro | 0.793 | Macro | 0.764 | Weighted | 0.792 \n",
      "\tRecall    | Micro | 0.793 | Macro | 0.752 | Weighted | 0.791 \n",
      "\tF1        | Micro | 0.793 | Macro | 0.758 | Weighted | 0.793\n",
      "Epoch: 1558, Train Loss: 0.782, Validation Loss: 0.939, LR: 0.000105 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.770 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 1559, Train Loss: 0.786, Validation Loss: 0.930, LR: 0.000105 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.770 | Weighted | 0.809\n",
      "Epoch: 1560, Train Loss: 0.783, Validation Loss: 0.932, LR: 0.000105 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.778 | Weighted | 0.810\n",
      "Epoch: 1561, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000105 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1562, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000105 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1563, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000105 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.766 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1564, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000105 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1565, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1566, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1567, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1568, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1569, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1570, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1571, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1572, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1573, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1574, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000104 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1575, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1576, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1577, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1578, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1579, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1580, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1581, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1582, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1583, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000103 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1584, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1585, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1586, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1587, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.775 | Weighted | 0.815\n",
      "Epoch: 1588, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1589, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1590, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1591, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1592, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1593, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000102 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1594, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1595, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1596, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1597, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1598, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1599, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1600, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1601, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1602, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.776 | Weighted | 0.815\n",
      "Epoch: 1603, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000101 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1604, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1605, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1606, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1607, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1608, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1609, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1610, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1611, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1612, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1613, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000100 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1614, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1615, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1616, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1617, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1618, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1619, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1620, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1621, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1622, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 1623, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000099 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1624, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1625, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1626, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1627, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1628, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1629, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1630, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1631, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1632, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1633, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000098 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1634, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1635, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1636, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1637, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1638, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1639, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1640, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1641, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1642, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1643, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 1644, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000097 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1645, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1646, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1647, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1648, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1649, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1650, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1651, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1652, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1653, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1654, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000096 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1655, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1656, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1657, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1658, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1659, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1660, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1661, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1662, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000095 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.768 | Weighted | 0.810\n",
      "Epoch: 1663, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000095 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1664, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000095 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1665, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000095 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1666, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1667, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1668, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1669, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000094 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1670, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.783 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.774 | Weighted | 0.814\n",
      "Epoch: 1671, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.778 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.770 | Weighted | 0.812\n",
      "Epoch: 1672, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000094 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 1673, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 1674, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.772 | Weighted | 0.812\n",
      "Epoch: 1675, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000094 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.773 | Weighted | 0.814\n",
      "Epoch: 1676, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000093 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.769 | Weighted | 0.810\n",
      "Epoch: 1677, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000093 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.767 | Weighted | 0.807\n",
      "Epoch: 1678, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000093 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 1679, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000093 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1680, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000093 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1681, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000093 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.777 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.769 | Weighted | 0.809\n",
      "Epoch: 1682, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000093 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.793 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 1683, Train Loss: 0.782, Validation Loss: 0.935, LR: 0.000093 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.753 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.763 | Weighted | 0.806\n",
      "Epoch: 1684, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000093 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.782 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.785 | Weighted | 0.820\n",
      "Epoch: 1685, Train Loss: 0.782, Validation Loss: 0.921, LR: 0.000093 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.807 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.778 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.789 | Weighted | 0.822\n",
      "Epoch: 1686, Train Loss: 0.782, Validation Loss: 0.922, LR: 0.000093 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.800 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.786 | Weighted | 0.822\n",
      "Epoch: 1687, Train Loss: 0.782, Validation Loss: 0.920, LR: 0.000092 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.793 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.757 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.771 | Weighted | 0.815\n",
      "Epoch: 1688, Train Loss: 0.782, Validation Loss: 0.918, LR: 0.000092 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.805 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.778 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.789 | Weighted | 0.823\n",
      "Epoch: 1689, Train Loss: 0.782, Validation Loss: 0.917, LR: 0.000092 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.808 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.781 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.792 | Weighted | 0.828\n",
      "Epoch: 1690, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000092 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.775 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.786 | Weighted | 0.825\n",
      "Epoch: 1691, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000092 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.800 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.773 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.784 | Weighted | 0.823\n",
      "Epoch: 1692, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000092 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.802 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.778 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.788 | Weighted | 0.825\n",
      "Epoch: 1693, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000092 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1694, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000092 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1695, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000092 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1696, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000092 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1697, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000092 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1698, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.805 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.783 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.792 | Weighted | 0.827\n",
      "Epoch: 1699, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1700, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1701, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1702, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1703, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1704, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1705, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1706, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1707, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1708, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000091 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1709, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1710, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1711, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1712, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1713, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1714, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1715, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1716, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1717, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1718, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1719, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000090 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1720, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1721, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1722, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1723, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1724, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1725, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1726, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1727, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.806 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.784 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.794 | Weighted | 0.828\n",
      "Epoch: 1728, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1729, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1730, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000089 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1731, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1732, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1733, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1734, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1735, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1736, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1737, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1738, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1739, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1740, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1741, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1742, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000088 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1743, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1744, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1745, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.816 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.831 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.800 | Weighted | 0.833\n",
      "Epoch: 1746, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1747, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1748, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1749, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1750, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1751, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1752, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1753, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000087 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1754, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1755, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1756, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1757, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1758, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1759, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.788 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1760, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1761, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1762, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1763, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1764, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1765, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000086 Accuracy: 0.833 \n",
      "\tPrecision | Micro | 0.833 | Macro | 0.813 | Weighted | 0.831 \n",
      "\tRecall    | Micro | 0.833 | Macro | 0.789 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.833 | Macro | 0.799 | Weighted | 0.833\n",
      "Epoch: 1766, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.828 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.797 | Weighted | 0.831\n",
      "Epoch: 1767, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.828 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.797 | Weighted | 0.831\n",
      "Epoch: 1768, Train Loss: 0.782, Validation Loss: 0.915, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.811 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.828 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.797 | Weighted | 0.831\n",
      "Epoch: 1769, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.815 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1770, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.815 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1771, Train Loss: 0.782, Validation Loss: 0.916, LR: 0.000085 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.815 | Weighted | 0.829 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.787 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.798 | Weighted | 0.831\n",
      "Epoch: 1772, Train Loss: 0.782, Validation Loss: 0.917, LR: 0.000085 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.812 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.785 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.796 | Weighted | 0.828\n",
      "Epoch: 1773, Train Loss: 0.782, Validation Loss: 0.919, LR: 0.000085 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.781 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.793 | Weighted | 0.825\n",
      "Epoch: 1774, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000085 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 1775, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000085 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.801 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1776, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000085 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 1777, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000084 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.780 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1778, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000084 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 1779, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1780, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1781, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1782, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1783, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1784, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1785, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1786, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1787, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.775 | Weighted | 0.807\n",
      "Epoch: 1788, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000084 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1789, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1790, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1791, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1792, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1793, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.787 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 1794, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.787 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 1795, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.787 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.776 | Weighted | 0.809\n",
      "Epoch: 1796, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1797, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1798, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1799, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1800, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000083 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1801, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1802, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1803, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1804, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1805, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1806, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1807, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1808, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1809, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1810, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1811, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1812, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 1813, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000082 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 1814, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 1815, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.761 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1816, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.783 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.761 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1817, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.781 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.757 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.767 | Weighted | 0.804\n",
      "Epoch: 1818, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1819, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1820, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1821, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1822, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1823, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1824, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1825, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000081 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1826, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1827, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1828, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1829, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1830, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1831, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1832, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1833, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1834, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1835, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1836, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1837, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000080 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1838, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1839, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1840, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.759 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1841, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1842, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1843, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 1844, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.786 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 1845, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 1846, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1847, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.787 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 1848, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000079 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.764 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1849, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.779 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.760 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.768 | Weighted | 0.804\n",
      "Epoch: 1850, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000079 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1851, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000078 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.764 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1852, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1853, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1854, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1855, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.779 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.761 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.769 | Weighted | 0.804\n",
      "Epoch: 1856, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 1857, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1858, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 1859, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1860, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1861, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.775 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.755 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.763 | Weighted | 0.801\n",
      "Epoch: 1862, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1863, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000078 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1864, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 1865, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1866, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1867, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1868, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.777 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.758 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 1869, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1870, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.765 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 1871, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000077 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 1872, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1873, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1874, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 1875, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1876, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000077 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.778 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 1877, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 1878, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.756 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 1879, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 1880, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1881, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1882, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1883, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 1884, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.779 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.760 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.768 | Weighted | 0.806\n",
      "Epoch: 1885, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1886, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.780 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 1887, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 1888, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.772 | Weighted | 0.807\n",
      "Epoch: 1889, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000076 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 1890, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1891, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1892, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000075 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.783 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 1893, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000075 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1894, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1895, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000075 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1896, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000075 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 1897, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000075 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 1898, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1899, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.772 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.761 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 1900, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000075 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.778 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1901, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000075 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.788 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1902, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000075 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 1903, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.775 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.779 | Weighted | 0.809\n",
      "Epoch: 1904, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1905, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.771 | Weighted | 0.809\n",
      "Epoch: 1906, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.759 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 1907, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000074 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.784 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.786 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 1908, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1909, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000074 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 1910, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000074 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1911, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.776 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.772 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 1912, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.793 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1913, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.790 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1914, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.777 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 1915, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.772 | Weighted | 0.806\n",
      "Epoch: 1916, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000074 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1917, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000073 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.788 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 1918, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000073 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.778 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.772 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 1919, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000073 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.782 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.765 | Weighted | 0.804\n",
      "Epoch: 1920, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000073 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.802 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 1921, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000073 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.783 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 1922, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000073 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.782 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.775 | Weighted | 0.806\n",
      "Epoch: 1923, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000073 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.758 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1924, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000073 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.785 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 1925, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000073 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.782 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 1926, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000073 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.779 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.763 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.770 | Weighted | 0.804\n",
      "Epoch: 1927, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000073 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 1928, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000073 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.785 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.767 | Weighted | 0.804\n",
      "Epoch: 1929, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000073 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.781 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.778 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.779 | Weighted | 0.809\n",
      "Epoch: 1930, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000073 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.792 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1931, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000072 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.797 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.771 | Weighted | 0.806\n",
      "Epoch: 1932, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000072 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.778 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.772 | Weighted | 0.804\n",
      "Epoch: 1933, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000072 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.780 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.773 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 1934, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000072 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.764 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 1935, Train Loss: 0.782, Validation Loss: 0.933, LR: 0.000072 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.787 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.752 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.766 | Weighted | 0.802\n",
      "Epoch: 1936, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000072 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 1937, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000072 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.780 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.761 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 1938, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000072 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 1939, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000072 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.790 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1940, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000072 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.782 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 1941, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000072 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.757 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 1942, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000072 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.792 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.753 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.768 | Weighted | 0.804\n",
      "Epoch: 1943, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000072 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.773 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 1944, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 1945, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000071 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.759 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 1946, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000071 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.777 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.757 | Weighted | 0.797 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.765 | Weighted | 0.801\n",
      "Epoch: 1947, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 1948, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000071 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.776 | Weighted | 0.812\n",
      "Epoch: 1949, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000071 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.751 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 1950, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000071 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 1951, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.770 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1952, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 1953, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000071 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.772 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.758 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 1954, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000071 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 1955, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.768 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.785 | Weighted | 0.818\n",
      "Epoch: 1956, Train Loss: 0.782, Validation Loss: 0.931, LR: 0.000071 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.756 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 1957, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000071 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 1958, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000071 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.771 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1959, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 1960, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000070 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.772 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.775 | Weighted | 0.807\n",
      "Epoch: 1961, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000070 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.788 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.778 | Weighted | 0.810\n",
      "Epoch: 1962, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000070 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.766 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1963, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000070 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.787 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 1964, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.781 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.769 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.775 | Weighted | 0.807\n",
      "Epoch: 1965, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.768 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.780 | Weighted | 0.818\n",
      "Epoch: 1966, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 1967, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 1968, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.796 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.768 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1969, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000070 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.765 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1970, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000070 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.776 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.759 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 1971, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.788 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 1972, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000070 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 1973, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.763 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 1974, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000069 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.785 | Weighted | 0.815\n",
      "Epoch: 1975, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.799 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.771 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 1976, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000069 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 1977, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000069 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.779 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.769 | Weighted | 0.807\n",
      "Epoch: 1978, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 1979, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.777 | Weighted | 0.815\n",
      "Epoch: 1980, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.796 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 1981, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.788 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 1982, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.797 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.781 | Weighted | 0.817\n",
      "Epoch: 1983, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000069 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 1984, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000069 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.782 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 1985, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000069 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.786 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 1986, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000069 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.784 | Weighted | 0.817\n",
      "Epoch: 1987, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000068 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.794 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.758 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.772 | Weighted | 0.810\n",
      "Epoch: 1988, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000068 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.785 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 1989, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000068 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.798 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 1990, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000068 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 1991, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000068 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.774 | Weighted | 0.807\n",
      "Epoch: 1992, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000068 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 1993, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000068 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.804 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 1994, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000068 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.794 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 1995, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000068 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.799 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.787 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.792 | Weighted | 0.822\n",
      "Epoch: 1996, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000068 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1997, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000068 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.803 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.766 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 1998, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000068 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.780 | Weighted | 0.814\n",
      "Epoch: 1999, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000068 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.796 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.779 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.786 | Weighted | 0.820\n",
      "Epoch: 2000, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000068 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 2001, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000068 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 2002, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000067 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.796 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.785 | Weighted | 0.815\n",
      "Epoch: 2003, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000067 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.776 | Weighted | 0.814\n",
      "Epoch: 2004, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000067 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.759 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.775 | Weighted | 0.814\n",
      "Epoch: 2005, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000067 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 2006, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000067 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 2007, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000067 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.779 | Weighted | 0.815\n",
      "Epoch: 2008, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000067 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 2009, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000067 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2010, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000067 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.777 | Weighted | 0.814\n",
      "Epoch: 2011, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000067 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.760 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.778 | Weighted | 0.815\n",
      "Epoch: 2012, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000067 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2013, Train Loss: 0.782, Validation Loss: 0.932, LR: 0.000067 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 2014, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000067 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.786 | Weighted | 0.817\n",
      "Epoch: 2015, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000067 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 2016, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000067 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 2017, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000066 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.757 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.771 | Weighted | 0.812\n",
      "Epoch: 2018, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000066 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.775 | Weighted | 0.810\n",
      "Epoch: 2019, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000066 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 2020, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000066 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.770 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.783 | Weighted | 0.818\n",
      "Epoch: 2021, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000066 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 2022, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000066 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.779 | Weighted | 0.812\n",
      "Epoch: 2023, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000066 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 2024, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000066 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.804 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.768 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.782 | Weighted | 0.817\n",
      "Epoch: 2025, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000066 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 2026, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000066 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2027, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000066 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.770 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.786 | Weighted | 0.822\n",
      "Epoch: 2028, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000066 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.785 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.775 | Weighted | 0.812\n",
      "Epoch: 2029, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000066 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.789 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 2030, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000066 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.770 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.786 | Weighted | 0.822\n",
      "Epoch: 2031, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000066 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.760 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 2032, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000065 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.778 | Weighted | 0.814\n",
      "Epoch: 2033, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000065 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.797 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.777 | Weighted | 0.812\n",
      "Epoch: 2034, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000065 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.763 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.780 | Weighted | 0.815\n",
      "Epoch: 2035, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000065 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.786 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 2036, Train Loss: 0.782, Validation Loss: 0.930, LR: 0.000065 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.791 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.777 | Weighted | 0.806\n",
      "Epoch: 2037, Train Loss: 0.782, Validation Loss: 0.929, LR: 0.000065 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.787 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2038, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000065 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.790 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.782 | Weighted | 0.815\n",
      "Epoch: 2039, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000065 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.789 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2040, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.803 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2041, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.783 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.795 | Weighted | 0.823\n",
      "Epoch: 2042, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 2043, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.804 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2044, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.804 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2045, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000065 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.806 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2046, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000065 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.803 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2047, Train Loss: 0.782, Validation Loss: 0.923, LR: 0.000064 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.807 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.794 | Weighted | 0.822\n",
      "Epoch: 2048, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.795 | Weighted | 0.820\n",
      "Epoch: 2049, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2050, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2051, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2052, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.805 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2053, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2054, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000064 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2055, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2056, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 2057, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2058, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2059, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000064 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2060, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000064 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2061, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000064 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2062, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000064 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2063, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000063 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2064, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000063 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2065, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000063 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.772 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2066, Train Loss: 0.782, Validation Loss: 0.924, LR: 0.000063 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.805 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2067, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000063 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.803 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2068, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000063 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2069, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000063 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2070, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000063 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2071, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000063 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2072, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000063 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.785 | Weighted | 0.815\n",
      "Epoch: 2073, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000063 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2074, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000063 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2075, Train Loss: 0.782, Validation Loss: 0.926, LR: 0.000063 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.798 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2076, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000063 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2077, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000063 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2078, Train Loss: 0.782, Validation Loss: 0.925, LR: 0.000063 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.803 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2079, Train Loss: 0.782, Validation Loss: 0.927, LR: 0.000062 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2080, Train Loss: 0.782, Validation Loss: 0.928, LR: 0.000062 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2081, Train Loss: 0.781, Validation Loss: 0.929, LR: 0.000062 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2082, Train Loss: 0.773, Validation Loss: 0.936, LR: 0.000062 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.791 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.763 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.775 | Weighted | 0.802\n",
      "Epoch: 2083, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000062 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.799 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.756 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2084, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000062 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.774 | Weighted | 0.812\n",
      "Epoch: 2085, Train Loss: 0.770, Validation Loss: 0.940, LR: 0.000062 Accuracy: 0.797 \n",
      "\tPrecision | Micro | 0.797 | Macro | 0.779 | Weighted | 0.796 \n",
      "\tRecall    | Micro | 0.797 | Macro | 0.748 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.797 | Macro | 0.760 | Weighted | 0.797\n",
      "Epoch: 2086, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000062 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2087, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000062 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.773 | Weighted | 0.809\n",
      "Epoch: 2088, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.774 | Weighted | 0.810\n",
      "Epoch: 2089, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 2090, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 2091, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.758 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 2092, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2093, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2094, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000062 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2095, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000061 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2096, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2097, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2098, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2099, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.788 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.771 | Weighted | 0.807\n",
      "Epoch: 2100, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2101, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2102, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2103, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2104, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2105, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2106, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2107, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2108, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2109, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2110, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000061 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2111, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2112, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2113, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2114, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.785 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.767 | Weighted | 0.806\n",
      "Epoch: 2115, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2116, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2117, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2118, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2119, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2120, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2121, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2122, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2123, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2124, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2125, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2126, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2127, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000060 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.784 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.766 | Weighted | 0.804\n",
      "Epoch: 2128, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000059 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.783 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.753 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 2129, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.792 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.772 | Weighted | 0.809\n",
      "Epoch: 2130, Train Loss: 0.770, Validation Loss: 0.936, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.790 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.770 | Weighted | 0.806\n",
      "Epoch: 2131, Train Loss: 0.770, Validation Loss: 0.938, LR: 0.000059 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.780 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.747 | Weighted | 0.799 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 2132, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2133, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000059 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.783 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.743 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.758 | Weighted | 0.802\n",
      "Epoch: 2134, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000059 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.782 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.741 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.756 | Weighted | 0.801\n",
      "Epoch: 2135, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000059 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.782 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.741 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.756 | Weighted | 0.801\n",
      "Epoch: 2136, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000059 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.783 | Weighted | 0.799 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.743 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.758 | Weighted | 0.802\n",
      "Epoch: 2137, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.788 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 2138, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.788 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 2139, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.788 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 2140, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.788 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.752 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 2141, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2142, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2143, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2144, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000059 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2145, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2146, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2147, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2148, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2149, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2150, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2151, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2152, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2153, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2154, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2155, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2156, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2157, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2158, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2159, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2160, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000058 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2161, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000058 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2162, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000057 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.791 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.757 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.770 | Weighted | 0.807\n",
      "Epoch: 2163, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000057 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.792 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 2164, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000057 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2165, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.792 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 2166, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000057 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.788 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.767 | Weighted | 0.804\n",
      "Epoch: 2167, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.792 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.773 | Weighted | 0.807\n",
      "Epoch: 2168, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.788 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.767 | Weighted | 0.804\n",
      "Epoch: 2169, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000057 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.755 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.769 | Weighted | 0.806\n",
      "Epoch: 2170, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.789 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.749 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.765 | Weighted | 0.802\n",
      "Epoch: 2171, Train Loss: 0.770, Validation Loss: 0.936, LR: 0.000057 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.789 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.747 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.762 | Weighted | 0.802\n",
      "Epoch: 2172, Train Loss: 0.770, Validation Loss: 0.936, LR: 0.000057 Accuracy: 0.799 \n",
      "\tPrecision | Micro | 0.799 | Macro | 0.786 | Weighted | 0.797 \n",
      "\tRecall    | Micro | 0.799 | Macro | 0.744 | Weighted | 0.798 \n",
      "\tF1        | Micro | 0.799 | Macro | 0.760 | Weighted | 0.799\n",
      "Epoch: 2173, Train Loss: 0.770, Validation Loss: 0.938, LR: 0.000057 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.793 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.747 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 2174, Train Loss: 0.770, Validation Loss: 0.938, LR: 0.000057 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.795 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.741 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.760 | Weighted | 0.801\n",
      "Epoch: 2175, Train Loss: 0.770, Validation Loss: 0.938, LR: 0.000057 Accuracy: 0.801 \n",
      "\tPrecision | Micro | 0.801 | Macro | 0.791 | Weighted | 0.798 \n",
      "\tRecall    | Micro | 0.801 | Macro | 0.742 | Weighted | 0.800 \n",
      "\tF1        | Micro | 0.801 | Macro | 0.759 | Weighted | 0.801\n",
      "Epoch: 2176, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000057 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.785 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.783 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2177, Train Loss: 0.770, Validation Loss: 0.941, LR: 0.000057 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.783 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.752 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.764 | Weighted | 0.802\n",
      "Epoch: 2178, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.791 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.761 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.774 | Weighted | 0.804\n",
      "Epoch: 2179, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000057 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.762 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 2180, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.799 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.778 | Weighted | 0.810\n",
      "Epoch: 2181, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2182, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2183, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2184, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.798 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.763 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.777 | Weighted | 0.809\n",
      "Epoch: 2185, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000056 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.761 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.776 | Weighted | 0.807\n",
      "Epoch: 2186, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000056 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2187, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2188, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2189, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.783 | Weighted | 0.810\n",
      "Epoch: 2190, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2191, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2192, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000056 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.795 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.779 | Weighted | 0.809\n",
      "Epoch: 2193, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2194, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000056 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2195, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2196, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2197, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000056 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2198, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000055 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2199, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.792 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.777 | Weighted | 0.806\n",
      "Epoch: 2200, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000055 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2201, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2202, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000055 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.795 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.779 | Weighted | 0.809\n",
      "Epoch: 2203, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.793 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2204, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.793 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2205, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.791 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.762 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.774 | Weighted | 0.806\n",
      "Epoch: 2206, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2207, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2208, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2209, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2210, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2211, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2212, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000055 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2213, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2214, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000055 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2215, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000055 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2216, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2217, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 2218, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2219, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 2220, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2221, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2222, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2223, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2224, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2225, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2226, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2227, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2228, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2229, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2230, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2231, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2232, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000054 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2233, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000054 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2234, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2235, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2236, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.759 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 2237, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2238, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2239, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2240, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2241, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2242, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2243, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2244, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000053 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.803 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 2245, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000053 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2246, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2247, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2248, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.800 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2249, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2250, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2251, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2252, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000053 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2253, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.799 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2254, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2255, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.783 | Weighted | 0.814\n",
      "Epoch: 2256, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2257, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.804 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2258, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2259, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2260, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2261, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2262, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2263, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000052 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2264, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2265, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2266, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2267, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000052 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.800 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.759 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 2268, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2269, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000052 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2270, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.776 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 2271, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000052 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.776 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2272, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2273, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2274, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000051 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2275, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000051 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 2276, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2277, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2278, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000051 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2279, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000051 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2280, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000051 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.755 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.773 | Weighted | 0.812\n",
      "Epoch: 2281, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2282, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000051 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.791 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2283, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2284, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.771 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.786 | Weighted | 0.817\n",
      "Epoch: 2285, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2286, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2287, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000051 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.791 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.773 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2288, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.769 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.785 | Weighted | 0.817\n",
      "Epoch: 2289, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000051 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2290, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2291, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000051 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.792 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2292, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000050 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.765 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.783 | Weighted | 0.817\n",
      "Epoch: 2293, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000050 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.783 | Weighted | 0.814\n",
      "Epoch: 2294, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000050 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2295, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000050 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.785 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.775 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.779 | Weighted | 0.807\n",
      "Epoch: 2296, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000050 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.781 | Weighted | 0.814\n",
      "Epoch: 2297, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000050 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.763 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 2298, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000050 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.784 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.775 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.779 | Weighted | 0.807\n",
      "Epoch: 2299, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000050 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2300, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000050 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.762 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.778 | Weighted | 0.812\n",
      "Epoch: 2301, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000050 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2302, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000050 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2303, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000050 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2304, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000050 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.757 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 2305, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000050 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.789 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.776 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2306, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000050 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.792 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2307, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000050 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2308, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000050 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2309, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000050 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2310, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000050 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.813 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.787 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.798 | Weighted | 0.823\n",
      "Epoch: 2311, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000050 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2312, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000049 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.798 | Weighted | 0.822\n",
      "Epoch: 2313, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000049 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.805 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2314, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000049 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.787 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.799 | Weighted | 0.823\n",
      "Epoch: 2315, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2316, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 2317, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000049 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.804 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2318, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.811 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2319, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.805 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 2320, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000049 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.811 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2321, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.809 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.756 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.775 | Weighted | 0.809\n",
      "Epoch: 2322, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000049 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.800 | Weighted | 0.801 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.754 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.771 | Weighted | 0.804\n",
      "Epoch: 2323, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.805 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.778 | Weighted | 0.809\n",
      "Epoch: 2324, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.809 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.758 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.777 | Weighted | 0.809\n",
      "Epoch: 2325, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.810 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 2326, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000049 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.810 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 2327, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000049 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.811 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2328, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000049 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.812 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2329, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.811 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2330, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.811 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2331, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000049 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.806 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2332, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.806 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2333, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.806 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2334, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.805 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.762 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.778 | Weighted | 0.809\n",
      "Epoch: 2335, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.806 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2336, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.808 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2337, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000048 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.808 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2338, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.808 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2339, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000048 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.815 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.785 | Weighted | 0.815\n",
      "Epoch: 2340, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.806 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.763 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2341, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.769 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2342, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.808 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.769 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2343, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.760 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.779 | Weighted | 0.814\n",
      "Epoch: 2344, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000048 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.800 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.763 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2345, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.796 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.778 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 2346, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000048 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2347, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2348, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000048 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.769 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2349, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.797 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2350, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000048 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.808 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.755 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.774 | Weighted | 0.809\n",
      "Epoch: 2351, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000048 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.800 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.781 | Weighted | 0.806\n",
      "Epoch: 2352, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000048 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2353, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.783 | Weighted | 0.814\n",
      "Epoch: 2354, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.808 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2355, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000047 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.770 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2356, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 2357, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.815 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.765 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 2358, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2359, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2360, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2361, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2362, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000047 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.770 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2363, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2364, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.812 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.765 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2365, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.804 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 2366, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2367, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2368, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.810 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.760 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2369, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2370, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2371, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000047 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.783 | Weighted | 0.814\n",
      "Epoch: 2372, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.811 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.764 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.781 | Weighted | 0.810\n",
      "Epoch: 2373, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000047 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.782 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 2374, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000046 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 2375, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000046 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.810 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.757 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810\n",
      "Epoch: 2376, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000046 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2377, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000046 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 2378, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2379, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.770 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2380, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 2381, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.803 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 2382, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.766 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.783 | Weighted | 0.814\n",
      "Epoch: 2383, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 2384, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 2385, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2386, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000046 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2387, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 2388, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 2389, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.785 | Weighted | 0.812\n",
      "Epoch: 2390, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 2391, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 2392, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 2393, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 2394, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000046 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 2395, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000046 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2396, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000045 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2397, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000045 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.790 | Weighted | 0.814\n",
      "Epoch: 2398, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000045 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.817 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 2399, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000045 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.814 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2400, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000045 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2401, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000045 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2402, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000045 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 2403, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000045 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.816 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820\n",
      "Epoch: 2404, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000045 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2405, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000045 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2406, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000045 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.812 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.799 | Weighted | 0.822\n",
      "Epoch: 2407, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000045 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.776 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 2408, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000045 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 2409, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000045 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.811 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.767 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2410, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000045 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2411, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000045 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.806 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 2412, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000045 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.782 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 2413, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000045 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.809 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.753 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.773 | Weighted | 0.810\n",
      "Epoch: 2414, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000045 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.815 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.783 | Weighted | 0.815\n",
      "Epoch: 2415, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000045 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.783 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.785 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.783 | Weighted | 0.810\n",
      "Epoch: 2416, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000045 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2417, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000045 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.804 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.746 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.766 | Weighted | 0.806\n",
      "Epoch: 2418, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000044 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.787 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.777 | Weighted | 0.802 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.781 | Weighted | 0.806\n",
      "Epoch: 2419, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.807 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 2420, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 2421, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000044 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.801 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.785 | Weighted | 0.815\n",
      "Epoch: 2422, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2423, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2424, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.776 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.790 | Weighted | 0.818\n",
      "Epoch: 2425, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2426, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.768 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2427, Train Loss: 0.770, Validation Loss: 0.937, LR: 0.000044 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.801 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.745 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.765 | Weighted | 0.806\n",
      "Epoch: 2428, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000044 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.804 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.760 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.777 | Weighted | 0.807\n",
      "Epoch: 2429, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000044 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.793 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.773 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2430, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2431, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2432, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2433, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2434, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2435, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2436, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2437, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2438, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2439, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2440, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000044 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2441, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2442, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2443, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2444, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2445, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2446, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2447, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2448, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2449, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2450, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2451, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2452, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2453, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2454, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.781 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2455, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2456, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2457, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2458, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2459, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2460, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2461, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2462, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2463, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000043 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2464, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000042 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2465, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2466, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2467, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2468, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2469, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2470, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2471, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2472, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2473, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.786 | Weighted | 0.817\n",
      "Epoch: 2474, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.786 | Weighted | 0.817\n",
      "Epoch: 2475, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.786 | Weighted | 0.817\n",
      "Epoch: 2476, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2477, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2478, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2479, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2480, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2481, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2482, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2483, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.774 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 2484, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.775 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.789 | Weighted | 0.820\n",
      "Epoch: 2485, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.775 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.789 | Weighted | 0.820\n",
      "Epoch: 2486, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 2487, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000042 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.776 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 2488, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.781 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.795 | Weighted | 0.823\n",
      "Epoch: 2489, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.781 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.795 | Weighted | 0.823\n",
      "Epoch: 2490, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.781 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.795 | Weighted | 0.823\n",
      "Epoch: 2491, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.779 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822\n",
      "Epoch: 2492, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.779 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822\n",
      "Epoch: 2493, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.784 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823\n",
      "Epoch: 2494, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.782 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.796 | Weighted | 0.822\n",
      "Epoch: 2495, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000041 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.783 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.799 | Weighted | 0.823\n",
      "Epoch: 2496, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000041 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2497, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000041 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.806 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2498, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.783 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.774 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.778 | Weighted | 0.804\n",
      "Epoch: 2499, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000041 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.773 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.783 | Weighted | 0.807\n",
      "Epoch: 2500, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000041 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.796 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.773 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.783 | Weighted | 0.807\n",
      "Epoch: 2501, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000041 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.792 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.772 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.781 | Weighted | 0.806\n",
      "Epoch: 2502, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000041 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.792 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.772 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.781 | Weighted | 0.806\n",
      "Epoch: 2503, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.792 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.772 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.781 | Weighted | 0.806\n",
      "Epoch: 2504, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2505, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2506, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2507, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2508, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2509, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2510, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2511, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2512, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000041 Accuracy: 0.804 \n",
      "\tPrecision | Micro | 0.804 | Macro | 0.789 | Weighted | 0.802 \n",
      "\tRecall    | Micro | 0.804 | Macro | 0.767 | Weighted | 0.801 \n",
      "\tF1        | Micro | 0.804 | Macro | 0.777 | Weighted | 0.804\n",
      "Epoch: 2513, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2514, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2515, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2516, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2517, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2518, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2519, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2520, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2521, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2522, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2523, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2524, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2525, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2526, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2527, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000040 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.794 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.769 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2528, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2529, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2530, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2531, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2532, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2533, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2534, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2535, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2536, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2537, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000040 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2538, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2539, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2540, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2541, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2542, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2543, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2544, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2545, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.781 | Weighted | 0.807\n",
      "Epoch: 2546, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2547, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2548, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2549, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2550, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2551, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2552, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2553, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2554, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2555, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2556, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2557, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2558, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2559, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2560, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2561, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2562, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000039 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2563, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2564, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.797 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2565, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2566, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2567, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2568, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2569, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.778 | Weighted | 0.807\n",
      "Epoch: 2570, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2571, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2572, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2573, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2574, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2575, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2576, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2577, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2578, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2579, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2580, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2581, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2582, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2583, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.800 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2584, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2585, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.783 | Weighted | 0.810\n",
      "Epoch: 2586, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000038 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.805 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2587, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000038 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 2588, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000038 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.800 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2589, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000037 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2590, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000037 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.787 | Weighted | 0.810\n",
      "Epoch: 2591, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2592, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.800 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2593, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2594, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.800 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2595, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.767 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 2596, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000037 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 2597, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000037 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 2598, Train Loss: 0.770, Validation Loss: 0.936, LR: 0.000037 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.804 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.761 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.776 | Weighted | 0.806\n",
      "Epoch: 2599, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000037 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.761 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.777 | Weighted | 0.810\n",
      "Epoch: 2600, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000037 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2601, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2602, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2603, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2604, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2605, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2606, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2607, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2608, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2609, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2610, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2611, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2612, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2613, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2614, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2615, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000037 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2616, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2617, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2618, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2619, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2620, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2621, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2622, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2623, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2624, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2625, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2626, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2627, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2628, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2629, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2630, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2631, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2632, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2633, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2634, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2635, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2636, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2637, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2638, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2639, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2640, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2641, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2642, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2643, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000036 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2644, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2645, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2646, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2647, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2648, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2649, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2650, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2651, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2652, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2653, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2654, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2655, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2656, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2657, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2658, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2659, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2660, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2661, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2662, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2663, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2664, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2665, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2666, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2667, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2668, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2669, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2670, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2671, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2672, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000035 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2673, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2674, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2675, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2676, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2677, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2678, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2679, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2680, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2681, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2682, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2683, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2684, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2685, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2686, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2687, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2688, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2689, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2690, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2691, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2692, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2693, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2694, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2695, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2696, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2697, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2698, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000034 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2699, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 2700, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000034 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 2701, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000034 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 2702, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000033 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2703, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2704, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2705, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 2706, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.773 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2707, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2708, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2709, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.806 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2710, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2711, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.768 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2712, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 2713, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2714, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2715, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000033 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 2716, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.808 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 2717, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820\n",
      "Epoch: 2718, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2719, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 2720, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.807 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 2721, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.777 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2722, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2723, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.808 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820\n",
      "Epoch: 2724, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2725, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2726, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2727, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820\n",
      "Epoch: 2728, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2729, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000033 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2730, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2731, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000033 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2732, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000033 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2733, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2734, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2735, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2736, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 2737, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2738, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2739, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2740, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.779 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2741, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2742, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000032 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.795 | Weighted | 0.820\n",
      "Epoch: 2743, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2744, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2745, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2746, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.801 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2747, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2748, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000032 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.777 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.791 | Weighted | 0.822\n",
      "Epoch: 2749, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2750, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000032 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 2751, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.776 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2752, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000032 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2753, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000032 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.801 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 2754, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2755, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000032 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.779 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.794 | Weighted | 0.822\n",
      "Epoch: 2756, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000032 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.799 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 2757, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2758, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.777 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2759, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000032 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.790 | Weighted | 0.814\n",
      "Epoch: 2760, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2761, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2762, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000032 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 2763, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000032 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2764, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2765, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000031 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2766, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2767, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2768, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2769, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2770, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2771, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2772, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2773, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2774, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2775, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2776, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2777, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2778, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 2779, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.774 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 2780, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2781, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000031 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2782, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2783, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2784, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2785, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000031 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.789 | Weighted | 0.814\n",
      "Epoch: 2786, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000031 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.785 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.798 | Weighted | 0.823\n",
      "Epoch: 2787, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000031 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.773 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.788 | Weighted | 0.818\n",
      "Epoch: 2788, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000031 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.797 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.779 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2789, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000031 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.812 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.786 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822\n",
      "Epoch: 2790, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000031 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2791, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000031 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.787 | Weighted | 0.810\n",
      "Epoch: 2792, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000031 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 2793, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000031 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.777 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820\n",
      "Epoch: 2794, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000031 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.799 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.779 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.787 | Weighted | 0.810\n",
      "Epoch: 2795, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000031 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 2796, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.779 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.794 | Weighted | 0.822\n",
      "Epoch: 2797, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 2798, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000030 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2799, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.782 | Weighted | 0.814\n",
      "Epoch: 2800, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.789 | Weighted | 0.814\n",
      "Epoch: 2801, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000030 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2802, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2803, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000030 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2804, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000030 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2805, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2806, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000030 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.780 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2807, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2808, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000030 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2809, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2810, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2811, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2812, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2813, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 2814, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.772 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2815, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000030 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2816, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.799 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.789 | Weighted | 0.814\n",
      "Epoch: 2817, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000030 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.809 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.796 | Weighted | 0.822\n",
      "Epoch: 2818, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000030 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.764 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.781 | Weighted | 0.815\n",
      "Epoch: 2819, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000030 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.787 | Weighted | 0.810\n",
      "Epoch: 2820, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000030 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.806 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.799 | Weighted | 0.823\n",
      "Epoch: 2821, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.774 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817\n",
      "Epoch: 2822, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.790 | Weighted | 0.814\n",
      "Epoch: 2823, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000030 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2824, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2825, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000030 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 2826, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000030 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.777 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820\n",
      "Epoch: 2827, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2828, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000030 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 2829, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2830, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.804 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.770 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.784 | Weighted | 0.815\n",
      "Epoch: 2831, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 2832, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000029 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2833, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.782 | Weighted | 0.814\n",
      "Epoch: 2834, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2835, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2836, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2837, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2838, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2839, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000029 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.795 | Weighted | 0.820\n",
      "Epoch: 2840, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2841, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2842, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000029 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2843, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2844, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2845, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.771 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 2846, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 2847, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 2848, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000029 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.782 | Weighted | 0.814\n",
      "Epoch: 2849, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000029 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2850, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 2851, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 2852, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000029 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.809 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.765 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.782 | Weighted | 0.814\n",
      "Epoch: 2853, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000029 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2854, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.807 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 2855, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000029 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.776 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 2856, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000029 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.798 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.764 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.778 | Weighted | 0.809\n",
      "Epoch: 2857, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2858, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.781 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 2859, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000029 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2860, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2861, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000029 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.779 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 2862, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000029 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2863, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000029 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.775 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 2864, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.772 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2865, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.789 | Weighted | 0.814\n",
      "Epoch: 2866, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2867, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.769 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.784 | Weighted | 0.814\n",
      "Epoch: 2868, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000028 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 2869, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000028 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2870, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000028 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.771 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2871, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 2872, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000028 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.799 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 2873, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000028 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2874, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000028 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.784 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.779 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 2875, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000028 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.776 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2876, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000028 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.786 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.774 | Weighted | 0.803 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.779 | Weighted | 0.807\n",
      "Epoch: 2877, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000028 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.783 | Weighted | 0.810\n",
      "Epoch: 2878, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000028 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.791 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.783 | Weighted | 0.810\n",
      "Epoch: 2879, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.776 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 2880, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.794 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 2881, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 2882, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2883, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2884, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2885, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2886, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.797 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2887, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2888, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2889, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2890, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2891, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2892, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2893, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2894, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2895, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2896, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.798 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2897, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.800 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 2898, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000028 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2899, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2900, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2901, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2902, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2903, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.802 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 2904, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2905, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 2906, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2907, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2908, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2909, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2910, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2911, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2912, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2913, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2914, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2915, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 2916, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2917, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2918, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2919, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2920, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2921, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2922, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2923, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2924, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2925, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2926, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2927, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2928, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2929, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2930, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2931, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2932, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2933, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2934, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2935, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000027 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2936, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2937, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2938, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2939, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 2940, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.767 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.780 | Weighted | 0.809\n",
      "Epoch: 2941, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2942, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.802 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.770 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 2943, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.765 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.779 | Weighted | 0.810\n",
      "Epoch: 2944, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.768 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 2945, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.767 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.781 | Weighted | 0.812\n",
      "Epoch: 2946, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.766 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.780 | Weighted | 0.812\n",
      "Epoch: 2947, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000026 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 2948, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2949, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000026 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.805 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.773 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 2950, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000026 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.806 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 2951, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.803 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.771 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.785 | Weighted | 0.814\n",
      "Epoch: 2952, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.800 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.766 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 2953, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000026 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.799 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 2954, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000026 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.802 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 2955, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.799 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.766 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.779 | Weighted | 0.807\n",
      "Epoch: 2956, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.795 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.776 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.784 | Weighted | 0.807\n",
      "Epoch: 2957, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000026 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.783 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.788 | Weighted | 0.812\n",
      "Epoch: 2958, Train Loss: 0.770, Validation Loss: 0.937, LR: 0.000026 Accuracy: 0.802 \n",
      "\tPrecision | Micro | 0.802 | Macro | 0.793 | Weighted | 0.800 \n",
      "\tRecall    | Micro | 0.802 | Macro | 0.757 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.802 | Macro | 0.770 | Weighted | 0.802\n",
      "Epoch: 2959, Train Loss: 0.770, Validation Loss: 0.935, LR: 0.000026 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.797 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2960, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000026 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.797 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.768 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.780 | Weighted | 0.806\n",
      "Epoch: 2961, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.782 | Weighted | 0.807\n",
      "Epoch: 2962, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.782 | Weighted | 0.807\n",
      "Epoch: 2963, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.782 | Weighted | 0.807\n",
      "Epoch: 2964, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.782 | Weighted | 0.807\n",
      "Epoch: 2965, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.798 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.782 | Weighted | 0.807\n",
      "Epoch: 2966, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2967, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2968, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2969, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2970, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2971, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2972, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2973, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2974, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000026 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2975, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2976, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2977, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2978, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2979, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2980, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2981, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2982, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2983, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2984, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2985, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2986, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2987, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2988, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2989, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2990, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2991, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2992, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2993, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2994, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2995, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2996, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 2997, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2998, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 2999, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3000, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3001, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3002, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3003, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3004, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3005, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3006, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3007, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3008, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3009, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3010, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3011, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3012, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3013, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3014, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000025 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3015, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.799 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3016, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000024 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 3017, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000024 Accuracy: 0.807 \n",
      "\tPrecision | Micro | 0.807 | Macro | 0.794 | Weighted | 0.805 \n",
      "\tRecall    | Micro | 0.807 | Macro | 0.770 | Weighted | 0.805 \n",
      "\tF1        | Micro | 0.807 | Macro | 0.780 | Weighted | 0.807\n",
      "Epoch: 3018, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.796 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.771 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 3019, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000024 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.798 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.786 | Weighted | 0.810\n",
      "Epoch: 3020, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 3021, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 3022, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.793 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.783 | Weighted | 0.809\n",
      "Epoch: 3023, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 3024, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 3025, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 3026, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.790 | Weighted | 0.807 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.774 | Weighted | 0.806 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.781 | Weighted | 0.809\n",
      "Epoch: 3027, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.794 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 3028, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3029, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3030, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3031, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3032, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3033, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3034, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3035, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3036, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3037, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3038, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3039, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3040, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3041, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3042, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 3043, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.796 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3044, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 3045, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3046, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 3047, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3048, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.793 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.784 | Weighted | 0.812\n",
      "Epoch: 3049, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000024 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 3050, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000024 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3051, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000024 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.799 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 3052, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000024 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.804 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3053, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000024 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.794 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 3054, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000024 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3055, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000024 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3056, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000024 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3057, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3058, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3059, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3060, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3061, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3062, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3063, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3064, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3065, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3066, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3067, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3068, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3069, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 3070, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 3071, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 3072, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 3073, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.784 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.787 | Weighted | 0.814\n",
      "Epoch: 3074, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3075, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3076, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3077, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3078, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3079, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3080, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3081, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3082, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3083, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3084, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3085, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3086, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3087, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3088, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3089, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3090, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.796 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3091, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3092, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3093, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3094, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3095, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3096, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3097, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3098, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3099, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000023 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3100, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3101, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3102, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3103, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3104, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3105, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.797 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3106, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3107, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3108, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3109, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.791 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.787 | Weighted | 0.815\n",
      "Epoch: 3110, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3111, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.793 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.788 | Weighted | 0.817\n",
      "Epoch: 3112, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3113, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3114, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3115, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3116, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3117, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3118, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3119, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3120, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3121, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3122, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3123, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3124, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3125, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3126, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3127, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3128, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3129, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3130, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3131, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3132, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3133, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3134, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3135, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3136, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.793 | Weighted | 0.820\n",
      "Epoch: 3137, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.794 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.789 | Weighted | 0.818\n",
      "Epoch: 3138, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000022 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.799 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.796 | Weighted | 0.822\n",
      "Epoch: 3139, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3140, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3141, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000022 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3142, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.798 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3143, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000022 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.798 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3144, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000022 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.793 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.791 | Weighted | 0.815\n",
      "Epoch: 3145, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.798 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3146, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3147, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3148, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3149, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3150, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3151, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.792 | Weighted | 0.818\n",
      "Epoch: 3152, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3153, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.802 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3154, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3155, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3156, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.800 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818\n",
      "Epoch: 3157, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3158, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3159, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3160, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3161, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.802 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3162, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.799 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3163, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3164, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3165, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.803 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3166, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3167, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3168, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3169, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3170, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3171, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 3172, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.803 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3173, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000021 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 3174, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.798 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.794 | Weighted | 0.818\n",
      "Epoch: 3175, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3176, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3177, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 3178, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3179, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3180, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3181, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 3182, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3183, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3184, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.802 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.795 | Weighted | 0.820\n",
      "Epoch: 3185, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.789 | Weighted | 0.815\n",
      "Epoch: 3186, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.804 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.794 | Weighted | 0.820\n",
      "Epoch: 3187, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.801 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 3188, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000021 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3189, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.802 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3190, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000021 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.794 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.779 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 3191, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.799 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 3192, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000021 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.799 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 3193, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000020 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3194, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.799 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.778 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.787 | Weighted | 0.817\n",
      "Epoch: 3195, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.799 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.788 | Weighted | 0.815\n",
      "Epoch: 3196, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3197, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3198, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3199, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3200, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.802 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.791 | Weighted | 0.818\n",
      "Epoch: 3201, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.798 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.786 | Weighted | 0.815\n",
      "Epoch: 3202, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3203, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3204, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3205, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3206, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3207, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3208, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3209, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3210, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3211, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3212, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.800 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.790 | Weighted | 0.817\n",
      "Epoch: 3213, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3214, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.798 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.785 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.791 | Weighted | 0.817\n",
      "Epoch: 3215, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3216, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000020 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.797 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.784 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3217, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3218, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000020 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.795 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.783 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3219, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000020 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.800 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.786 | Weighted | 0.814\n",
      "Epoch: 3220, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 3221, Train Loss: 0.770, Validation Loss: 0.934, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.801 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.771 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 3222, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 3223, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.795 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.784 | Weighted | 0.810\n",
      "Epoch: 3224, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.796 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.778 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.786 | Weighted | 0.812\n",
      "Epoch: 3225, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.794 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.782 | Weighted | 0.810\n",
      "Epoch: 3226, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3227, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.795 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3228, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.793 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.770 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.780 | Weighted | 0.810\n",
      "Epoch: 3229, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.797 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.782 | Weighted | 0.812\n",
      "Epoch: 3230, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.801 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.771 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.783 | Weighted | 0.812\n",
      "Epoch: 3231, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.789 | Weighted | 0.804 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.775 | Weighted | 0.806\n",
      "Epoch: 3232, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000020 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.801 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.777 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.787 | Weighted | 0.809\n",
      "Epoch: 3233, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000020 Accuracy: 0.806 \n",
      "\tPrecision | Micro | 0.806 | Macro | 0.800 | Weighted | 0.803 \n",
      "\tRecall    | Micro | 0.806 | Macro | 0.765 | Weighted | 0.804 \n",
      "\tF1        | Micro | 0.806 | Macro | 0.779 | Weighted | 0.806\n",
      "Epoch: 3234, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000020 Accuracy: 0.809 \n",
      "\tPrecision | Micro | 0.809 | Macro | 0.802 | Weighted | 0.806 \n",
      "\tRecall    | Micro | 0.809 | Macro | 0.768 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.809 | Macro | 0.782 | Weighted | 0.809\n",
      "Epoch: 3235, Train Loss: 0.770, Validation Loss: 0.933, LR: 0.000020 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.773 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3236, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 3237, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 3238, Train Loss: 0.770, Validation Loss: 0.932, LR: 0.000020 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 3239, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3240, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3241, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.777 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3242, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000020 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3243, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3244, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3245, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.775 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.788 | Weighted | 0.814\n",
      "Epoch: 3246, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3247, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3248, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3249, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3250, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3251, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3252, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3253, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3254, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3255, Train Loss: 0.770, Validation Loss: 0.931, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3256, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3257, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3258, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3259, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3260, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3261, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3262, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3263, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3264, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3265, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3266, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3267, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.772 | Weighted | 0.808 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.785 | Weighted | 0.810\n",
      "Epoch: 3268, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3269, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3270, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3271, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3272, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3273, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3274, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3275, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3276, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3277, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3278, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3279, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3280, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3281, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3282, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3283, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3284, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3285, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3286, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3287, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3288, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3289, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3290, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3291, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3292, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3293, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3294, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3295, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000019 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3296, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3297, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3298, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3299, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3300, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3301, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3302, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3303, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3304, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3305, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3306, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3307, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3308, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3309, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3310, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3311, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3312, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3313, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3314, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3315, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3316, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3317, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3318, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3319, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3320, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3321, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3322, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3323, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3324, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3325, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3326, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3327, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3328, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3329, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3330, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3331, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3332, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3333, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3334, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3335, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.804 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.775 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3336, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3337, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3338, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3339, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3340, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3341, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3342, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3343, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3344, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3345, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3346, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3347, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3348, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3349, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000018 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3350, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000018 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3351, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.805 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.774 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812\n",
      "Epoch: 3352, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3353, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3354, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3355, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3356, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3357, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3358, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3359, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3360, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3361, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3362, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3363, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3364, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3365, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3366, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3367, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3368, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3369, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3370, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3371, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3372, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3373, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3374, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3375, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3376, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 3377, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3378, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.792 | Weighted | 0.812\n",
      "Epoch: 3379, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3380, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3381, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3382, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3383, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3384, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3385, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3386, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3387, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.780 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3388, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3389, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.794 | Weighted | 0.814\n",
      "Epoch: 3390, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3391, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3392, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3393, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000017 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3394, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3395, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3396, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.792 | Weighted | 0.814\n",
      "Epoch: 3397, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3398, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3399, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3400, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3401, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3402, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3403, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3404, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3405, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3406, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3407, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000017 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3408, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000017 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3409, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000017 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3410, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3411, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3412, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3413, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3414, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3415, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.808 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.776 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815\n",
      "Epoch: 3416, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3417, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3418, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3419, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3420, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3421, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3422, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3423, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3424, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3425, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3426, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3427, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3428, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3429, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3430, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3431, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3432, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3433, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3434, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3435, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3436, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3437, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3438, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3439, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3440, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3441, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3442, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3443, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3444, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3445, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3446, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000016 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3447, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3448, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3449, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3450, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3451, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3452, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3453, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3454, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3455, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3456, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3457, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3458, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3459, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3460, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3461, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3462, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3463, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3464, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.793 | Weighted | 0.815\n",
      "Epoch: 3465, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3466, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3467, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3468, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3469, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000016 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3470, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000016 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3471, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3472, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000016 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3473, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3474, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3475, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3476, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3477, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3478, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3479, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3480, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3481, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3482, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3483, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.792 | Weighted | 0.817\n",
      "Epoch: 3484, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3485, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3486, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3487, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3488, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3489, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3490, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3491, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3492, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3493, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.797 | Weighted | 0.820\n",
      "Epoch: 3494, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.777 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.789 | Weighted | 0.812\n",
      "Epoch: 3495, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3496, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3497, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.794 | Weighted | 0.814\n",
      "Epoch: 3498, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3499, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3500, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3501, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3502, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3503, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 3504, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3505, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3506, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3507, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3508, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 3509, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3510, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 3511, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 3512, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3513, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.785 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.798 | Weighted | 0.822\n",
      "Epoch: 3514, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3515, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.778 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3516, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3517, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3518, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.784 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820\n",
      "Epoch: 3519, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 3520, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3521, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3522, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3523, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3524, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3525, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3526, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3527, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3528, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3529, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3530, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3531, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3532, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3533, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3534, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3535, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.793 | Weighted | 0.817\n",
      "Epoch: 3536, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000015 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.783 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 3537, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000015 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3538, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000015 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3539, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3540, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.812 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 3541, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3542, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3543, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3544, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3545, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 3546, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3547, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3548, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3549, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3550, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3551, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3552, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3553, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3554, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3555, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3556, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 3557, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.795 | Weighted | 0.817\n",
      "Epoch: 3558, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3559, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3560, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3561, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.785 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3562, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3563, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.779 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 3564, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3565, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3566, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3567, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3568, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3569, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3570, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3571, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3572, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.795 | Weighted | 0.815\n",
      "Epoch: 3573, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 3574, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3575, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3576, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3577, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3578, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.808 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 3579, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3580, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3581, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3582, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000014 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3583, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3584, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3585, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3586, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3587, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3588, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3589, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3590, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3591, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.788 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.797 | Weighted | 0.818\n",
      "Epoch: 3592, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3593, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 3594, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3595, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3596, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 3597, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3598, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3599, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3600, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3601, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3602, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.781 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3603, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.813 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 3604, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3605, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.782 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.794 | Weighted | 0.817\n",
      "Epoch: 3606, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.788 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 3607, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3608, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3609, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000014 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 3610, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000014 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3611, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 3612, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3613, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.796 | Weighted | 0.814\n",
      "Epoch: 3614, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3615, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.786 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 3616, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 3617, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000013 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3618, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.794 | Weighted | 0.814\n",
      "Epoch: 3619, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000013 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3620, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000013 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.785 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.794 | Weighted | 0.814\n",
      "Epoch: 3621, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000013 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.783 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.795 | Weighted | 0.818\n",
      "Epoch: 3622, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000013 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 3623, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000013 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.778 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 3624, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000013 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.780 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.792 | Weighted | 0.815\n",
      "Epoch: 3625, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000013 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.805 | Weighted | 0.809 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.776 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.788 | Weighted | 0.810\n",
      "Epoch: 3626, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000013 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.789 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3627, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000013 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 3628, Train Loss: 0.770, Validation Loss: 0.930, LR: 0.000013 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.780 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.792 | Weighted | 0.810\n",
      "Epoch: 3629, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.804 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.811 | Weighted | 0.823\n",
      "Epoch: 3630, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.803 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.812 | Weighted | 0.825\n",
      "Epoch: 3631, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3632, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3633, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3634, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3635, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3636, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3637, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3638, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.806 | Weighted | 0.820\n",
      "Epoch: 3639, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3640, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3641, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3642, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.807 | Weighted | 0.822\n",
      "Epoch: 3643, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3644, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3645, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3646, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3647, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3648, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3649, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3650, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 3651, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3652, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3653, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3654, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3655, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3656, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3657, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3658, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3659, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3660, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3661, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3662, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3663, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3664, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3665, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3666, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3667, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3668, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3669, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3670, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3671, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3672, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3673, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3674, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3675, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3676, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3677, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3678, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3679, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3680, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3681, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3682, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3683, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3684, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3685, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3686, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3687, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000013 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3688, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3689, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3690, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3691, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3692, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3693, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3694, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3695, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3696, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3697, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3698, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3699, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3700, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3701, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3702, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3703, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3704, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3705, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3706, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3707, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3708, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3709, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3710, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3711, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3712, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3713, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3714, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3715, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3716, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3717, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3718, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3719, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3720, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3721, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3722, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3723, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3724, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3725, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3726, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3727, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3728, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3729, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3730, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3731, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3732, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3733, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3734, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3735, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3736, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3737, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3738, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3739, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3740, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3741, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3742, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3743, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3744, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3745, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3746, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3747, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3748, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3749, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3750, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3751, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3752, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3753, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3754, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3755, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3756, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3757, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3758, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3759, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3760, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3761, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3762, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3763, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3764, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3765, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3766, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3767, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3768, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3769, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3770, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000012 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3771, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3772, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3773, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3774, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3775, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3776, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3777, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3778, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3779, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3780, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3781, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3782, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3783, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3784, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3785, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3786, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3787, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3788, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3789, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3790, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3791, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3792, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3793, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3794, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3795, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3796, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3797, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3798, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3799, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3800, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3801, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3802, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3803, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3804, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3805, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3806, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3807, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3808, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3809, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3810, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3811, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3812, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3813, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3814, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3815, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3816, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3817, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3818, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3819, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.821 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3820, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3821, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3822, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3823, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3824, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3825, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3826, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3827, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3828, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3829, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3830, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3831, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3832, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3833, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3834, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3835, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3836, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3837, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3838, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3839, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3840, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3841, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3842, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3843, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3844, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3845, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3846, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3847, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3848, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3849, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3850, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3851, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3852, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3853, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3854, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3855, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3856, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3857, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3858, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3859, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3860, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3861, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000011 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3862, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3863, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3864, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3865, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3866, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3867, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3868, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3869, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3870, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3871, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3872, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3873, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3874, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3875, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3876, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3877, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3878, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3879, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3880, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3881, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3882, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3883, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3884, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3885, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3886, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3887, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3888, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3889, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3890, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3891, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3892, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3893, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 3894, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3895, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3896, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3897, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3898, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 3899, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3900, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3901, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 3902, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3903, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3904, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.824 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3905, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3906, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3907, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3908, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3909, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3910, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3911, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3912, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3913, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3914, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 3915, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3916, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3917, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3918, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.828 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 3919, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3920, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.825 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.811 | Weighted | 0.827\n",
      "Epoch: 3921, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3922, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3923, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3924, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.804 | Weighted | 0.823\n",
      "Epoch: 3925, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3926, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3927, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3928, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3929, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3930, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3931, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3932, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3933, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3934, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 3935, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3936, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3937, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3938, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3939, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3940, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3941, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3942, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3943, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 3944, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3945, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 3946, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3947, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3948, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.806 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 3949, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3950, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3951, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 3952, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.826 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.795 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 3953, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3954, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3955, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3956, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3957, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3958, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3959, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000010 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 3960, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3961, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000010 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3962, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3963, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3964, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3965, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3966, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 3967, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3968, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3969, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3970, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3971, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.815 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3972, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.816 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 3973, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3974, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3975, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3976, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3977, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3978, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3979, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3980, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 3981, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3982, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3983, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 3984, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3985, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 3986, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3987, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3988, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3989, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 3990, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 3991, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3992, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3993, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3994, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3995, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 3996, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 3997, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 3998, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.814 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 3999, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4000, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4001, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4002, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4003, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.815 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4004, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4005, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.815 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 4006, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4007, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4008, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4009, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4010, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4011, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 4012, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4013, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4014, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4015, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4016, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4017, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4018, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4019, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.819 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4020, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4021, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4022, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4023, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4024, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.809 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 4025, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4026, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4027, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4028, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4029, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4030, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4031, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4032, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.814 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4033, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4034, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4035, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4036, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4037, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4038, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.815 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 4039, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4040, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4041, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4042, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4043, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4044, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4045, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.814 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4046, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4047, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4048, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4049, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4050, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4051, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4052, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4053, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4054, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4055, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4056, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4057, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.823 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4058, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4059, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4060, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4061, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4062, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4063, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4064, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4065, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4066, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4067, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4068, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4069, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4070, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4071, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000009 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4072, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000009 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4073, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4074, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4075, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4076, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4077, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4078, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4079, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4080, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4081, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4082, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4083, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4084, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4085, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4086, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4087, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4088, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4089, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4090, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4091, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4092, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4093, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4094, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4095, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4096, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4097, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4098, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4099, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4100, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4101, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.825 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4102, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4103, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4104, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4105, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4106, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4107, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4108, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4109, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4110, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4111, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4112, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4113, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4114, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4115, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4116, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4117, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4118, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4119, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4120, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4121, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4122, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4123, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4124, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4125, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4126, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4127, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4128, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4129, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4130, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4131, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4132, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4133, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4134, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4135, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4136, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4137, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4138, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4139, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4140, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4141, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4142, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4143, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4144, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4145, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4146, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4147, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4148, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4149, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4150, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4151, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4152, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4153, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4154, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4155, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4156, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4157, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4158, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4159, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4160, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4161, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4162, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4163, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4164, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4165, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4166, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4167, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4168, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4169, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4170, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4171, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4172, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4173, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4174, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4175, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4176, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4177, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4178, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4179, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4180, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4181, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4182, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4183, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4184, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4185, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4186, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4187, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4188, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4189, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4190, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4191, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4192, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4193, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4194, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4195, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4196, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000008 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4197, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000008 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4198, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4199, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4200, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4201, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4202, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4203, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4204, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4205, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4206, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4207, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4208, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4209, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4210, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4211, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4212, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4213, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4214, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4215, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4216, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4217, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4218, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4219, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4220, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4221, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4222, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4223, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4224, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4225, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4226, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4227, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4228, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4229, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4230, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4231, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4232, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4233, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4234, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4235, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4236, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4237, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4238, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4239, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4240, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4241, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4242, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4243, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4244, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4245, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4246, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4247, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4248, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4249, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4250, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4251, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4252, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4253, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4254, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4255, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4256, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4257, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4258, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4259, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4260, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4261, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4262, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4263, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4264, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4265, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4266, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4267, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4268, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4269, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4270, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4271, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4272, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4273, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4274, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4275, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4276, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4277, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4278, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4279, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4280, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4281, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4282, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4283, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4284, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4285, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4286, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4287, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4288, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4289, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4290, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4291, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4292, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4293, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4294, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4295, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4296, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4297, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4298, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4299, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4300, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4301, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4302, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4303, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4304, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4305, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4306, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4307, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4308, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4309, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4310, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4311, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4312, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4313, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4314, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4315, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4316, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4317, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4318, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4319, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4320, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4321, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4322, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4323, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4324, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4325, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4326, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4327, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.791 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4328, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4329, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4330, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4331, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4332, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4333, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4334, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4335, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4336, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4337, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4338, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4339, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4340, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000007 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4341, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4342, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4343, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4344, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4345, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4346, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4347, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4348, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4349, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4350, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4351, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4352, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4353, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4354, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4355, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4356, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4357, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4358, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4359, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4360, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4361, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4362, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4363, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4364, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4365, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4366, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4367, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4368, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4369, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4370, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4371, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4372, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4373, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4374, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4375, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4376, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4377, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4378, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4379, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4380, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4381, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4382, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4383, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4384, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4385, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4386, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4387, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4388, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4389, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4390, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.811 | Weighted | 0.825\n",
      "Epoch: 4391, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4392, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.808 | Weighted | 0.822\n",
      "Epoch: 4393, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4394, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4395, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.811 | Weighted | 0.825\n",
      "Epoch: 4396, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4397, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4398, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4399, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4400, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.808 | Weighted | 0.822\n",
      "Epoch: 4401, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.819 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 4402, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4403, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4404, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4405, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.808 | Weighted | 0.822\n",
      "Epoch: 4406, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.819 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 4407, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4408, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4409, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4410, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.811 | Weighted | 0.825\n",
      "Epoch: 4411, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4412, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.819 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4413, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4414, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.824 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4415, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4416, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4417, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4418, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4419, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.810 | Weighted | 0.825\n",
      "Epoch: 4420, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.796 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4421, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4422, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4423, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4424, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4425, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4426, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.808 | Weighted | 0.822\n",
      "Epoch: 4427, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.819 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 4428, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.806 | Weighted | 0.822\n",
      "Epoch: 4429, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4430, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4431, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.822 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.809 | Weighted | 0.823\n",
      "Epoch: 4432, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4433, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4434, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4435, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.821 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 4436, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.808 | Weighted | 0.822\n",
      "Epoch: 4437, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.818 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.799 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.808 | Weighted | 0.823\n",
      "Epoch: 4438, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.823 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.811 | Weighted | 0.825\n",
      "Epoch: 4439, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4440, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4441, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.803 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4442, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4443, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4444, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4445, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4446, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4447, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4448, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4449, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4450, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4451, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4452, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4453, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4454, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4455, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4456, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4457, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4458, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4459, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4460, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4461, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4462, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4463, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4464, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4465, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4466, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4467, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4468, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4469, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4470, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4471, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4472, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4473, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4474, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4475, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4476, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4477, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4478, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4479, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4480, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4481, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4482, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.820 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.803 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4483, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4484, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.820 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.803 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4485, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4486, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4487, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4488, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.816 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.800 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 4489, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4490, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4491, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4492, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4493, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4494, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4495, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4496, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.803 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4497, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.809 | Weighted | 0.825\n",
      "Epoch: 4498, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.804 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 4499, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000006 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.804 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 4500, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4501, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000006 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.822 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.805 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.813 | Weighted | 0.830\n",
      "Epoch: 4502, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.810 | Weighted | 0.827\n",
      "Epoch: 4503, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000006 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.823 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.805 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.813 | Weighted | 0.830\n",
      "Epoch: 4504, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.818 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.801 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 4505, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000006 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.823 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.805 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.813 | Weighted | 0.830\n",
      "Epoch: 4506, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000006 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.818 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.804 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.810 | Weighted | 0.828\n",
      "Epoch: 4507, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000006 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.821 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.803 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 4508, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000005 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.817 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 4509, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000005 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.825 | Weighted | 0.826 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.803 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.813 | Weighted | 0.828\n",
      "Epoch: 4510, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000005 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.817 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.802 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 4511, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000005 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.800 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 4512, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4513, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4514, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4515, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000005 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.807 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 4516, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 4517, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000005 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 4518, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000005 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 4519, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000005 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.814 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 4520, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4521, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4522, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4523, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4524, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4525, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4526, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4527, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4528, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4529, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4530, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4531, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4532, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4533, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4534, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 4535, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4536, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4537, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4538, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4539, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4540, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4541, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4542, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4543, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4544, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4545, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4546, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4547, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4548, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 4549, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4550, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4551, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4552, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4553, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4554, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4555, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4556, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4557, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4558, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4559, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4560, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4561, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.809 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 4562, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4563, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4564, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4565, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4566, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4567, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4568, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4569, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4570, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4571, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4572, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4573, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4574, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4575, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4576, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4577, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4578, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4579, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 4580, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4581, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4582, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4583, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4584, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4585, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4586, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4587, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4588, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4589, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4590, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4591, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4592, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4593, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4594, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4595, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4596, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4597, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4598, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4599, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4600, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4601, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4602, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4603, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4604, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4605, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4606, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4607, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4608, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4609, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4610, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4611, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4612, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4613, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4614, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4615, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4616, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4617, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4618, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4619, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4620, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4621, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4622, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4623, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4624, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4625, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4626, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4627, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4628, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4629, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4630, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4631, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4632, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4633, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4634, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4635, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4636, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4637, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4638, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4639, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4640, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4641, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4642, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4643, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4644, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4645, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4646, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4647, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4648, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4649, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4650, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4651, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4652, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4653, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4654, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4655, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4656, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4657, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4658, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4659, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4660, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4661, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4662, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4663, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4664, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4665, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4666, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4667, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4668, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4669, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4670, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4671, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4672, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4673, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4674, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4675, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4676, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4677, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4678, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4679, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4680, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4681, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4682, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4683, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4684, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4685, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.796 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4686, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4687, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4688, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4689, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4690, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4691, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4692, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4693, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4694, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4695, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4696, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4697, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4698, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4699, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4700, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4701, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4702, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4703, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4704, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4705, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4706, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4707, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4708, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000005 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4709, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4710, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4711, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4712, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4713, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4714, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4715, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4716, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4717, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4718, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 4719, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4720, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.796 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4721, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4722, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4723, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4724, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4725, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4726, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4727, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4728, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4729, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4730, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.811 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4731, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4732, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 4733, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4734, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.803 | Weighted | 0.820\n",
      "Epoch: 4735, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4736, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4737, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 4738, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.804 | Weighted | 0.820\n",
      "Epoch: 4739, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4740, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.808 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 4741, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.805 | Weighted | 0.822\n",
      "Epoch: 4742, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4743, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4744, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000004 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.811 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.798 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 4745, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.806 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.796 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.800 | Weighted | 0.818\n",
      "Epoch: 4746, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.805 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 4747, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 4748, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 4749, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.789 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.795 | Weighted | 0.812\n",
      "Epoch: 4750, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.795 | Weighted | 0.810\n",
      "Epoch: 4751, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.810 \n",
      "\tPrecision | Micro | 0.810 | Macro | 0.802 | Weighted | 0.808 \n",
      "\tRecall    | Micro | 0.810 | Macro | 0.791 | Weighted | 0.807 \n",
      "\tF1        | Micro | 0.810 | Macro | 0.795 | Weighted | 0.810\n",
      "Epoch: 4752, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.797 | Weighted | 0.812\n",
      "Epoch: 4753, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.797 | Weighted | 0.812\n",
      "Epoch: 4754, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.797 | Weighted | 0.812\n",
      "Epoch: 4755, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4756, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4757, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.792 | Weighted | 0.809 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4758, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.794 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4759, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.795 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4760, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.807 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 4761, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.809 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.789 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4762, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4763, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4764, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4765, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4766, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4767, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4768, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4769, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4770, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4771, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4772, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4773, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4774, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4775, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4776, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4777, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4778, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4779, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4780, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4781, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4782, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4783, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4784, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4785, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4786, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4787, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4788, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4789, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4790, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4791, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4792, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4793, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4794, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.790 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.798 | Weighted | 0.812\n",
      "Epoch: 4795, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4796, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4797, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4798, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4799, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4800, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4801, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4802, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.802 | Weighted | 0.815\n",
      "Epoch: 4803, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.802 | Weighted | 0.815\n",
      "Epoch: 4804, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.802 | Weighted | 0.815\n",
      "Epoch: 4805, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.802 | Weighted | 0.815\n",
      "Epoch: 4806, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.802 | Weighted | 0.815\n",
      "Epoch: 4807, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4808, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4809, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4810, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4811, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4812, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4813, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4814, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4815, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4816, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4817, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4818, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4819, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4820, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4821, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4822, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.812 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4823, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4824, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4825, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4826, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4827, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4828, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4829, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.810 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.791 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.799 | Weighted | 0.812\n",
      "Epoch: 4830, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4831, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4832, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4833, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4834, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4835, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4836, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4837, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4838, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4839, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4840, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4841, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4842, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4843, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4844, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4845, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4846, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4847, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.792 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.799 | Weighted | 0.814\n",
      "Epoch: 4848, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4849, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4850, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4851, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4852, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4853, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4854, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4855, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4856, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.813 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4857, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4858, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4859, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4860, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4861, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4862, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4863, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4864, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4865, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4866, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4867, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4868, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4869, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4870, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4871, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4872, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4873, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4874, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4875, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.800 | Weighted | 0.814\n",
      "Epoch: 4876, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.792 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.801 | Weighted | 0.815\n",
      "Epoch: 4877, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.814 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.791 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.801 | Weighted | 0.814\n",
      "Epoch: 4878, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4879, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.816 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.793 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.803 | Weighted | 0.815\n",
      "Epoch: 4880, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4881, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4882, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4883, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4884, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.817 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.804 | Weighted | 0.817\n",
      "Epoch: 4885, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4886, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.817 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.804 | Weighted | 0.817\n",
      "Epoch: 4887, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4888, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4889, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4890, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4891, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4892, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4893, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4894, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4895, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.817 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.804 | Weighted | 0.817\n",
      "Epoch: 4896, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.817 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.805 | Weighted | 0.820\n",
      "Epoch: 4897, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4898, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4899, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.817 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.805 | Weighted | 0.820\n",
      "Epoch: 4900, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4901, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.794 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4902, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4903, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4904, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4905, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4906, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4907, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4908, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4909, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.795 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.804 | Weighted | 0.818\n",
      "Epoch: 4910, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4911, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4912, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4913, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4914, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4915, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4916, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4917, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4918, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4919, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4920, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4921, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.817 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.802 | Weighted | 0.817\n",
      "Epoch: 4922, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.817 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.797 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.805 | Weighted | 0.820\n",
      "Epoch: 4923, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4924, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 4925, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4926, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4927, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4928, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4929, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4930, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4931, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4932, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4933, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4934, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4935, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4936, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4937, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4938, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4939, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4940, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4941, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4942, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4943, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4944, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4945, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4946, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4947, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4948, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4949, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4950, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4951, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4952, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4953, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4954, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4955, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4956, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4957, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4958, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000004 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4959, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000004 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4960, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4961, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4962, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4963, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4964, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4965, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4966, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4967, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4968, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4969, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4970, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4971, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4972, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4973, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4974, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4975, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4976, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 4977, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4978, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4979, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4980, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4981, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4982, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4983, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4984, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4985, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4986, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4987, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4988, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4989, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4990, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4991, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4992, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4993, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4994, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4995, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4996, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4997, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4998, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 4999, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5000, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5001, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5002, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5003, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5004, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5005, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5006, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5007, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5008, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5009, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5010, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5011, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5012, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5013, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5014, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5015, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5016, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5017, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5018, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5019, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5020, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5021, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5022, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5023, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5024, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5025, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5026, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5027, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5028, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5029, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5030, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5031, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5032, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5033, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5034, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5035, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5036, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5037, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5038, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5039, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5040, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5041, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5042, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5043, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5044, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5045, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5046, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5047, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5048, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5049, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5050, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5051, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5052, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5053, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5054, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.801 | Weighted | 0.817\n",
      "Epoch: 5055, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5056, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5057, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5058, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5059, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5060, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5061, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5062, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5063, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5064, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5065, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5066, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5067, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5068, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5069, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5070, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5071, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5072, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5073, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5074, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5075, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5076, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5077, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5078, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5079, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5080, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5081, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5082, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.801 | Weighted | 0.817\n",
      "Epoch: 5083, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5084, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5085, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5086, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5087, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5088, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5089, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5090, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5091, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5092, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5093, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5094, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5095, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5096, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5097, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5098, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5099, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5100, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5101, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5102, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5103, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5104, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5105, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5106, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5107, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5108, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5109, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5110, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5111, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5112, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5113, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5114, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5115, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5116, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5117, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5118, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5119, Train Loss: 0.770, Validation Loss: 0.929, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5120, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5121, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5122, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5123, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.815 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.792 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.802 | Weighted | 0.818\n",
      "Epoch: 5124, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5125, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5126, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5127, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5128, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5129, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5130, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5131, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5132, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5133, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5134, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5135, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5136, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5137, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.814 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5138, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5139, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5140, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5141, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5142, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5143, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5144, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5145, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5146, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5147, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5148, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5149, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5150, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5151, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5152, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5153, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5154, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5155, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5156, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5157, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5158, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5159, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5160, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5161, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5162, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5163, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5164, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5165, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5166, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5167, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5168, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5169, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5170, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5171, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5172, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5173, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5174, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5175, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5176, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5177, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5178, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5179, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5180, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5181, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5182, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5183, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5184, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5185, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5186, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5187, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5188, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5189, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5190, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5191, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5192, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5193, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5194, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5195, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5196, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5197, Train Loss: 0.770, Validation Loss: 0.928, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5198, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5199, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5200, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5201, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5202, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5203, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5204, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5205, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.813 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.800 | Weighted | 0.817\n",
      "Epoch: 5206, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5207, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5208, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5209, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5210, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5211, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5212, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5213, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5214, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5215, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.789 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5216, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5217, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5218, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5219, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5220, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5221, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5222, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.810 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.797 | Weighted | 0.814\n",
      "Epoch: 5223, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.809 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.796 | Weighted | 0.812\n",
      "Epoch: 5224, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.809 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.796 | Weighted | 0.812\n",
      "Epoch: 5225, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5226, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5227, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5228, Train Loss: 0.770, Validation Loss: 0.927, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5229, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.788 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5230, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5231, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.798 | Weighted | 0.815\n",
      "Epoch: 5232, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.796 | Weighted | 0.814\n",
      "Epoch: 5233, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.795 | Weighted | 0.812\n",
      "Epoch: 5234, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.795 | Weighted | 0.812\n",
      "Epoch: 5235, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.795 | Weighted | 0.812\n",
      "Epoch: 5236, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.806 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.787 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.795 | Weighted | 0.812\n",
      "Epoch: 5237, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.796 | Weighted | 0.814\n",
      "Epoch: 5238, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.796 | Weighted | 0.814\n",
      "Epoch: 5239, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5240, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5241, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5242, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5243, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5244, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5245, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5246, Train Loss: 0.770, Validation Loss: 0.926, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.811 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.798 | Weighted | 0.814\n",
      "Epoch: 5247, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5248, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5249, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5250, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5251, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.812 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.799 | Weighted | 0.815\n",
      "Epoch: 5252, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5253, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5254, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5255, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5256, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5257, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5258, Train Loss: 0.770, Validation Loss: 0.925, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5259, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5260, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5261, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5262, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5263, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.809 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.797 | Weighted | 0.815\n",
      "Epoch: 5264, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5265, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5266, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5267, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5268, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5269, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5270, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5271, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5272, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5273, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5274, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5275, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5276, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.804 | Weighted | 0.811 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.789 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.795 | Weighted | 0.814\n",
      "Epoch: 5277, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5278, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5279, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5280, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5281, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5282, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5283, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5284, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5285, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5286, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5287, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5288, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5289, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5290, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5291, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5292, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5293, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5294, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5295, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000003 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5296, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5297, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5298, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5299, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5300, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5301, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5302, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5303, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5304, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5305, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5306, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5307, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5308, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5309, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5310, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5311, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5312, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5313, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5314, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5315, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5316, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5317, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5318, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5319, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5320, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5321, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5322, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5323, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5324, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5325, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5326, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5327, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5328, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5329, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5330, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5331, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5332, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5333, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5334, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5335, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5336, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5337, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5338, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5339, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5340, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5341, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5342, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5343, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5344, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5345, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5346, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5347, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5348, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5349, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5350, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5351, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5352, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5353, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5354, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5355, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5356, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5357, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5358, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5359, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5360, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5361, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5362, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5363, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5364, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5365, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5366, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5367, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5368, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5369, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5370, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5371, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5372, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5373, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5374, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5375, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5376, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5377, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5378, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5379, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5380, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5381, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5382, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5383, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5384, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5385, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5386, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5387, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5388, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5389, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5390, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5391, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5392, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5393, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5394, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5395, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.806 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.790 | Weighted | 0.814 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 5396, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5397, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5398, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5399, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5400, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5401, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5402, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5403, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5404, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5405, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5406, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5407, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5408, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5409, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5410, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5411, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5412, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5413, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5414, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5415, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5416, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5417, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5418, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5419, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5420, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5421, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5422, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.816 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 5423, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5424, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5425, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5426, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5427, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5428, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5429, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5430, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5431, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5432, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5433, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5434, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5435, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5436, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5437, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5438, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5439, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5440, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5441, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5442, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5443, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5444, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5445, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5446, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5447, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5448, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5449, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5450, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5451, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5452, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5453, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5454, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5455, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5456, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5457, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5458, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5459, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5460, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5461, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5462, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5463, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5464, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5465, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5466, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5467, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.807 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 5468, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5469, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5470, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5471, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5472, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5473, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5474, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5475, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5476, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5477, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5478, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5479, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5480, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5481, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5482, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5483, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5484, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5485, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5486, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5487, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5488, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5489, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.810 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.801 | Weighted | 0.820\n",
      "Epoch: 5490, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5491, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5492, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5493, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5494, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5495, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5496, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5497, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.791 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5498, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5499, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5500, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5501, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5502, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5503, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5504, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5505, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5506, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5507, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5508, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5509, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5510, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5511, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5512, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5513, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5514, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5515, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5516, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5517, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5518, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5519, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5520, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5521, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5522, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5523, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5524, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5525, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5526, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5527, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5528, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5529, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5530, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5531, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5532, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5533, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5534, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5535, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5536, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5537, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5538, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5539, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5540, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5541, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5542, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5543, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5544, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5545, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5546, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5547, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5548, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5549, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5550, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5551, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5552, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5553, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5554, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5555, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5556, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5557, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5558, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5559, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5560, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5561, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5562, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5563, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5564, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5565, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5566, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5567, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5568, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5569, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5570, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5571, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5572, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5573, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5574, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5575, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5576, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5577, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5578, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5579, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5580, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5581, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5582, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5583, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5584, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5585, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5586, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5587, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5588, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5589, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5590, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5591, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5592, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5593, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5594, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5595, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5596, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5597, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5598, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5599, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5600, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5601, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5602, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5603, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5604, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5605, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5606, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5607, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5608, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5609, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5610, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5611, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5612, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5613, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5614, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5615, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5616, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5617, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5618, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5619, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5620, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5621, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5622, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5623, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5624, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5625, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5626, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5627, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5628, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5629, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5630, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5631, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5632, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5633, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5634, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5635, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5636, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5637, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5638, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5639, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5640, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5641, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5642, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5643, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5644, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5645, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5646, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5647, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5648, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5649, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5650, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5651, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5652, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5653, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5654, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5655, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5656, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5657, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5658, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5659, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5660, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5661, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5662, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5663, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5664, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5665, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5666, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5667, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5668, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5669, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5670, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5671, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5672, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5673, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5674, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5675, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5676, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5677, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5678, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5679, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5680, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5681, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5682, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5683, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.810 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.792 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.799 | Weighted | 0.817\n",
      "Epoch: 5684, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5685, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5686, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5687, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5688, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5689, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5690, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5691, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5692, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5693, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5694, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5695, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5696, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5697, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5698, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5699, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5700, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5701, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5702, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5703, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5704, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5705, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5706, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5707, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5708, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5709, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5710, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5711, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5712, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5713, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5714, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.812 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.793 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.801 | Weighted | 0.818\n",
      "Epoch: 5715, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5716, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5717, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.813 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.794 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5718, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5719, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5720, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5721, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5722, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5723, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5724, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5725, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5726, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5727, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.815 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.796 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5728, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 5729, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 5730, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 5731, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 5732, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.806 | Weighted | 0.823\n",
      "Epoch: 5733, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5734, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5735, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5736, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5737, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5738, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5739, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5740, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5741, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5742, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5743, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5744, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5745, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5746, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5747, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5748, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5749, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5750, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5751, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5752, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5753, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5754, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5755, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5756, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5757, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5758, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5759, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5760, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5761, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5762, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5763, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5764, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5765, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5766, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5767, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5768, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5769, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5770, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5771, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5772, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5773, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5774, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5775, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5776, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5777, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5778, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5779, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5780, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5781, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5782, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5783, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5784, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5785, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5786, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5787, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5788, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5789, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5790, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5791, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5792, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5793, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5794, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5795, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5796, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5797, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5798, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5799, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5800, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5801, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5802, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5803, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5804, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5805, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5806, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000002 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5807, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5808, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5809, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5810, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5811, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5812, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5813, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5814, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5815, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5816, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5817, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5818, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5819, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5820, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5821, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5822, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5823, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.821 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5824, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5825, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5826, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5827, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5828, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5829, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5830, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.822 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.809 | Weighted | 0.827\n",
      "Epoch: 5831, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.823 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 5832, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.823 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 5833, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.823 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 5834, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.823 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 5835, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.825 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.803 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.812 | Weighted | 0.830\n",
      "Epoch: 5836, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.823 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.811 | Weighted | 0.828\n",
      "Epoch: 5837, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.808 | Weighted | 0.825\n",
      "Epoch: 5838, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.798 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.807 | Weighted | 0.823\n",
      "Epoch: 5839, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 5840, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 5841, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.816 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.792 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.802 | Weighted | 0.820\n",
      "Epoch: 5842, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5843, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5844, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5845, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5846, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5847, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5848, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5849, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5850, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5851, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5852, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5853, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.817 | Weighted | 0.821 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.793 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.804 | Weighted | 0.822\n",
      "Epoch: 5854, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.819 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.795 | Weighted | 0.823 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 5855, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 5856, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.820 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 5857, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5858, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5859, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5860, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5861, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5862, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5863, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5864, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5865, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5866, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5867, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5868, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5869, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5870, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5871, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5872, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5873, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5874, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5875, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5876, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5877, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5878, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5879, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5880, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5881, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5882, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5883, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5884, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5885, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5886, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5887, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5888, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.821 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5889, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5890, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5891, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5892, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5893, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5894, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5895, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5896, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5897, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5898, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5899, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5900, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5901, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5902, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5903, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5904, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5905, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5906, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5907, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5908, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5909, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5910, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5911, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5912, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5913, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5914, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5915, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5916, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5917, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5918, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5919, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5920, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5921, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5922, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5923, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5924, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5925, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5926, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5927, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5928, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5929, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5930, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5931, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5932, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5933, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5934, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5935, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5936, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5937, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5938, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5939, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5940, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5941, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5942, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5943, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5944, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5945, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5946, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5947, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5948, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5949, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5950, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5951, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5952, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5953, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5954, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5955, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5956, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5957, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5958, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5959, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5960, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5961, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5962, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5963, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5964, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.816 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.796 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 5965, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5966, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5967, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5968, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5969, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5970, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5971, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5972, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5973, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5974, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5975, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.797 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 5976, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5977, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5978, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5979, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5980, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5981, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5982, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5983, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5984, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5985, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5986, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5987, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5988, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5989, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5990, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5991, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5992, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5993, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5994, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5995, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5996, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5997, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 5998, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 5999, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6000, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6001, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6002, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6003, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6004, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6005, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6006, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6007, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6008, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6009, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.802 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6010, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6011, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6012, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6013, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6014, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6015, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6016, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6017, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6018, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6019, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6020, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6021, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6022, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6023, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6024, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6025, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6026, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6027, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6028, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6029, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6030, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6031, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6032, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6033, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6034, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6035, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6036, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6037, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6038, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6039, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6040, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6041, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6042, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6043, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6044, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6045, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6046, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6047, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6048, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6049, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6050, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6051, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6052, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6053, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6054, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6055, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6056, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6057, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6058, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6059, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6060, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6061, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6062, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6063, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6064, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6065, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6066, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6067, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6068, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6069, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6070, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6071, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6072, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6073, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6074, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6075, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6076, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6077, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6078, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6079, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6080, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6081, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6082, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6083, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6084, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6085, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6086, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6087, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6088, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6089, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6090, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6091, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6092, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6093, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6094, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6095, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6096, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6097, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6098, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6099, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6100, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6101, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6102, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6103, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6104, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6105, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6106, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6107, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6108, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6109, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6110, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6111, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6112, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6113, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6114, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6115, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6116, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6117, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6118, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6119, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6120, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6121, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6122, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6123, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6124, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6125, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6126, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6127, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6128, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6129, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6130, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6131, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6132, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6133, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6134, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6135, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6136, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6137, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6138, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6139, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6140, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6141, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6142, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6143, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6144, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6145, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6146, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6147, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6148, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6149, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6150, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6151, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6152, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6153, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6154, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6155, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6156, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6157, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6158, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6159, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6160, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6161, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6162, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6163, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6164, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6165, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6166, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6167, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6168, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6169, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6170, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6171, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6172, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6173, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6174, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6175, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6176, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6177, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6178, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6179, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6180, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6181, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6182, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6183, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6184, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6185, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6186, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6187, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6188, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6189, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6190, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6191, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6192, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6193, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6194, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6195, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6196, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6197, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6198, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6199, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6200, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6201, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6202, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6203, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6204, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6205, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6206, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6207, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6208, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6209, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6210, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6211, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6212, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6213, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6214, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6215, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6216, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6217, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6218, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6219, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6220, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6221, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6222, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6223, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6224, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6225, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6226, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6227, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6228, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6229, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6230, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6231, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6232, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6233, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6234, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6235, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6236, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6237, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6238, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6239, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6240, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6241, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6242, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6243, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6244, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6245, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6246, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6247, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6248, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6249, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6250, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6251, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6252, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6253, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6254, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6255, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6256, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6257, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6258, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6259, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6260, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6261, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6262, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6263, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6264, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6265, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6266, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6267, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6268, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6269, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6270, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6271, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6272, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6273, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6274, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6275, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6276, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6277, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6278, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6279, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6280, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6281, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6282, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6283, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6284, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6285, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6286, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6287, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6288, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6289, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6290, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6291, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6292, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6293, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6294, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6295, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6296, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6297, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6298, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6299, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6300, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6301, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6302, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6303, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6304, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6305, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6306, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6307, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6308, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6309, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6310, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6311, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6312, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6313, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6314, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6315, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6316, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6317, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6318, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6319, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6320, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6321, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6322, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6323, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6324, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6325, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6326, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6327, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6328, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6329, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6330, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6331, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6332, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6333, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6334, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6335, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6336, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6337, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6338, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6339, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6340, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6341, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6342, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6343, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6344, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6345, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6346, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6347, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6348, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6349, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6350, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6351, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6352, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6353, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6354, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6355, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6356, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6357, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6358, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6359, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6360, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6361, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6362, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6363, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6364, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6365, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6366, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6367, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6368, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6369, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6370, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6371, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6372, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6373, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6374, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6375, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6376, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6377, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6378, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6379, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6380, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6381, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6382, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6383, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6384, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6385, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6386, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6387, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6388, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6389, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6390, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6391, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6392, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6393, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6394, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6395, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6396, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6397, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6398, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6399, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6400, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6401, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6402, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6403, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6404, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6405, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6406, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6407, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6408, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6409, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6410, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6411, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6412, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6413, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6414, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6415, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6416, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6417, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6418, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6419, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6420, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6421, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6422, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6423, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6424, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6425, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6426, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6427, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6428, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6429, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6430, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6431, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6432, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6433, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6434, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6435, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6436, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6437, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6438, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6439, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6440, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6441, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6442, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6443, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6444, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6445, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6446, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6447, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6448, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6449, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6450, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6451, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6452, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6453, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6454, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6455, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6456, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6457, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6458, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6459, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6460, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6461, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6462, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6463, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6464, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6465, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6466, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6467, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6468, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6469, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6470, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6471, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6472, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6473, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6474, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6475, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6476, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6477, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6478, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6479, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6480, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6481, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6482, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6483, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6484, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6485, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6486, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6487, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6488, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6489, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6490, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6491, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6492, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6493, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6494, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6495, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6496, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6497, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6498, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6499, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6500, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6501, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6502, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6503, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6504, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6505, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6506, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6507, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6508, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6509, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6510, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6511, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6512, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6513, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6514, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6515, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6516, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6517, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6518, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6519, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6520, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6521, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6522, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6523, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6524, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6525, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6526, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6527, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6528, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6529, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6530, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6531, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6532, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6533, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6534, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6535, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6536, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6537, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6538, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6539, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6540, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6541, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6542, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6543, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6544, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6545, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6546, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6547, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6548, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6549, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6550, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6551, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6552, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6553, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6554, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6555, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6556, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6557, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6558, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6559, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6560, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6561, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6562, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6563, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6564, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6565, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6566, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6567, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6568, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6569, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6570, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6571, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6572, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6573, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6574, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6575, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6576, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6577, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6578, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6579, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6580, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6581, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6582, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6583, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6584, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6585, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6586, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6587, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6588, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6589, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6590, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6591, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6592, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6593, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6594, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6595, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6596, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6597, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6598, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6599, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6600, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6601, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6602, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6603, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6604, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6605, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6606, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6607, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6608, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6609, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6610, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6611, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6612, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6613, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6614, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6615, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6616, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6617, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6618, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6619, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6620, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6621, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6622, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6623, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6624, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6625, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6626, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6627, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6628, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6629, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6630, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6631, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6632, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6633, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6634, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6635, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6636, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6637, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6638, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6639, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6640, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6641, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6642, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6643, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6644, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6645, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6646, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6647, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6648, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6649, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6650, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6651, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6652, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6653, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6654, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6655, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6656, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6657, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6658, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6659, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6660, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6661, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6662, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6663, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6664, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6665, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6666, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6667, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6668, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6669, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6670, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6671, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6672, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6673, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6674, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6675, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6676, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6677, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6678, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6679, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6680, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6681, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6682, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6683, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6684, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6685, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6686, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6687, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6688, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6689, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6690, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6691, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6692, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6693, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6694, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6695, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6696, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6697, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6698, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6699, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6700, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6701, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6702, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6703, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6704, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6705, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6706, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6707, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6708, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6709, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6710, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6711, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6712, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6713, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6714, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6715, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6716, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6717, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6718, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6719, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6720, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6721, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6722, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6723, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6724, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6725, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6726, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6727, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6728, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6729, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6730, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6731, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6732, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6733, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.819 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6734, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6735, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6736, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6737, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6738, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6739, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6740, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6741, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6742, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6743, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6744, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6745, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6746, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6747, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6748, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6749, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6750, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6751, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6752, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6753, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6754, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6755, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6756, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6757, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6758, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6759, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6760, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6761, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6762, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6763, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6764, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6765, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6766, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6767, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6768, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6769, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6770, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6771, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6772, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6773, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6774, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6775, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6776, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6777, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6778, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6779, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6780, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6781, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6782, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6783, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6784, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6785, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6786, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6787, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6788, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6789, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6790, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6791, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6792, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6793, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6794, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6795, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6796, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6797, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6798, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6799, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6800, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6801, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.823 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.806 | Weighted | 0.825\n",
      "Epoch: 6802, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6803, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6804, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6805, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6806, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6807, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6808, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6809, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6810, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6811, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6812, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6813, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6814, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6815, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6816, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6817, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6818, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6819, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6820, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6821, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6822, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6823, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6824, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6825, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.820 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 6826, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.825 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.807 | Weighted | 0.827\n",
      "Epoch: 6827, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.818 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.808 | Weighted | 0.827\n",
      "Epoch: 6828, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6829, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.817 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.799 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.807 | Weighted | 0.825\n",
      "Epoch: 6830, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6831, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6832, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6833, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6834, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6835, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6836, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 6837, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6838, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6839, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6840, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6841, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6842, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6843, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6844, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6845, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6846, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6847, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6848, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6849, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6850, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6851, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6852, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6853, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6854, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6855, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6856, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6857, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6858, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6859, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6860, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6861, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6862, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6863, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6864, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6865, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6866, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6867, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6868, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6869, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6870, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6871, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6872, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6873, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6874, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6875, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6876, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6877, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6878, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6879, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6880, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6881, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6882, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6883, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6884, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6885, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.794 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 6886, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6887, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6888, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6889, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6890, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6891, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6892, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6893, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6894, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6895, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6896, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6897, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6898, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6899, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6900, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6901, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6902, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6903, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6904, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000001 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6905, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6906, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6907, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6908, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6909, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6910, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6911, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6912, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6913, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6914, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6915, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6916, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6917, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6918, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6919, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6920, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6921, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6922, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6923, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6924, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6925, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6926, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6927, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6928, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6929, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6930, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6931, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6932, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6933, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6934, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6935, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6936, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6937, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6938, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6939, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6940, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6941, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6942, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6943, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6944, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6945, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6946, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6947, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6948, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6949, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6950, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6951, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6952, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6953, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6954, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6955, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6956, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6957, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6958, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6959, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 6960, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6961, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6962, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6963, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6964, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6965, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6966, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6967, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6968, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6969, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6970, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6971, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6972, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6973, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6974, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6975, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6976, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6977, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6978, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6979, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6980, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6981, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6982, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6983, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6984, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6985, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6986, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6987, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6988, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6989, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6990, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6991, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6992, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6993, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6994, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6995, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6996, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6997, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6998, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 6999, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7000, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7001, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7002, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7003, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7004, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7005, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7006, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7007, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7008, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7009, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7010, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7011, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7012, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7013, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7014, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7015, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7016, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7017, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7018, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7019, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7020, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7021, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7022, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7023, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7024, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7025, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7026, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7027, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7028, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7029, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7030, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7031, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7032, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7033, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7034, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7035, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7036, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7037, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7038, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.818 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7039, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 7040, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 7041, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 7042, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 7043, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.810 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.789 | Weighted | 0.816 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.798 | Weighted | 0.818\n",
      "Epoch: 7044, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 7045, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.808 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.797 | Weighted | 0.817\n",
      "Epoch: 7046, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7047, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7048, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7049, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7050, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7051, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7052, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7053, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7054, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7055, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.812 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.787 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.798 | Weighted | 0.817\n",
      "Epoch: 7056, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 7057, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 7058, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 7059, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 7060, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.785 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.796 | Weighted | 0.815\n",
      "Epoch: 7061, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7062, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7063, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7064, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7065, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7066, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.808 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.812 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.793 | Weighted | 0.814\n",
      "Epoch: 7067, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7068, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7069, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7070, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7071, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7072, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7073, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7074, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7075, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.807 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.791 | Weighted | 0.812\n",
      "Epoch: 7076, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.812 \n",
      "\tPrecision | Micro | 0.812 | Macro | 0.803 | Weighted | 0.810 \n",
      "\tRecall    | Micro | 0.812 | Macro | 0.779 | Weighted | 0.810 \n",
      "\tF1        | Micro | 0.812 | Macro | 0.790 | Weighted | 0.812\n",
      "Epoch: 7077, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 7078, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 7079, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 7080, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.814 \n",
      "\tPrecision | Micro | 0.814 | Macro | 0.805 | Weighted | 0.812 \n",
      "\tRecall    | Micro | 0.814 | Macro | 0.781 | Weighted | 0.811 \n",
      "\tF1        | Micro | 0.814 | Macro | 0.791 | Weighted | 0.814\n",
      "Epoch: 7081, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7082, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7083, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7084, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7085, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7086, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7087, Train Loss: 0.770, Validation Loss: 0.924, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7088, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7089, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7090, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7091, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7092, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7093, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7094, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7095, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7096, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.815 \n",
      "\tPrecision | Micro | 0.815 | Macro | 0.810 | Weighted | 0.813 \n",
      "\tRecall    | Micro | 0.815 | Macro | 0.782 | Weighted | 0.813 \n",
      "\tF1        | Micro | 0.815 | Macro | 0.794 | Weighted | 0.815\n",
      "Epoch: 7097, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 7098, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 7099, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 7100, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 7101, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.817 \n",
      "\tPrecision | Micro | 0.817 | Macro | 0.811 | Weighted | 0.815 \n",
      "\tRecall    | Micro | 0.817 | Macro | 0.784 | Weighted | 0.815 \n",
      "\tF1        | Micro | 0.817 | Macro | 0.796 | Weighted | 0.817\n",
      "Epoch: 7102, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7103, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7104, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7105, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7106, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7107, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7108, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7109, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7110, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7111, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7112, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7113, Train Loss: 0.770, Validation Loss: 0.923, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7114, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7115, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7116, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7117, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.816 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.785 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.799 | Weighted | 0.818\n",
      "Epoch: 7118, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7119, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7120, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7121, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7122, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7123, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7124, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7125, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7126, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7127, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7128, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7129, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7130, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7131, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7132, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7133, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7134, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7135, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7136, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7137, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7138, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7139, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7140, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7141, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7142, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7143, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7144, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7145, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7146, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7147, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7148, Train Loss: 0.770, Validation Loss: 0.922, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7149, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7150, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7151, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7152, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7153, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7154, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7155, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7156, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7157, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7158, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.818 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7159, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 7160, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 7161, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 7162, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 7163, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.820 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.789 | Weighted | 0.821 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.802 | Weighted | 0.822\n",
      "Epoch: 7164, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7165, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7166, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7167, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7168, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7169, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7170, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7171, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7172, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7173, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7174, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7175, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7176, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7177, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7178, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7179, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7180, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7181, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7182, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7183, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7184, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7185, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7186, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7187, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7188, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7189, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7190, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7191, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7192, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7193, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7194, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7195, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7196, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7197, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7198, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7199, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7200, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7201, Train Loss: 0.770, Validation Loss: 0.921, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7202, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7203, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7204, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7205, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7206, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7207, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7208, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.814 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.787 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.799 | Weighted | 0.820\n",
      "Epoch: 7209, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 7210, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.818 \n",
      "\tPrecision | Micro | 0.818 | Macro | 0.809 | Weighted | 0.817 \n",
      "\tRecall    | Micro | 0.818 | Macro | 0.786 | Weighted | 0.817 \n",
      "\tF1        | Micro | 0.818 | Macro | 0.796 | Weighted | 0.818\n",
      "Epoch: 7211, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7212, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7213, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7214, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7215, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7216, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7217, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7218, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7219, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7220, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7221, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7222, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7223, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7224, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7225, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7226, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7227, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7228, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7229, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7230, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7231, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7232, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7233, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7234, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7235, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7236, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7237, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7238, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7239, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7240, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7241, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7242, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7243, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7244, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7245, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.811 | Weighted | 0.819 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.788 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.798 | Weighted | 0.820\n",
      "Epoch: 7246, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7247, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7248, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7249, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7250, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7251, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7252, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7253, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7254, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7255, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7256, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7257, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7258, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7259, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7260, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7261, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7262, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7263, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7264, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7265, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7266, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7267, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7268, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7269, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7270, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7271, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7272, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7273, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7274, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7275, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7276, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7277, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7278, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7279, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7280, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7281, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7282, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7283, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7284, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7285, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7286, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7287, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7288, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7289, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7290, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7291, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7292, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7293, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7294, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7295, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7296, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7297, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7298, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7299, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7300, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7301, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7302, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7303, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7304, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7305, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7306, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7307, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7308, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7309, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7310, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7311, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7312, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7313, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7314, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7315, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7316, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7317, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7318, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7319, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7320, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7321, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7322, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7323, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7324, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7325, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7326, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7327, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7328, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7329, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7330, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7331, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7332, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7333, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7334, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7335, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7336, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7337, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7338, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7339, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7340, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7341, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7342, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7343, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7344, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7345, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7346, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7347, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7348, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7349, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7350, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7351, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7352, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7353, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7354, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7355, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7356, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7357, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7358, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7359, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7360, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7361, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7362, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7363, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7364, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7365, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7366, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7367, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7368, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7369, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7370, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7371, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7372, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7373, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7374, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7375, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7376, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7377, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7378, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7379, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7380, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7381, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7382, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7383, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7384, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7385, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.810 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.800 | Weighted | 0.822\n",
      "Epoch: 7386, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7387, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7388, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7389, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7390, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7391, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7392, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7393, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7394, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7395, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7396, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7397, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7398, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7399, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7400, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7401, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7402, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7403, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7404, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7405, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7406, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7407, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7408, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7409, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7410, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7411, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7412, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7413, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7414, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.811 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.801 | Weighted | 0.823\n",
      "Epoch: 7415, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7416, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7417, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7418, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7419, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7420, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7421, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7422, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7423, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7424, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7425, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7426, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7427, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7428, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7429, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7430, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7431, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7432, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7433, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7434, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7435, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7436, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7437, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7438, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7439, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7440, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7441, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7442, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7443, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7444, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7445, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7446, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7447, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7448, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7449, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7450, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7451, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7452, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.814 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.793 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7453, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7454, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7455, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7456, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7457, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7458, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7459, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7460, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7461, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7462, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.813 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.792 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.801 | Weighted | 0.822\n",
      "Epoch: 7463, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7464, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7465, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7466, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7467, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7468, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7469, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7470, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7471, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7472, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7473, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7474, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7475, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7476, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7477, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.820 \n",
      "\tPrecision | Micro | 0.820 | Macro | 0.812 | Weighted | 0.818 \n",
      "\tRecall    | Micro | 0.820 | Macro | 0.790 | Weighted | 0.819 \n",
      "\tF1        | Micro | 0.820 | Macro | 0.800 | Weighted | 0.820\n",
      "Epoch: 7478, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7479, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7480, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7481, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7482, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7483, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7484, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7485, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7486, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7487, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7488, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7489, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7490, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7491, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7492, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7493, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7494, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7495, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7496, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7497, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7498, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7499, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7500, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7501, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7502, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7503, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7504, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7505, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7506, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7507, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7508, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7509, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7510, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7511, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7512, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7513, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7514, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7515, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7516, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7517, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7518, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7519, Train Loss: 0.770, Validation Loss: 0.920, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7520, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7521, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7522, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7523, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7524, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7525, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7526, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7527, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7528, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7529, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7530, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7531, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7532, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7533, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7534, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7535, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7536, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7537, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7538, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7539, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7540, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7541, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7542, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7543, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7544, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7545, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7546, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7547, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7548, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7549, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7550, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7551, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7552, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7553, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7554, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7555, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7556, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7557, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7558, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7559, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7560, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7561, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7562, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7563, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7564, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7565, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7566, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7567, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7568, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7569, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7570, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7571, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7572, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7573, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7574, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7575, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7576, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7577, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7578, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7579, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7580, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7581, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.822 \n",
      "\tPrecision | Micro | 0.822 | Macro | 0.814 | Weighted | 0.820 \n",
      "\tRecall    | Micro | 0.822 | Macro | 0.795 | Weighted | 0.820 \n",
      "\tF1        | Micro | 0.822 | Macro | 0.803 | Weighted | 0.822\n",
      "Epoch: 7582, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7583, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7584, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7585, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7586, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7587, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7588, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7589, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7590, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7591, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7592, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7593, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7594, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7595, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7596, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7597, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7598, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7599, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7600, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7601, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7602, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7603, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7604, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7605, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7606, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7607, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7608, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7609, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7610, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7611, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7612, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7613, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7614, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7615, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7616, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7617, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7618, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7619, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7620, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7621, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7622, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7623, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7624, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7625, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7626, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7627, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7628, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7629, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7630, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7631, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7632, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7633, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7634, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7635, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7636, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7637, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7638, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7639, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7640, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7641, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7642, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.815 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.805 | Weighted | 0.823\n",
      "Epoch: 7643, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7644, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7645, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7646, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7647, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7648, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7649, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7650, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7651, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7652, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7653, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7654, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7655, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7656, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7657, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7658, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7659, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7660, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7661, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7662, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7663, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7664, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7665, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7666, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7667, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7668, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7669, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7670, Train Loss: 0.770, Validation Loss: 0.919, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7671, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7672, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7673, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7674, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7675, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7676, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7677, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7678, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7679, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7680, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7681, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7682, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7683, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7684, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7685, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7686, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7687, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7688, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7689, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7690, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7691, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7692, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7693, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7694, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7695, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7696, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7697, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7698, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7699, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7700, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7701, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7702, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7703, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7704, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7705, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7706, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7707, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7708, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7709, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7710, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7711, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7712, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7713, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7714, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7715, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7716, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7717, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.809 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.802 | Weighted | 0.823\n",
      "Epoch: 7718, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7719, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7720, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7721, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7722, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7723, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7724, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7725, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7726, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7727, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7728, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7729, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7730, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7731, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7732, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7733, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7734, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7735, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7736, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7737, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7738, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7739, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7740, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.823 \n",
      "\tPrecision | Micro | 0.823 | Macro | 0.812 | Weighted | 0.822 \n",
      "\tRecall    | Micro | 0.823 | Macro | 0.797 | Weighted | 0.822 \n",
      "\tF1        | Micro | 0.823 | Macro | 0.803 | Weighted | 0.823\n",
      "Epoch: 7741, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7742, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7743, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7744, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7745, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7746, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7747, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7748, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7749, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7750, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7751, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7752, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7753, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7754, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7755, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7756, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7757, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7758, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7759, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7760, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7761, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7762, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7763, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7764, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7765, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7766, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7767, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7768, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7769, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7770, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7771, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7772, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7773, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.825 \n",
      "\tPrecision | Micro | 0.825 | Macro | 0.813 | Weighted | 0.824 \n",
      "\tRecall    | Micro | 0.825 | Macro | 0.798 | Weighted | 0.824 \n",
      "\tF1        | Micro | 0.825 | Macro | 0.805 | Weighted | 0.825\n",
      "Epoch: 7774, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7775, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7776, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7777, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7778, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7779, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7780, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7781, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7782, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7783, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7784, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7785, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7786, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7787, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7788, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7789, Train Loss: 0.770, Validation Loss: 0.918, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7790, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7791, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7792, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7793, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7794, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7795, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7796, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7797, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7798, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7799, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7800, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7801, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7802, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7803, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7804, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7805, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7806, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7807, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7808, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7809, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7810, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7811, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7812, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7813, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7814, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7815, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7816, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7817, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7818, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7819, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7820, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7821, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7822, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7823, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7824, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7825, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7826, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7827, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7828, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7829, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7830, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7831, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7832, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7833, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7834, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7835, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7836, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7837, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7838, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7839, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7840, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7841, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7842, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7843, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7844, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7845, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7846, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7847, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7848, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7849, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7850, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7851, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7852, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7853, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7854, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7855, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7856, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7857, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7858, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7859, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7860, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7861, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7862, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7863, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7864, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7865, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7866, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7867, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7868, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7869, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7870, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7871, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7872, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7873, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7874, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7875, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7876, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7877, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7878, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7879, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7880, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7881, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7882, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7883, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7884, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7885, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7886, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7887, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7888, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7889, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7890, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7891, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7892, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7893, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7894, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7895, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7896, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7897, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7898, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7899, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7900, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7901, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7902, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7903, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7904, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7905, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7906, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7907, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7908, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7909, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7910, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7911, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7912, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7913, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7914, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7915, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7916, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7917, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7918, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7919, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7920, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7921, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7922, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7923, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7924, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7925, Train Loss: 0.770, Validation Loss: 0.917, LR: 0.000000 Accuracy: 0.827 \n",
      "\tPrecision | Micro | 0.827 | Macro | 0.815 | Weighted | 0.825 \n",
      "\tRecall    | Micro | 0.827 | Macro | 0.800 | Weighted | 0.826 \n",
      "\tF1        | Micro | 0.827 | Macro | 0.806 | Weighted | 0.827\n",
      "Epoch: 7926, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7927, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7928, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7929, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7930, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7931, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7932, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7933, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7934, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7935, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7936, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7937, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7938, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7939, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7940, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7941, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7942, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7943, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7944, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7945, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7946, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7947, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7948, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7949, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7950, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7951, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7952, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7953, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7954, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7955, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7956, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7957, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7958, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7959, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7960, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7961, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7962, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7963, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7964, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7965, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7966, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7967, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7968, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7969, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7970, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7971, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7972, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7973, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7974, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7975, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7976, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7977, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7978, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7979, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7980, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7981, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7982, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7983, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7984, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7985, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7986, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7987, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7988, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7989, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7990, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7991, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7992, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7993, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7994, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7995, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7996, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7997, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7998, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 7999, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8000, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8001, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8002, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8003, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8004, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8005, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8006, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8007, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8008, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8009, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8010, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8011, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8012, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8013, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8014, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8015, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8016, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8017, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8018, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8019, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8020, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8021, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8022, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8023, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8024, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8025, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8026, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8027, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8028, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8029, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8030, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8031, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8032, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8033, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8034, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8035, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8036, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8037, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8038, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8039, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8040, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8041, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8042, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8043, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8044, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8045, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8046, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8047, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8048, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8049, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8050, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8051, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8052, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8053, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8054, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8055, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8056, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8057, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8058, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8059, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8060, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8061, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8062, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8063, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8064, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8065, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8066, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8067, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8068, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8069, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8070, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8071, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8072, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8073, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8074, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8075, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8076, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8077, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8078, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8079, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8080, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8081, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8082, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8083, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8084, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.828 \n",
      "\tPrecision | Micro | 0.828 | Macro | 0.819 | Weighted | 0.827 \n",
      "\tRecall    | Micro | 0.828 | Macro | 0.801 | Weighted | 0.827 \n",
      "\tF1        | Micro | 0.828 | Macro | 0.809 | Weighted | 0.828\n",
      "Epoch: 8085, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8086, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8087, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8088, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8089, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8090, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8091, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8092, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8093, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8094, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8095, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8096, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8097, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8098, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8099, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8100, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8101, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8102, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8103, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8104, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8105, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8106, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8107, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8108, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8109, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8110, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8111, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8112, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8113, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8114, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8115, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8116, Train Loss: 0.770, Validation Loss: 0.916, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8117, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8118, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8119, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8120, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8121, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8122, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8123, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8124, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8125, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8126, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8127, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8128, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8129, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8130, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8131, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8132, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8133, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8134, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8135, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8136, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8137, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8138, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8139, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8140, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8141, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8142, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8143, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8144, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8145, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8146, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8147, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8148, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8149, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8150, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8151, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8152, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8153, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8154, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8155, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8156, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8157, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8158, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8159, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8160, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8161, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8162, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8163, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8164, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8165, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8166, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8167, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8168, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8169, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8170, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8171, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8172, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8173, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8174, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8175, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8176, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8177, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8178, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8179, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8180, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8181, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8182, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.830 \n",
      "\tPrecision | Micro | 0.830 | Macro | 0.821 | Weighted | 0.828 \n",
      "\tRecall    | Micro | 0.830 | Macro | 0.802 | Weighted | 0.829 \n",
      "\tF1        | Micro | 0.830 | Macro | 0.810 | Weighted | 0.830\n",
      "Epoch: 8183, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8184, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8185, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8186, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8187, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8188, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8189, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8190, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8191, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8192, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8193, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8194, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8195, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8196, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8197, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8198, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8199, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8200, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8201, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8202, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8203, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8204, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8205, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8206, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8207, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8208, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8209, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8210, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8211, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8212, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8213, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8214, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8215, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8216, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8217, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8218, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8219, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8220, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8221, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8222, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8223, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8224, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8225, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8226, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8227, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8228, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8229, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8230, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8231, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8232, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8233, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8234, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8235, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8236, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8237, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8238, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8239, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8240, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8241, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8242, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8243, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8244, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8245, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8246, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8247, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8248, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8249, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8250, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8251, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8252, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8253, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8254, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8255, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8256, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8257, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8258, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8259, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8260, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8261, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8262, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8263, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8264, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8265, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8266, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8267, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8268, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8269, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8270, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8271, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8272, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8273, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8274, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8275, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8276, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8277, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8278, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8279, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8280, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8281, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8282, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8283, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8284, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8285, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8286, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8287, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8288, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8289, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8290, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8291, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8292, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8293, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8294, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8295, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8296, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8297, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8298, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8299, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8300, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8301, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8302, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8303, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8304, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8305, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8306, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8307, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8308, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8309, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8310, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8311, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8312, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8313, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8314, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8315, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8316, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8317, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8318, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8319, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8320, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8321, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8322, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8323, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8324, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8325, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8326, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8327, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8328, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8329, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8330, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8331, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8332, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8333, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8334, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8335, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8336, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8337, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8338, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8339, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8340, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8341, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8342, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8343, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8344, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8345, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8346, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8347, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8348, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8349, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8350, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8351, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8352, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8353, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8354, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8355, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8356, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8357, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8358, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8359, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8360, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8361, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8362, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8363, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8364, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8365, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8366, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8367, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8368, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8369, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8370, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8371, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8372, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8373, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8374, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8375, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8376, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8377, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8378, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8379, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8380, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8381, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8382, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8383, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8384, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8385, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8386, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8387, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8388, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8389, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8390, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8391, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8392, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8393, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8394, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8395, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8396, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8397, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8398, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8399, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8400, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8401, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8402, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8403, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8404, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8405, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8406, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8407, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8408, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8409, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8410, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8411, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8412, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8413, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8414, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8415, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8416, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8417, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8418, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8419, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8420, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8421, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8422, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8423, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8424, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8425, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8426, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8427, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8428, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8429, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8430, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8431, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8432, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8433, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8434, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8435, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8436, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8437, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8438, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8439, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8440, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8441, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8442, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8443, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8444, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8445, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8446, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8447, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8448, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8449, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8450, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8451, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8452, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8453, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8454, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8455, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8456, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8457, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8458, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8459, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8460, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8461, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8462, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8463, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8464, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8465, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8466, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8467, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8468, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8469, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8470, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8471, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8472, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8473, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8474, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8475, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8476, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8477, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8478, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8479, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8480, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8481, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8482, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8483, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8484, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8485, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8486, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8487, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8488, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8489, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8490, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8491, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8492, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8493, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8494, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8495, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8496, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8497, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8498, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8499, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8500, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8501, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8502, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8503, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8504, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8505, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8506, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8507, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8508, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8509, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8510, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8511, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8512, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8513, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8514, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8515, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8516, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8517, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8518, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8519, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8520, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8521, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8522, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8523, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8524, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8525, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8526, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8527, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8528, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8529, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8530, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8531, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8532, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8533, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8534, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8535, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8536, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8537, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8538, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8539, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8540, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8541, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8542, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8543, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8544, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8545, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8546, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8547, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8548, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8549, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8550, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8551, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8552, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8553, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8554, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8555, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8556, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8557, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8558, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8559, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8560, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8561, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8562, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8563, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8564, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8565, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8566, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8567, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8568, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8569, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8570, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8571, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8572, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8573, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8574, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8575, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8576, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8577, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8578, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8579, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8580, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8581, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8582, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8583, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8584, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8585, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8586, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8587, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8588, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8589, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8590, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8591, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8592, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8593, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8594, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8595, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8596, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8597, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8598, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8599, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8600, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8601, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8602, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8603, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8604, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8605, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8606, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8607, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8608, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8609, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8610, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8611, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8612, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8613, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8614, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8615, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8616, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8617, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8618, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8619, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8620, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8621, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8622, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8623, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8624, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8625, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8626, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8627, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8628, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8629, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8630, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8631, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8632, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8633, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8634, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8635, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8636, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8637, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8638, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8639, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8640, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8641, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8642, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8643, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8644, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8645, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8646, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8647, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8648, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8649, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8650, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8651, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8652, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8653, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8654, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8655, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8656, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8657, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8658, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8659, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8660, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8661, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8662, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8663, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8664, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8665, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8666, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8667, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8668, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8669, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8670, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8671, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8672, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8673, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8674, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8675, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8676, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8677, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8678, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8679, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8680, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8681, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8682, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8683, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8684, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8685, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8686, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8687, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8688, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8689, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8690, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8691, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8692, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8693, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8694, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8695, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8696, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8697, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8698, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8699, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8700, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8701, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8702, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8703, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8704, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8705, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8706, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8707, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8708, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8709, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8710, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8711, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8712, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8713, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8714, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8715, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8716, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8717, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8718, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8719, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8720, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8721, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8722, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8723, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8724, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8725, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8726, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8727, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8728, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8729, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8730, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8731, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8732, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8733, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8734, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8735, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8736, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8737, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8738, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8739, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8740, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8741, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8742, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8743, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8744, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8745, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8746, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8747, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8748, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8749, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8750, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8751, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8752, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8753, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8754, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8755, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8756, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8757, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8758, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8759, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8760, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8761, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8762, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8763, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8764, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8765, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8766, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8767, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8768, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8769, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8770, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8771, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8772, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8773, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8774, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8775, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8776, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8777, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8778, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8779, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8780, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8781, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8782, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8783, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8784, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8785, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8786, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8787, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8788, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8789, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8790, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8791, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8792, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8793, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8794, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8795, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8796, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8797, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8798, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8799, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8800, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8801, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8802, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8803, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8804, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8805, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8806, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8807, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8808, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8809, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8810, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8811, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8812, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8813, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8814, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8815, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8816, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8817, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8818, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8819, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8820, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8821, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8822, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8823, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8824, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8825, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8826, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8827, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8828, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8829, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8830, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8831, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8832, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8833, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8834, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8835, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8836, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8837, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8838, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8839, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8840, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8841, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8842, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8843, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8844, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8845, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8846, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8847, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8848, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8849, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8850, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8851, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8852, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8853, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8854, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8855, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8856, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8857, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8858, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8859, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8860, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8861, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8862, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8863, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8864, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8865, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8866, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8867, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8868, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8869, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8870, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8871, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8872, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8873, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8874, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8875, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8876, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8877, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8878, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8879, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8880, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8881, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8882, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8883, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8884, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8885, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8886, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8887, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8888, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8889, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8890, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8891, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8892, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8893, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8894, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8895, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8896, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8897, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8898, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8899, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8900, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8901, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8902, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8903, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8904, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8905, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8906, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8907, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8908, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8909, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8910, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8911, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8912, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8913, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8914, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8915, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8916, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8917, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8918, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8919, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8920, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8921, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8922, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8923, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8924, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8925, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8926, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8927, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8928, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8929, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8930, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8931, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8932, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8933, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8934, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8935, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8936, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8937, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8938, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8939, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8940, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8941, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8942, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8943, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8944, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8945, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8946, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8947, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8948, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8949, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8950, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8951, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8952, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8953, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8954, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8955, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8956, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8957, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8958, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8959, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8960, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8961, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8962, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8963, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8964, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8965, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8966, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8967, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8968, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8969, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8970, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8971, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8972, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8973, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8974, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8975, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8976, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8977, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8978, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8979, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8980, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8981, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8982, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8983, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8984, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8985, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8986, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8987, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8988, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8989, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8990, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8991, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8992, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8993, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8994, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8995, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8996, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8997, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8998, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 8999, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9000, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9001, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9002, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9003, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9004, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9005, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9006, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9007, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9008, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9009, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9010, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9011, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9012, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9013, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9014, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9015, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9016, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9017, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9018, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9019, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9020, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9021, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9022, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9023, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9024, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9025, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9026, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9027, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9028, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9029, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9030, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9031, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9032, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9033, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9034, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9035, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9036, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9037, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9038, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9039, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9040, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9041, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9042, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9043, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9044, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9045, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9046, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9047, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9048, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9049, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9050, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9051, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9052, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9053, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9054, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9055, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9056, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9057, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9058, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9059, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9060, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9061, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9062, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9063, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9064, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9065, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9066, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9067, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9068, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9069, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9070, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9071, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9072, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9073, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9074, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9075, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9076, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9077, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9078, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9079, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9080, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9081, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9082, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9083, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9084, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9085, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9086, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9087, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9088, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9089, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9090, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9091, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9092, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9093, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9094, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9095, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9096, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9097, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9098, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9099, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9100, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9101, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9102, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9103, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9104, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9105, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9106, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9107, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9108, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9109, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9110, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9111, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9112, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9113, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9114, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9115, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9116, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9117, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9118, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9119, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9120, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9121, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9122, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9123, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9124, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9125, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9126, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9127, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9128, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9129, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9130, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9131, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9132, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9133, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9134, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9135, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9136, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9137, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9138, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9139, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9140, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9141, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9142, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9143, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9144, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9145, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9146, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9147, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9148, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9149, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9150, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9151, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9152, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9153, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9154, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9155, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9156, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9157, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9158, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9159, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9160, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9161, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9162, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9163, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9164, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9165, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9166, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9167, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9168, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9169, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9170, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9171, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9172, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9173, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9174, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9175, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9176, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9177, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9178, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9179, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9180, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9181, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9182, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9183, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9184, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9185, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9186, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9187, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9188, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9189, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9190, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9191, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9192, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9193, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9194, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9195, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9196, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9197, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9198, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9199, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9200, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9201, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9202, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9203, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9204, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9205, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9206, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9207, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9208, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9209, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9210, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9211, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9212, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9213, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9214, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9215, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9216, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9217, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9218, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9219, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9220, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9221, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9222, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9223, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9224, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9225, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9226, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9227, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9228, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9229, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9230, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9231, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9232, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9233, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9234, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9235, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9236, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9237, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9238, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9239, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9240, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9241, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9242, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9243, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9244, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9245, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9246, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9247, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9248, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9249, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9250, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9251, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9252, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9253, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9254, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9255, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9256, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9257, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9258, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9259, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9260, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9261, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9262, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9263, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9264, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9265, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9266, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9267, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9268, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9269, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9270, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9271, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9272, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9273, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9274, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9275, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9276, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9277, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9278, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9279, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9280, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9281, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9282, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9283, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9284, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9285, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9286, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9287, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9288, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9289, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9290, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9291, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9292, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9293, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9294, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9295, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9296, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9297, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9298, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9299, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9300, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9301, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9302, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9303, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9304, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9305, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9306, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9307, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9308, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9309, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9310, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9311, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9312, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9313, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9314, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9315, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9316, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9317, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9318, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9319, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9320, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9321, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9322, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9323, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9324, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9325, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9326, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9327, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9328, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9329, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9330, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9331, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9332, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9333, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9334, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9335, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9336, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9337, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9338, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9339, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9340, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9341, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9342, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9343, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9344, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9345, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9346, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9347, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9348, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9349, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9350, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9351, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9352, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9353, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9354, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9355, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9356, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9357, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9358, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9359, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9360, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9361, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9362, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9363, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9364, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9365, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9366, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9367, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9368, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9369, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9370, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9371, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9372, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9373, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9374, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9375, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9376, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9377, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9378, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9379, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9380, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9381, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9382, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9383, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9384, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9385, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9386, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9387, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9388, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9389, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9390, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9391, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9392, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9393, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9394, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9395, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9396, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9397, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9398, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9399, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9400, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9401, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9402, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9403, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9404, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9405, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9406, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9407, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9408, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9409, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9410, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9411, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9412, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9413, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9414, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9415, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9416, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9417, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9418, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9419, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9420, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9421, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9422, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9423, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9424, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9425, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9426, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9427, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9428, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9429, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9430, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9431, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9432, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9433, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9434, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9435, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9436, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9437, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9438, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9439, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9440, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9441, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9442, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9443, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9444, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9445, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9446, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9447, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9448, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9449, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9450, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9451, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9452, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9453, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9454, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9455, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9456, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9457, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9458, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9459, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9460, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9461, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9462, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9463, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9464, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9465, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9466, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9467, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9468, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9469, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9470, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9471, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9472, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9473, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9474, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9475, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9476, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9477, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9478, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9479, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9480, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9481, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9482, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9483, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9484, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9485, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9486, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9487, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9488, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9489, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9490, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9491, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9492, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9493, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9494, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9495, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9496, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9497, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9498, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9499, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9500, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9501, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9502, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9503, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9504, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9505, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9506, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9507, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9508, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9509, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9510, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9511, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9512, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9513, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9514, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9515, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9516, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9517, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9518, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9519, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9520, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9521, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9522, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9523, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9524, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9525, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9526, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9527, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9528, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9529, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9530, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9531, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9532, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9533, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9534, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9535, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9536, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9537, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9538, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9539, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9540, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9541, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9542, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9543, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9544, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9545, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9546, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9547, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9548, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9549, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9550, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9551, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9552, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9553, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9554, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9555, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9556, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9557, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9558, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9559, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9560, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9561, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9562, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9563, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9564, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9565, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9566, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9567, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9568, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9569, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9570, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9571, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9572, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9573, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9574, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9575, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9576, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9577, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9578, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9579, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9580, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9581, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9582, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9583, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9584, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9585, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9586, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9587, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9588, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9589, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9590, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9591, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9592, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9593, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9594, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9595, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9596, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9597, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9598, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9599, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9600, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9601, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9602, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9603, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9604, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9605, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9606, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9607, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9608, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9609, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9610, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9611, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9612, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9613, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9614, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9615, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9616, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9617, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9618, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9619, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9620, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9621, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9622, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9623, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9624, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9625, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9626, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9627, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9628, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9629, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9630, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9631, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9632, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9633, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9634, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9635, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9636, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9637, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9638, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9639, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9640, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9641, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9642, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9643, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9644, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9645, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9646, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9647, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9648, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9649, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9650, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9651, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9652, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9653, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9654, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9655, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9656, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9657, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9658, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9659, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9660, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9661, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9662, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9663, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9664, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9665, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9666, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9667, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9668, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9669, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9670, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9671, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9672, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9673, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9674, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9675, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9676, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9677, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9678, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9679, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9680, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9681, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9682, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9683, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9684, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9685, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9686, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9687, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9688, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9689, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9690, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9691, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9692, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9693, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9694, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9695, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9696, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9697, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9698, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9699, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9700, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9701, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9702, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9703, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9704, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9705, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9706, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9707, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9708, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9709, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9710, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9711, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9712, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9713, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9714, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9715, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9716, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9717, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9718, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9719, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9720, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9721, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9722, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9723, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9724, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9725, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9726, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9727, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9728, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9729, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9730, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9731, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9732, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9733, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9734, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9735, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9736, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9737, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9738, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9739, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9740, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9741, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9742, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9743, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9744, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9745, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9746, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9747, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9748, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9749, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9750, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9751, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9752, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9753, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9754, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9755, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9756, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9757, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9758, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9759, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9760, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9761, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9762, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9763, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9764, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9765, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9766, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9767, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9768, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9769, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9770, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9771, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9772, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9773, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9774, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9775, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9776, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9777, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9778, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9779, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9780, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9781, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9782, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9783, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9784, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9785, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9786, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9787, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9788, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9789, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9790, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9791, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9792, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9793, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9794, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9795, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9796, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9797, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9798, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9799, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9800, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9801, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9802, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9803, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9804, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9805, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9806, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9807, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9808, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9809, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9810, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9811, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9812, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9813, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9814, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9815, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9816, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9817, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9818, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9819, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9820, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9821, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9822, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9823, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9824, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9825, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9826, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9827, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9828, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9829, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9830, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9831, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9832, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9833, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9834, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9835, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9836, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9837, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9838, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9839, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9840, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9841, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9842, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9843, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9844, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9845, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9846, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9847, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9848, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9849, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9850, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9851, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9852, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9853, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9854, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9855, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9856, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9857, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9858, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9859, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9860, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9861, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9862, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9863, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9864, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9865, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9866, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9867, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9868, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9869, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9870, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9871, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9872, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9873, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9874, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9875, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9876, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9877, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9878, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9879, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9880, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9881, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9882, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9883, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9884, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9885, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9886, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9887, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9888, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9889, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9890, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9891, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9892, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9893, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9894, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9895, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9896, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9897, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9898, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9899, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9900, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9901, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9902, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9903, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9904, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9905, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9906, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9907, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9908, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9909, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9910, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9911, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9912, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9913, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9914, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9915, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9916, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9917, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9918, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9919, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9920, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9921, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9922, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9923, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9924, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9925, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9926, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9927, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9928, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9929, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9930, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9931, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9932, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9933, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9934, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9935, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9936, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9937, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9938, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9939, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9940, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9941, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9942, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9943, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9944, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9945, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9946, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9947, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9948, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9949, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9950, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9951, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9952, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9953, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9954, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9955, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9956, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9957, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9958, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9959, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9960, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9961, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9962, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9963, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9964, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9965, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9966, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9967, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9968, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9969, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9970, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9971, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9972, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9973, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9974, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9975, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9976, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9977, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9978, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9979, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9980, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9981, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9982, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9983, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9984, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9985, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9986, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9987, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9988, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9989, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9990, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9991, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9992, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9993, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9994, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9995, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9996, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9997, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9998, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Epoch: 9999, Train Loss: 0.770, Validation Loss: 0.915, LR: 0.000000 Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function, optimizer, and early stopper\n",
    "# Best so far\n",
    "# 0.0005 LR | 1000 epochs | patience: 3 | min_delta: 0.5 | gamma: 0.999 | batch size: 64\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=0.5)\n",
    "train_losses, val_losses, accuracies, precisions, recalls, f1s = train(model, optimizer, criterion, scheduler, train_X, train_y, test_X, test_y, batch_size=128, num_epochs=10000, early_stopper=early_stopper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Accuracy: 0.831 \n",
      "\tPrecision | Micro | 0.831 | Macro | 0.822 | Weighted | 0.830 \n",
      "\tRecall    | Micro | 0.831 | Macro | 0.804 | Weighted | 0.830 \n",
      "\tF1        | Micro | 0.831 | Macro | 0.812 | Weighted | 0.831\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    # Forward Pass\n",
    "    output = model(test_X)\n",
    "\n",
    "    # Compute Metrics\n",
    "    correct = correct = test_y.cpu().argmax(dim=1)\n",
    "    answer = output.argmax(dim=1).cpu()\n",
    "\n",
    "    accuracy = accuracy_score(correct, answer)\n",
    "\n",
    "    micro_precision = precision_score(correct, answer, average='micro', zero_division=0)\n",
    "    micro_recall = recall_score(correct, answer, average='micro', zero_division=0)\n",
    "    micro_f1 = f1_score(correct, answer, average='micro', zero_division=0)\n",
    "\n",
    "    macro_precision = precision_score(correct, answer, average='macro', zero_division=0)\n",
    "    macro_recall = recall_score(correct, answer, average='macro', zero_division=0)\n",
    "    macro_f1 = f1_score(correct, answer, average='macro', zero_division=0)\n",
    "\n",
    "    weighted_precision = precision_score(correct, answer, average='weighted', zero_division=0)\n",
    "    weighted_recall = recall_score(correct, answer, average='weighted', zero_division=0)\n",
    "    weighted_f1 = f1_score(correct, answer, average='weighted', zero_division=0)\n",
    "\n",
    "    # Print Metrics\n",
    "    print(f\"Evaluation: Accuracy: {accuracy:.3f}\",\n",
    "            f\"\\n\\tPrecision | Micro | {micro_precision:.3f} | Macro | {macro_precision:.3f} | Weighted | {weighted_f1:.3f}\",\n",
    "            f\"\\n\\tRecall    | Micro | {micro_recall:.3f} | Macro | {macro_recall:.3f} | Weighted | {weighted_precision:.3f}\",\n",
    "            f\"\\n\\tF1        | Micro | {micro_f1:.3f} | Macro | {macro_f1:.3f} | Weighted | {weighted_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test losses and accuracies\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy vs. Epoch\")\n",
    "plt.plot(accuracies, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot precisions, recalls, and f1s\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Precision vs. Epoch\")\n",
    "plt.plot(precisions[0], label='Micro Precision')\n",
    "plt.plot(precisions[1], label='Macro Precision')\n",
    "plt.plot(precisions[2], label='Weighted Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Recall vs. Epoch\")\n",
    "plt.plot(recalls[0], label='Micro Recall')\n",
    "plt.plot(recalls[1], label='Macro Recall')\n",
    "plt.plot(recalls[2], label='Weighted Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"F1 vs. Epoch\")\n",
    "plt.plot(f1s[0], label='Micro F1')\n",
    "plt.plot(f1s[1], label='Macro F1')\n",
    "plt.plot(f1s[2], label='Weighted F1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion matrix')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pretty confusion matrix\n",
    "y_pred = torch.argmax(model(test_X), dim=1)\n",
    "ConfusionMatrixDisplay.from_predictions(test_y.argmax(dim=1).cpu(), y_pred.cpu(), display_labels=COMPOSERS)\n",
    "plt.title(\"Confusion matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
